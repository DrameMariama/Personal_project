{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = []\n",
    "test = []\n",
    "path = 'movie_data/full_train.txt'\n",
    "for line in open('movie_data/full_train.txt', 'r'):\n",
    "    train.append(line.strip())\n",
    "for line in open('movie_data/full_test.txt', 'r'):\n",
    "    test.append(line.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Data Prprocssing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Define rgular expression\n",
    "REMOVE = re.compile(\"(\\.)|(\\;)|(\\:)|(\\!)|(\\')|(\\?)|(\\,)|(\\\")|(\\()|(\\))|(\\[)|(\\])\") ## remove pontuation bracket\n",
    "REPLACE_WITH_SPACE = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\") ##replace them by space\n",
    "def preprocessing_text(text):\n",
    "    text = [REMOVE.sub(\"\", line.lower()) for line in text]\n",
    "    text = [REPLACE_WITH_SPACE.sub(\" \", line) for line in text]\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preprocess = preprocessing_text(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preprocess = preprocessing_text(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Vectorization or one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(binary=True)\n",
    "cv.fit(train_preprocess)\n",
    "X_train =  cv.transform(train_preprocess) ## sparse matrix\n",
    "X_test = cv.transform(test_preprocess) ## sparse matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import  LogisticRegression\n",
    "from sklearn.metrics import  accuracy_score\n",
    "from sklearn.model_selection import  train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "##creating target for training set\n",
    "target = [1 if i < 12500 else 0 for i in range(25000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "##splitting data \n",
    "x_train, x_val, y_train, y_val = train_test_split(X_train, target, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mariama/.local/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.87024\n",
      "Accuracy for C=0.02: 0.87632\n",
      "Accuracy for C=0.25: 0.87664\n",
      "Accuracy for C=0.5: 0.87568\n",
      "Accuracy for C=1: 0.8736\n"
     ]
    }
   ],
   "source": [
    "##tuning C hyperparameters for logistic regression\n",
    "for c in [0.01, 0.02, 0.25, 0.5, 1]:\n",
    "    lr = LogisticRegression(C=c)\n",
    "    lr.fit(x_train, y_train)\n",
    "    print (\"Accuracy for C=%s: %s\" % (c, accuracy_score(y_val, lr.predict(x_val))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=1: 0.86676\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(C=0.25)\n",
    "model.fit(X_train, target)\n",
    "print (\"Accuracy for C=%s: %s\" % (c, accuracy_score(target, lr.predict(X_test))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "most discriminating positive word\n",
      "========================================\n",
      "('excellent', 1.221845113337239)\n",
      "('perfect', 1.0617036184558397)\n",
      "('refreshing', 1.0252761986496355)\n",
      "('superb', 0.9405736244442207)\n",
      "('wonderfully', 0.9347513506886701)\n",
      "========================================\n",
      "most discriminating negative word\n",
      "========================================\n",
      "('worst', -1.8189662434932818)\n",
      "('waste', -1.676084549454925)\n",
      "('poorly', -1.413817408695419)\n",
      "('disappointment', -1.4095633351098813)\n",
      "('awful', -1.3875327059387244)\n"
     ]
    }
   ],
   "source": [
    "feature_to_coef = {\n",
    "    word: coef for word, coef in zip(cv.get_feature_names(), model.coef_[0])\n",
    "}\n",
    "print(\"=\"*40)\n",
    "print(\"most discriminating positive word\")\n",
    "print(\"=\"*40)\n",
    "for best_positive in sorted(feature_to_coef.items(), key=lambda x: x[1], reverse=True)[:5]:\n",
    "    print(best_positive)\n",
    "print(\"=\"*40)\n",
    "print(\"most discriminating negative word\")\n",
    "print(\"=\"*40)\n",
    "for best_negative in sorted(feature_to_coef.items(), key=lambda x: x[1])[:5]:\n",
    "    print(best_negative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Removing stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "def remove_stop_word(text):\n",
    "    text_without_stop_word = []\n",
    "    for t in text:\n",
    "        text_without_stop_word.append(''.join([word for word in t.split() if word not in stop_words]))\n",
    "    return text_without_stop_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_without_stop_word = remove_stop_word(train_preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1) Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemming_text(text):\n",
    "    from nltk.stem.porter import PorterStemmer\n",
    "    stemmer = PorterStemmer()\n",
    "    return [''.join(stemmer.stem(word) for word in review.split()) for review in text]\n",
    "stemming_text = stemming_text(train_preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2) Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "def lemmatization_text(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return [''.join(lemmatizer.lemmatize(word) for word in review.split()) for review in text]\n",
    "lemma_text = lemmatization_text(train_preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) N_gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_vectorizer = CountVectorizer(binary=True, ngram_range=(1, 2))\n",
    "ngram_vectorizer.fit(train_preprocess)\n",
    "X_train = ngram_vectorizer.transform(train_preprocess)\n",
    "X_test = ngram_vectorizer.transform(test_preprocess)\n",
    "\n",
    "##splitting data \n",
    "x_train, x_val, y_train, y_val = train_test_split(X_train, target, test_size=0.25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.884\n",
      "Accuracy for C=0.05: 0.89136\n",
      "Accuracy for C=0.25: 0.89152\n",
      "Accuracy for C=0.5: 0.89136\n",
      "Accuracy for C=1: 0.89088\n"
     ]
    }
   ],
   "source": [
    "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "    lr = LogisticRegression(C=c)\n",
    "    lr.fit(x_train, y_train)\n",
    "    print (\"Accuracy for C=%s: %s\" % (c, accuracy_score(y_val, lr.predict(x_val))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.89768\n"
     ]
    }
   ],
   "source": [
    "final_ngram = LogisticRegression(C=0.25)\n",
    "final_ngram.fit(X_train, target)\n",
    "print (\"Final Accuracy: %s\" % accuracy_score(target, final_ngram.predict(X_test)))\n",
    "#print (\"Accuracy for C=%s: %s\" % (c, accuracy_score(target, lr.predict(X_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.892\n",
      "Accuracy for C=0.05: 0.89008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mariama/.local/lib/python3.5/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.25: 0.88976\n",
      "Accuracy for C=0.5: 0.8904\n",
      "Accuracy for C=1: 0.89024\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "ngram_vectorizer = CountVectorizer(binary=True, ngram_range=(1, 2))\n",
    "ngram_vectorizer.fit(train_preprocess)\n",
    "X_train = ngram_vectorizer.transform(train_preprocess)\n",
    "X_test = ngram_vectorizer.transform(test_preprocess)\n",
    "\n",
    "##splitting data \n",
    "x_train, x_val, y_train, y_val = train_test_split(X_train, target, test_size=0.25)\n",
    "\n",
    "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "    svm = LinearSVC(C=c)\n",
    "    svm.fit(x_train, y_train)\n",
    "    print (\"Accuracy for C=%s: %s\" % (c, accuracy_score(y_val, svm.predict(x_val))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.89412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mariama/.local/lib/python3.5/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "final_svm_ngram = LinearSVC(C=0.5)\n",
    "final_svm_ngram.fit(X_train, target)\n",
    "print (\"Final Accuracy: %s\" \n",
    "% accuracy_score(target, final_svm_ngram.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
