{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import statments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"Empirical Sensitivity.\"\"\"\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from utils import get_data_loaders\n",
    "from logistic_regression import nonprivate_logistic_regression\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_hist(array_of_empirical_sensitivities, n, lmbda, name):\n",
    "    if not isinstance(array_of_empirical_sensitivities, np.ndarray):\n",
    "        raise ValueError('array_of_empirical_sensitivities should be a np.ndarray.')\n",
    "    if not isinstance(name, str):\n",
    "        raise ValueError('name should be a str')\n",
    "\n",
    "    import matplotlib\n",
    "    matplotlib.use('Agg')\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    ################################################################\n",
    "    # TODO(student): replace below with correct theoretical max sensitivity\n",
    "    max_theoretical_sensitivity = 2./(n*lmbda)\n",
    "    ################################################################\n",
    "\n",
    "    num_bins = 20\n",
    "    dirname = './figs'\n",
    "    filename = os.path.join(dirname, name) + '.histogram.png'\n",
    "    if not os.path.exists(dirname):\n",
    "        os.makedirs(dirname)\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_xscale('log')\n",
    "    bin_values, _, _ = ax.hist(array_of_empirical_sensitivities, \n",
    "            num_bins, label='empirical sensitivities')\n",
    "    ax.set_title('histogram of sensitivities: ' + name)\n",
    "    ax.axvline(x=max_theoretical_sensitivity, color='r', linestyle='dashed', linewidth=2,\n",
    "            label='theoretical max sensitivity')\n",
    "    ax.legend()\n",
    "    fig.savefig(filename)\n",
    "    return filename\n",
    "\n",
    "\n",
    "def plot_extreme_neighbors(sensitivities, list_of_neighboring_examples, name):\n",
    "    \"\"\"Plots to disk the neighboring-example pairs with the most and least empirical sensitivity\n",
    "    \n",
    "    Note on the data structures used: \n",
    "        sensitivities: a np.ndarray containing empirical sensitivities for each run\n",
    "        list_of_neighboring_examples: a list of neighboring example pairs, one for each run. in other words:\n",
    "        \n",
    "        list_of_neighboring_examples = [\n",
    "            neighboring_example_1, \n",
    "            neighboring_example_2,  \n",
    "            ...\n",
    "            neighboring_example_n,\n",
    "            ]\n",
    "            \n",
    "        where each tuple in the list represents the data diff between the neighboring \n",
    "        datasets and is formatted like this:\n",
    "        \n",
    "        neighboring_example_i = (\n",
    "            (neighbor_img_i, neighbor_label_i),\n",
    "            (neighbor_img_i_prime, neighbor_label_i_prime),\n",
    "        )\n",
    "        \n",
    "        See utils.py if you are still confused.\n",
    "    \"\"\"\n",
    "    if not isinstance(sensitivities, np.ndarray):\n",
    "        raise ValueError('sensitivies should be a np.ndarray.')\n",
    "    first_neighbor_pair = list_of_neighboring_examples[0]\n",
    "    if not isinstance(list_of_neighboring_examples, list) or not isinstance(first_neighbor_pair, tuple) \\\n",
    "            or not isinstance(first_neighbor_pair[0][0], torch.Tensor):\n",
    "        raise ValueError('list_of_neighboring_examples should be a list of tuple pairs, where tuple contains img tensors')\n",
    "    if not isinstance(name, str):\n",
    "        raise ValueError('name should be a str')\n",
    "\n",
    "    import matplotlib\n",
    "    matplotlib.use('Agg')\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    ############################################################################\n",
    "    # TODO(student)\n",
    "    #\n",
    "    # using list_of_empirical_sensitivies and neighboring_examples, create two image plots\n",
    "    # 1) side-by-side images for neighbor-pair that maximizes sensitivity\n",
    "    # 2) side-by-side images for neighbor-pair that minimizes sensitivity\n",
    "    #\n",
    "    # matplotlib.subplots and matplotlib.imshow may come in handy\n",
    "    #\n",
    "    pil_transform = transforms.ToPILImage()\n",
    "    idx_max = np.argmax(sensitivities)\n",
    "    idx_min = np.argmin(sensitivities)\n",
    "    neighbor_example_max = list_of_neighboring_examples[idx_max]\n",
    "    neighbor_example_min = list_of_neighboring_examples[idx_min]\n",
    "    max_neighbor, max_neighbor_prime = neighbor_example_max\n",
    "    min_neighbor, min_neighbor_prime = neighbor_example_min \n",
    "    \n",
    "    max_neighbor_img, max_neighbor_target = max_neighbor\n",
    "    max_neighbor_prime_img, max_neighbor_prime_target = max_neighbor_prime\n",
    "    min_neighbor_img, min_neighbor_target = min_neighbor\n",
    "    min_neighbor_prime_img, min_neighbor_prime_target = min_neighbor_prime\n",
    "    \n",
    "    dirname = './figs'\n",
    "    filename1 = os.path.join(dirname, name)+'.maximum_sensitivity.png'\n",
    "    filename2 = os.path.join(dirname, name)+'.minimum_sensitivity.png'\n",
    "    filenames = filename1, filename2\n",
    "    if not os.path.exists(dirname):\n",
    "        os.makedirs(dirname)\n",
    "    fig1, axis1 = plt.subplots(1, 2, figsize=(10, 4))\n",
    "    axis1[0].imshow(pil_transform(max_neighbor_img))\n",
    "    axis1[1].imshow(pil_transform(max_neighbor_prime_img))\n",
    "    fig1.suptitle('maximum sensitivity: '+name)\n",
    "    fig1.savefig(filename1)\n",
    "    \n",
    "    fig2, axis2 = plt.subplots(1, 2, figsize=(10, 4))\n",
    "    axis2[0].imshow(pil_transform(min_neighbor_img))\n",
    "    axis2[1].imshow(pil_transform(min_neighbor_prime_img))\n",
    "    fig2.suptitle('minimum sensitivity: '+name)\n",
    "    fig2.savefig(filename2)\n",
    "    #raise NotImplementedError\n",
    "    ############################################################################\n",
    "\n",
    "    return filenames\n",
    "\n",
    "\n",
    "def compute_empricial_sensivity(train_loader, neighbor_loader,\n",
    "        num_epochs, learning_rate, lmbda, model_seed=None):\n",
    "    ############################################################################\n",
    "    # TODO(student)\n",
    "    #\n",
    "    # your code here...\n",
    "    #\n",
    "    #\n",
    "    #raise NotImplementedError\n",
    "    non_private_train_params = nonprivate_logistic_regression(train_loader, num_epochs, learning_rate, lmbda, model_seed)\n",
    "    non_private_neighbor_params = nonprivate_logistic_regression(neighbor_loader, num_epochs, learning_rate, lmbda, model_seed)\n",
    "    sensitivity = torch.norm(non_private_train_params['weight'] - non_private_neighbor_params['weight'], p=2)\n",
    "    ############################################################################\n",
    "\n",
    "    return sensitivity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main(n, runs, epochs, lr, batch_size, model_seed, lmbda):\n",
    "    list_of_empirical_sensitivies = []\n",
    "    list_of_neighboring_examples = []\n",
    "    for data_seed in range(runs):\n",
    "        loaders, neighboring_examples = get_data_loaders(data_seed, batch_size, \n",
    "                num_train=n)\n",
    "        sensitivity = compute_empricial_sensivity(\n",
    "                loaders['train'], loaders['neighbor'],\n",
    "                epochs, lr, lmbda, model_seed)\n",
    "        list_of_empirical_sensitivies.append(sensitivity)\n",
    "        list_of_neighboring_examples.append(neighboring_examples)\n",
    "\n",
    "    list_of_empirical_sensitivies = np.array(list_of_empirical_sensitivies)\n",
    "    sensitivity_upper_bound = 3.\n",
    "    name = 'lambda={},n={}'.format(lmbda, n)\n",
    "    filename = plot_hist(list_of_empirical_sensitivies, n, lmbda, name)\n",
    "    print('see plot at', filename)\n",
    "\n",
    "    filenames = plot_extreme_neighbors(list_of_empirical_sensitivies, list_of_neighboring_examples, name)\n",
    "    print('see plots at {} and {}'.format(*filenames))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "arguments and main function call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:10<00:00,  9.68it/s]\n",
      "100%|██████████| 100/100 [00:10<00:00,  9.43it/s]\n",
      "100%|██████████| 100/100 [00:10<00:00,  9.60it/s]\n",
      "100%|██████████| 100/100 [00:10<00:00,  9.54it/s]\n",
      "100%|██████████| 100/100 [00:10<00:00,  9.04it/s]\n",
      "100%|██████████| 100/100 [00:10<00:00,  8.97it/s]\n",
      "100%|██████████| 100/100 [00:10<00:00,  9.21it/s]\n",
      "100%|██████████| 100/100 [00:10<00:00,  8.99it/s]\n",
      "100%|██████████| 100/100 [00:10<00:00,  8.83it/s]\n",
      "100%|██████████| 100/100 [00:10<00:00,  9.26it/s]\n",
      "100%|██████████| 100/100 [00:11<00:00,  9.17it/s]\n",
      "100%|██████████| 100/100 [00:10<00:00,  9.40it/s]\n",
      "100%|██████████| 100/100 [00:11<00:00,  9.20it/s]\n",
      "100%|██████████| 100/100 [00:10<00:00,  9.04it/s]\n",
      "100%|██████████| 100/100 [00:10<00:00,  9.29it/s]\n",
      "100%|██████████| 100/100 [00:10<00:00,  9.17it/s]\n",
      "100%|██████████| 100/100 [00:10<00:00,  9.17it/s]\n",
      "100%|██████████| 100/100 [00:11<00:00,  9.30it/s]\n",
      "100%|██████████| 100/100 [00:11<00:00,  8.81it/s]\n",
      "100%|██████████| 100/100 [00:10<00:00,  9.17it/s]\n",
      "100%|██████████| 100/100 [00:11<00:00,  9.27it/s]\n",
      "100%|██████████| 100/100 [00:10<00:00,  9.19it/s]\n",
      "100%|██████████| 100/100 [00:10<00:00,  9.07it/s]\n",
      "100%|██████████| 100/100 [00:10<00:00,  9.38it/s]\n",
      "100%|██████████| 100/100 [00:10<00:00,  9.23it/s]\n",
      "100%|██████████| 100/100 [00:10<00:00,  8.97it/s]\n",
      "100%|██████████| 100/100 [00:10<00:00,  8.83it/s]\n",
      "100%|██████████| 100/100 [00:11<00:00,  8.75it/s]\n",
      "100%|██████████| 100/100 [00:11<00:00,  9.10it/s]\n",
      "100%|██████████| 100/100 [00:10<00:00,  9.28it/s]\n",
      "100%|██████████| 100/100 [00:10<00:00,  9.28it/s]\n",
      "100%|██████████| 100/100 [00:10<00:00,  9.39it/s]\n",
      "100%|██████████| 100/100 [00:10<00:00,  9.28it/s]\n",
      "100%|██████████| 100/100 [00:10<00:00,  9.45it/s]\n",
      "100%|██████████| 100/100 [00:10<00:00,  9.23it/s]\n",
      "100%|██████████| 100/100 [00:10<00:00,  9.25it/s]\n",
      "100%|██████████| 100/100 [00:10<00:00,  9.29it/s]\n",
      "100%|██████████| 100/100 [00:10<00:00,  9.09it/s]\n",
      "100%|██████████| 100/100 [00:10<00:00,  9.33it/s]\n",
      "100%|██████████| 100/100 [00:10<00:00,  9.39it/s]\n",
      "/usr/lib/python3/dist-packages/matplotlib/pyplot.py:524: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "see plot at ./figs/lambda=0.005,n=1000.histogram.png\n",
      "see plots at ./figs/lambda=0.005,n=1000.maximum_sensitivity.png and ./figs/lambda=0.005,n=1000.minimum_sensitivity.png\n"
     ]
    }
   ],
   "source": [
    "N = 1000\n",
    "RUNS = 20  # TODO(student): run more times once your code works; something like 100\n",
    "EPOCHS = 100\n",
    "LR = 0.1\n",
    "BATCH_SIZE = 256\n",
    "MODEL_SEED = 0\n",
    "LMBDA = 5e-3\n",
    "\n",
    "main(N, RUNS, EPOCHS, LR, BATCH_SIZE, MODEL_SEED, LMBDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
