{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sbn\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "import numpy\n",
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(7)\n",
    "import seaborn as sns\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define the accuracy function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_accuracy(y, y_hat):\n",
    "    x = np.array(y == y_hat).astype(int)\n",
    "    return np.sum(x)/len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define the reweighted accuracy function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def reweighted_accuracy(y1_hat,y , A):\n",
    "    n_0 = np.count_nonzero(A == 0)\n",
    "    n_1 = np.count_nonzero(A)\n",
    "    a_0 = np.where(A == 0)[0]\n",
    "    a_1 = np.where(A==1)[0]\n",
    "    \n",
    "    y_0 = np.count_nonzero(y1_hat[a_0] == y[a_0])/n_0\n",
    "    y_1 = np.count_nonzero(y1_hat[a_1] == y[a_1])/n_1\n",
    "    r = (y_0 + y_1)/2\n",
    "    return r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define the delta_DP function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_delta_DP(y_hat, a):\n",
    "    n_a_0, n_a_1 = np.count_nonzero(a==0), np.count_nonzero(a)\n",
    "    y_hat_0 = y_hat[np.where(a == 0)]\n",
    "    y_hat_1 = y_hat[np.where(a == 1)]\n",
    "    delta_dp = np.abs(np.sum(y_hat_0)/n_a_0 - np.sum(y_hat_1)/n_a_1)\n",
    "    return delta_dp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  10 most corelated attributes with y and 10 most corelated attributes with a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load and visualize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "npz = np.load('adult/adult_train.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "      <th>106</th>\n",
       "      <th>107</th>\n",
       "      <th>108</th>\n",
       "      <th>109</th>\n",
       "      <th>110</th>\n",
       "      <th>111</th>\n",
       "      <th>112</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 113 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3    4    5    6    7    8    9   ...   103  104  105  106  \\\n",
       "0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  0.0  0.0  0.0   \n",
       "1  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  0.0  0.0  0.0   \n",
       "2  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0  0.0   \n",
       "3  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0  0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0 ...   0.0  0.0  0.0  0.0   \n",
       "\n",
       "   107  108  109  110  111  112  \n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 113 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(list(npz['x']))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "      <th>106</th>\n",
       "      <th>107</th>\n",
       "      <th>108</th>\n",
       "      <th>109</th>\n",
       "      <th>110</th>\n",
       "      <th>111</th>\n",
       "      <th>112</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.050889</td>\n",
       "      <td>0.247351</td>\n",
       "      <td>0.264519</td>\n",
       "      <td>0.220356</td>\n",
       "      <td>0.135684</td>\n",
       "      <td>0.061884</td>\n",
       "      <td>0.019318</td>\n",
       "      <td>0.697030</td>\n",
       "      <td>0.078038</td>\n",
       "      <td>0.034274</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001044</td>\n",
       "      <td>0.000369</td>\n",
       "      <td>0.000553</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>0.003255</td>\n",
       "      <td>0.000584</td>\n",
       "      <td>0.000952</td>\n",
       "      <td>0.000614</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.017905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.219775</td>\n",
       "      <td>0.431479</td>\n",
       "      <td>0.441083</td>\n",
       "      <td>0.414493</td>\n",
       "      <td>0.342458</td>\n",
       "      <td>0.240948</td>\n",
       "      <td>0.137641</td>\n",
       "      <td>0.459549</td>\n",
       "      <td>0.268236</td>\n",
       "      <td>0.181935</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032298</td>\n",
       "      <td>0.019194</td>\n",
       "      <td>0.023506</td>\n",
       "      <td>0.022162</td>\n",
       "      <td>0.056964</td>\n",
       "      <td>0.024149</td>\n",
       "      <td>0.030841</td>\n",
       "      <td>0.024776</td>\n",
       "      <td>0.005542</td>\n",
       "      <td>0.132608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 113 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0             1             2             3             4    \\\n",
       "count  32561.000000  32561.000000  32561.000000  32561.000000  32561.000000   \n",
       "mean       0.050889      0.247351      0.264519      0.220356      0.135684   \n",
       "std        0.219775      0.431479      0.441083      0.414493      0.342458   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      1.000000      0.000000      0.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "                5             6             7             8             9    \\\n",
       "count  32561.000000  32561.000000  32561.000000  32561.000000  32561.000000   \n",
       "mean       0.061884      0.019318      0.697030      0.078038      0.034274   \n",
       "std        0.240948      0.137641      0.459549      0.268236      0.181935   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      1.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      1.000000      0.000000      0.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "           ...                103           104           105           106  \\\n",
       "count      ...       32561.000000  32561.000000  32561.000000  32561.000000   \n",
       "mean       ...           0.001044      0.000369      0.000553      0.000491   \n",
       "std        ...           0.032298      0.019194      0.023506      0.022162   \n",
       "min        ...           0.000000      0.000000      0.000000      0.000000   \n",
       "25%        ...           0.000000      0.000000      0.000000      0.000000   \n",
       "50%        ...           0.000000      0.000000      0.000000      0.000000   \n",
       "75%        ...           0.000000      0.000000      0.000000      0.000000   \n",
       "max        ...           1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "                107           108           109           110           111  \\\n",
       "count  32561.000000  32561.000000  32561.000000  32561.000000  32561.000000   \n",
       "mean       0.003255      0.000584      0.000952      0.000614      0.000031   \n",
       "std        0.056964      0.024149      0.030841      0.024776      0.005542   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "                112  \n",
       "count  32561.000000  \n",
       "mean       0.017905  \n",
       "std        0.132608  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        0.000000  \n",
       "max        1.000000  \n",
       "\n",
       "[8 rows x 113 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "data = pd.read_csv('adult/adult_headers.txt', header = None)\n",
    "data.columns = ['header']\n",
    "headers = []\n",
    "for header in data['header']:\n",
    "    headers.append(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_u20</th>\n",
       "      <th>age_u30</th>\n",
       "      <th>age_u40</th>\n",
       "      <th>age_u50</th>\n",
       "      <th>age_u60</th>\n",
       "      <th>age_u70</th>\n",
       "      <th>age_u80</th>\n",
       "      <th>workclass_Private</th>\n",
       "      <th>workclass_Self-emp-not-inc</th>\n",
       "      <th>workclass_Self-emp-inc</th>\n",
       "      <th>...</th>\n",
       "      <th>country_Nicaragua</th>\n",
       "      <th>country_Scotland</th>\n",
       "      <th>country_Thailand</th>\n",
       "      <th>country_Yugoslavia</th>\n",
       "      <th>country_El-Salvador</th>\n",
       "      <th>country_Trinadad&amp;Tobago</th>\n",
       "      <th>country_Peru</th>\n",
       "      <th>country_Hong</th>\n",
       "      <th>country_Holand-Netherlands</th>\n",
       "      <th>country_?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 113 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age_u20  age_u30  age_u40  age_u50  age_u60  age_u70  age_u80  \\\n",
       "0      1.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1      0.0      1.0      0.0      0.0      0.0      0.0      0.0   \n",
       "2      0.0      0.0      0.0      0.0      1.0      0.0      0.0   \n",
       "3      0.0      0.0      0.0      1.0      0.0      0.0      0.0   \n",
       "4      0.0      0.0      0.0      0.0      0.0      1.0      0.0   \n",
       "\n",
       "   workclass_Private  workclass_Self-emp-not-inc  workclass_Self-emp-inc  \\\n",
       "0                1.0                         0.0                     0.0   \n",
       "1                1.0                         0.0                     0.0   \n",
       "2                0.0                         0.0                     0.0   \n",
       "3                0.0                         0.0                     0.0   \n",
       "4                1.0                         0.0                     0.0   \n",
       "\n",
       "     ...      country_Nicaragua  country_Scotland  country_Thailand  \\\n",
       "0    ...                    0.0               0.0               0.0   \n",
       "1    ...                    0.0               0.0               0.0   \n",
       "2    ...                    0.0               0.0               0.0   \n",
       "3    ...                    0.0               0.0               0.0   \n",
       "4    ...                    0.0               0.0               0.0   \n",
       "\n",
       "   country_Yugoslavia  country_El-Salvador  country_Trinadad&Tobago  \\\n",
       "0                 0.0                  0.0                      0.0   \n",
       "1                 0.0                  0.0                      0.0   \n",
       "2                 0.0                  0.0                      0.0   \n",
       "3                 0.0                  0.0                      0.0   \n",
       "4                 0.0                  0.0                      0.0   \n",
       "\n",
       "   country_Peru  country_Hong  country_Holand-Netherlands  country_?  \n",
       "0           0.0           0.0                         0.0        0.0  \n",
       "1           0.0           0.0                         0.0        0.0  \n",
       "2           0.0           0.0                         0.0        0.0  \n",
       "3           0.0           0.0                         0.0        0.0  \n",
       "4           0.0           0.0                         0.0        0.0  \n",
       "\n",
       "[5 rows x 113 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns = headers[0:len(headers)-1]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   income\n",
       "0     0.0\n",
       "1     0.0\n",
       "2     1.0\n",
       "3     1.0\n",
       "4     0.0"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y =  pd.DataFrame(list(npz['y']))\n",
    "y =headers[len(headers)-1]\n",
    "df_y.columns = [y]\n",
    "df_y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adult_dataset = pd.concat([df, df_y], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_u20</th>\n",
       "      <th>age_u30</th>\n",
       "      <th>age_u40</th>\n",
       "      <th>age_u50</th>\n",
       "      <th>age_u60</th>\n",
       "      <th>age_u70</th>\n",
       "      <th>age_u80</th>\n",
       "      <th>workclass_Private</th>\n",
       "      <th>workclass_Self-emp-not-inc</th>\n",
       "      <th>workclass_Self-emp-inc</th>\n",
       "      <th>...</th>\n",
       "      <th>country_Scotland</th>\n",
       "      <th>country_Thailand</th>\n",
       "      <th>country_Yugoslavia</th>\n",
       "      <th>country_El-Salvador</th>\n",
       "      <th>country_Trinadad&amp;Tobago</th>\n",
       "      <th>country_Peru</th>\n",
       "      <th>country_Hong</th>\n",
       "      <th>country_Holand-Netherlands</th>\n",
       "      <th>country_?</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 114 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age_u20  age_u30  age_u40  age_u50  age_u60  age_u70  age_u80  \\\n",
       "0      1.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1      0.0      1.0      0.0      0.0      0.0      0.0      0.0   \n",
       "2      0.0      0.0      0.0      0.0      1.0      0.0      0.0   \n",
       "3      0.0      0.0      0.0      1.0      0.0      0.0      0.0   \n",
       "4      0.0      0.0      0.0      0.0      0.0      1.0      0.0   \n",
       "\n",
       "   workclass_Private  workclass_Self-emp-not-inc  workclass_Self-emp-inc  \\\n",
       "0                1.0                         0.0                     0.0   \n",
       "1                1.0                         0.0                     0.0   \n",
       "2                0.0                         0.0                     0.0   \n",
       "3                0.0                         0.0                     0.0   \n",
       "4                1.0                         0.0                     0.0   \n",
       "\n",
       "    ...    country_Scotland  country_Thailand  country_Yugoslavia  \\\n",
       "0   ...                 0.0               0.0                 0.0   \n",
       "1   ...                 0.0               0.0                 0.0   \n",
       "2   ...                 0.0               0.0                 0.0   \n",
       "3   ...                 0.0               0.0                 0.0   \n",
       "4   ...                 0.0               0.0                 0.0   \n",
       "\n",
       "   country_El-Salvador  country_Trinadad&Tobago  country_Peru  country_Hong  \\\n",
       "0                  0.0                      0.0           0.0           0.0   \n",
       "1                  0.0                      0.0           0.0           0.0   \n",
       "2                  0.0                      0.0           0.0           0.0   \n",
       "3                  0.0                      0.0           0.0           0.0   \n",
       "4                  0.0                      0.0           0.0           0.0   \n",
       "\n",
       "   country_Holand-Netherlands  country_?  income  \n",
       "0                         0.0        0.0     0.0  \n",
       "1                         0.0        0.0     0.0  \n",
       "2                         0.0        0.0     1.0  \n",
       "3                         0.0        0.0     1.0  \n",
       "4                         0.0        0.0     0.0  \n",
       "\n",
       "[5 rows x 114 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adult_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### top 10 correlated with y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "incom = pd.DataFrame(np.abs(adult_dataset.corr()['income']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>marital-status_Married-civ-spouse</th>\n",
       "      <td>0.444696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relationship_Husband</th>\n",
       "      <td>0.401035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education_num</th>\n",
       "      <td>0.335154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>marital-status_Never-married</th>\n",
       "      <td>0.318440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age_u30</th>\n",
       "      <td>0.238133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hours-per-week</th>\n",
       "      <td>0.229689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relationship_Own-child</th>\n",
       "      <td>0.228532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital-gain</th>\n",
       "      <td>0.223329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex_Male</th>\n",
       "      <td>0.215980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex_Female</th>\n",
       "      <td>0.215980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     income\n",
       "marital-status_Married-civ-spouse  0.444696\n",
       "relationship_Husband               0.401035\n",
       "education_num                      0.335154\n",
       "marital-status_Never-married       0.318440\n",
       "age_u30                            0.238133\n",
       "hours-per-week                     0.229689\n",
       "relationship_Own-child             0.228532\n",
       "capital-gain                       0.223329\n",
       "sex_Male                           0.215980\n",
       "sex_Female                         0.215980"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_income = incom.sort_values(by='income',  ascending=False)\n",
    "top_10 = corr_income[1:11] #the first row is y itself\n",
    "top_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlAAAAGBCAYAAACpaI9SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe135fcb898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels = [att for att in top_10['income'].index]\n",
    "\n",
    "#labels = ['Cookies', 'Jellybean', 'Milkshake', 'Cheesecake']\n",
    "sizes = [top_10['income'][i]*100/10 for i in range(10)]\n",
    "#colors = ['yellowgreen', 'gold', 'lightskyblue', 'lightcoral']\n",
    "explode = (0, 0.1, 0, 0, 0, 0.1, 0, 0, 0, 0)  \n",
    "\n",
    "#fig1, ax1 = plt.subplots()\n",
    "colors = ['yellowgreen', 'gold', 'lightskyblue', 'lightcoral', 'green', 'purple', 'cyan', 'indigo', 'red', 'maroon']\n",
    "#fig1, ax1 = plt.subplots()\n",
    "plt.pie(sizes, explode=explode, labels=labels, colors=colors, autopct='%1.1f%%',\n",
    "        shadow=False, startangle=90)\n",
    "\n",
    "# Equal aspect ratio ensures that pie is drawn as a circle\n",
    "plt.axis('equal')  \n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('corr10_y.png', dpi= 500 )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### top 10 correlated with A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sexe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sexe\n",
       "0   0.0\n",
       "1   0.0\n",
       "2   1.0\n",
       "3   1.0\n",
       "4   0.0"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_a =  pd.DataFrame(list(npz['a']))\n",
    "df_a.columns = ['sexe']\n",
    "df_a.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "adult_dataset_a = pd.concat([df, df_a], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sexe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sex_Female</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex_Male</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relationship_Husband</th>\n",
       "      <td>0.580135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>marital-status_Married-civ-spouse</th>\n",
       "      <td>0.431805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relationship_Unmarried</th>\n",
       "      <td>0.321273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relationship_Wife</th>\n",
       "      <td>0.319311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>occupation_Adm-clerical</th>\n",
       "      <td>0.263148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hours-per-week</th>\n",
       "      <td>0.229309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>marital-status_Divorced</th>\n",
       "      <td>0.228621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>occupation_Craft-repair</th>\n",
       "      <td>0.223128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       sexe\n",
       "sex_Female                         1.000000\n",
       "sex_Male                           1.000000\n",
       "relationship_Husband               0.580135\n",
       "marital-status_Married-civ-spouse  0.431805\n",
       "relationship_Unmarried             0.321273\n",
       "relationship_Wife                  0.319311\n",
       "occupation_Adm-clerical            0.263148\n",
       "hours-per-week                     0.229309\n",
       "marital-status_Divorced            0.228621\n",
       "occupation_Craft-repair            0.223128"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = pd.DataFrame(np.abs(adult_dataset_a.corr()['sexe']))\n",
    "corr_a = a.sort_values(by='sexe',  ascending=False)\n",
    "top_10_corr_a = corr_a[1:11]  #the first row is a itself\n",
    "top_10_corr_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAGICAYAAAC9XMGTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe135fc8f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels = [att for att in top_10_corr_a['sexe'].index]\n",
    "\n",
    "#labels = ['Cookies', 'Jellybean', 'Milkshake', 'Cheesecake']\n",
    "sizes = [top_10_corr_a['sexe'][i]*100/10 for i in range(10)]\n",
    "#colors = ['yellowgreen', 'gold', 'lightskyblue', 'lightcoral']\n",
    "explode = (0, 0.1, 0, 0, 0, 0.1, 0, 0, 0, 0)  \n",
    "colors = ['yellowgreen', 'gold', 'lightskyblue', 'lightcoral', 'green', 'purple', 'cyan', 'indigo', 'red', 'maroon']\n",
    "#fig1, ax1 = plt.subplots()\n",
    "plt.pie(sizes, explode=explode, labels=labels, colors=colors, autopct='%1.1f%%',\n",
    "        shadow= False, startangle=90)\n",
    "\n",
    "# Equal aspect ratio ensures that pie is drawn as a circle\n",
    "plt.axis('equal')  \n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('corr10_a.png', dpi= 500 )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model(train_data, train_target, val_data, val_target, batch_size=32, epochs=300, verbose=1):\n",
    "    # Build neural network\n",
    "    model1 = Sequential()\n",
    "    model1.add(Dense(256, activation='relu', input_dim=train_data.shape[1]))\n",
    "    #model.add(Dropout(0.1))\n",
    "    model1.add(Dense(128, activation='relu'))\n",
    "    #model.add(Dropout(0.1))\n",
    "    model1.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Compile model\n",
    "    model1.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam', \n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # Train model\n",
    "    model1.fit(train_data, train_target,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              verbose=verbose,\n",
    "              validation_data=(val_data, val_target))\n",
    "    return model1\n",
    "def scaling_data(data):\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(data)\n",
    "    data = scaler.transform(data)\n",
    "    return data\n",
    "    \n",
    "def evaluate_model(model, test_data, test_target):\n",
    "    score = model.evaluate(test_data, test_target, verbose=0)\n",
    "    return score[1]\n",
    "def predict(model, test_data):\n",
    "    y_hat = model.predict_classes(test_data)\n",
    "    return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get the training data\n",
    "\n",
    "X_train = df.copy()  #contents only attributes in x\n",
    "Y_train = df_y #contents only y attribut\n",
    "\n",
    "##loading test data\n",
    "npz_test = np.load('adult/adult_test.npz')\n",
    "df_test = pd.DataFrame(list(npz_test['x']))\n",
    "df_test.columns = headers[0:len(headers)-1]\n",
    "\n",
    "Y_test = pd.DataFrame(list(npz_test['y']))\n",
    "a_test =  pd.DataFrame(list(npz_test['a']))\n",
    "a_test.columns = ['sexe']\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "Y_train = np.array(Y_train)\n",
    "Y_train = Y_train.flatten()\n",
    "\n",
    "X_test = np.array(df_test)\n",
    "Y_test = np.array(Y_test)\n",
    "Y_test = Y_test.flatten()\n",
    "X_train.shape[0]\n",
    "\n",
    "train_ind = np.random.choice(X_train.shape[0], 3*X_train.shape[0]//4, replace=False) ## choose indexes for train and validation set\n",
    "\n",
    "\n",
    "X_train, Y_train = X_train[train_ind], Y_train[train_ind]\n",
    "X_val= df.drop(train_ind, axis=0)\n",
    "Y_val = df_y.drop(train_ind)\n",
    "X_val = np.array(X_val)\n",
    "Y_val = np.array(Y_val)\n",
    "Y_val = Y_val.flatten()\n",
    "# X_train = scaling_data(X_train)\n",
    "# X_test = scaling_data(X_test)\n",
    "# X_val = scaling_data(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24420 samples, validate on 8141 samples\n",
      "Epoch 1/300\n",
      "24420/24420 [==============================] - 1s 45us/step - loss: 1.2151 - acc: 0.8023 - val_loss: 1.1533 - val_acc: 0.7986\n",
      "Epoch 2/300\n",
      "24420/24420 [==============================] - 1s 45us/step - loss: 1.1829 - acc: 0.8100 - val_loss: 1.1247 - val_acc: 0.8188\n",
      "Epoch 3/300\n",
      "24420/24420 [==============================] - 1s 39us/step - loss: 1.1788 - acc: 0.8137 - val_loss: 1.1247 - val_acc: 0.8191\n",
      "Epoch 4/300\n",
      "24420/24420 [==============================] - 1s 34us/step - loss: 1.1720 - acc: 0.8166 - val_loss: 1.1212 - val_acc: 0.8225\n",
      "Epoch 5/300\n",
      "24420/24420 [==============================] - 1s 34us/step - loss: 1.1701 - acc: 0.8172 - val_loss: 1.1183 - val_acc: 0.8245\n",
      "Epoch 6/300\n",
      "24420/24420 [==============================] - 1s 34us/step - loss: 1.1684 - acc: 0.8173 - val_loss: 1.1202 - val_acc: 0.8180\n",
      "Epoch 7/300\n",
      "24420/24420 [==============================] - 1s 34us/step - loss: 1.1662 - acc: 0.8201 - val_loss: 1.1195 - val_acc: 0.8234\n",
      "Epoch 8/300\n",
      "24420/24420 [==============================] - 1s 33us/step - loss: 1.1648 - acc: 0.8206 - val_loss: 1.1240 - val_acc: 0.8204\n",
      "Epoch 9/300\n",
      "24420/24420 [==============================] - 1s 33us/step - loss: 1.1653 - acc: 0.8196 - val_loss: 1.1195 - val_acc: 0.8224\n",
      "Epoch 10/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 1.1637 - acc: 0.8198 - val_loss: 1.1314 - val_acc: 0.8186\n",
      "Epoch 11/300\n",
      "24420/24420 [==============================] - 1s 33us/step - loss: 1.1630 - acc: 0.8199 - val_loss: 1.1195 - val_acc: 0.8207\n",
      "Epoch 12/300\n",
      "24420/24420 [==============================] - 1s 34us/step - loss: 1.1612 - acc: 0.8210 - val_loss: 1.1227 - val_acc: 0.8237\n",
      "Epoch 13/300\n",
      "24420/24420 [==============================] - 1s 33us/step - loss: 1.1608 - acc: 0.8224 - val_loss: 1.1210 - val_acc: 0.8203\n",
      "Epoch 14/300\n",
      "24420/24420 [==============================] - 1s 33us/step - loss: 1.1594 - acc: 0.8223 - val_loss: 1.1221 - val_acc: 0.8213\n",
      "Epoch 15/300\n",
      "24420/24420 [==============================] - 1s 34us/step - loss: 1.1582 - acc: 0.8233 - val_loss: 1.1317 - val_acc: 0.8153\n",
      "Epoch 16/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 1.1563 - acc: 0.8258 - val_loss: 1.1328 - val_acc: 0.8138\n",
      "Epoch 17/300\n",
      "24420/24420 [==============================] - 1s 33us/step - loss: 1.1570 - acc: 0.8232 - val_loss: 1.5079 - val_acc: 0.7972\n",
      "Epoch 18/300\n",
      "24420/24420 [==============================] - 1s 34us/step - loss: 1.4585 - acc: 0.8051 - val_loss: 1.5125 - val_acc: 0.7919\n",
      "Epoch 19/300\n",
      "24420/24420 [==============================] - 1s 33us/step - loss: 1.4579 - acc: 0.8060 - val_loss: 1.5172 - val_acc: 0.7907\n",
      "Epoch 20/300\n",
      "24420/24420 [==============================] - 1s 34us/step - loss: 1.4560 - acc: 0.8056 - val_loss: 1.5168 - val_acc: 0.7995\n",
      "Epoch 21/300\n",
      "24420/24420 [==============================] - 1s 33us/step - loss: 1.4564 - acc: 0.8064 - val_loss: 1.5143 - val_acc: 0.7936\n",
      "Epoch 22/300\n",
      "24420/24420 [==============================] - 1s 33us/step - loss: 1.4539 - acc: 0.8068 - val_loss: 1.5098 - val_acc: 0.7972\n",
      "Epoch 23/300\n",
      "24420/24420 [==============================] - 1s 33us/step - loss: 1.4523 - acc: 0.8068 - val_loss: 1.5179 - val_acc: 0.7965\n",
      "Epoch 24/300\n",
      "24420/24420 [==============================] - 1s 32us/step - loss: 1.4518 - acc: 0.8068 - val_loss: 1.5166 - val_acc: 0.7976\n",
      "Epoch 25/300\n",
      "24420/24420 [==============================] - 1s 33us/step - loss: 1.4503 - acc: 0.8099 - val_loss: 1.5291 - val_acc: 0.7933\n",
      "Epoch 26/300\n",
      "24420/24420 [==============================] - 1s 33us/step - loss: 1.4491 - acc: 0.8090 - val_loss: 1.5243 - val_acc: 0.7976\n",
      "Epoch 27/300\n",
      "24420/24420 [==============================] - 1s 33us/step - loss: 1.4476 - acc: 0.8116 - val_loss: 1.5255 - val_acc: 0.7930\n",
      "Epoch 28/300\n",
      "24420/24420 [==============================] - 1s 33us/step - loss: 1.4460 - acc: 0.8103 - val_loss: 1.5279 - val_acc: 0.7956\n",
      "Epoch 29/300\n",
      "24420/24420 [==============================] - 1s 33us/step - loss: 1.4447 - acc: 0.8114 - val_loss: 1.5248 - val_acc: 0.7934\n",
      "Epoch 30/300\n",
      "24420/24420 [==============================] - 1s 32us/step - loss: 1.4429 - acc: 0.8123 - val_loss: 1.5265 - val_acc: 0.7950\n",
      "Epoch 31/300\n",
      "24420/24420 [==============================] - 1s 33us/step - loss: 1.4413 - acc: 0.8140 - val_loss: 1.5378 - val_acc: 0.7943\n",
      "Epoch 32/300\n",
      "24420/24420 [==============================] - 1s 33us/step - loss: 1.4404 - acc: 0.8113 - val_loss: 1.5349 - val_acc: 0.7956\n",
      "Epoch 33/300\n",
      "24420/24420 [==============================] - 1s 33us/step - loss: 1.4387 - acc: 0.8130 - val_loss: 1.5394 - val_acc: 0.7955\n",
      "Epoch 34/300\n",
      "24420/24420 [==============================] - 1s 33us/step - loss: 1.4368 - acc: 0.8139 - val_loss: 1.5387 - val_acc: 0.7901\n",
      "Epoch 35/300\n",
      "24420/24420 [==============================] - 1s 33us/step - loss: 1.4366 - acc: 0.8143 - val_loss: 1.5614 - val_acc: 0.7915\n",
      "Epoch 36/300\n",
      "24420/24420 [==============================] - 1s 32us/step - loss: 1.4348 - acc: 0.8161 - val_loss: 1.5313 - val_acc: 0.7947\n",
      "Epoch 37/300\n",
      "24420/24420 [==============================] - 1s 33us/step - loss: 1.4335 - acc: 0.8165 - val_loss: 1.5415 - val_acc: 0.7913\n",
      "Epoch 38/300\n",
      "24420/24420 [==============================] - 1s 33us/step - loss: 1.4322 - acc: 0.8177 - val_loss: 1.5519 - val_acc: 0.7947\n",
      "Epoch 39/300\n",
      "24420/24420 [==============================] - 1s 33us/step - loss: 1.4302 - acc: 0.8170 - val_loss: 1.5589 - val_acc: 0.7927\n",
      "Epoch 40/300\n",
      "24420/24420 [==============================] - 1s 33us/step - loss: 1.4293 - acc: 0.8172 - val_loss: 1.5521 - val_acc: 0.7927\n",
      "Epoch 41/300\n",
      "24420/24420 [==============================] - 1s 34us/step - loss: 1.4271 - acc: 0.8189 - val_loss: 1.5823 - val_acc: 0.7940\n",
      "Epoch 42/300\n",
      "24420/24420 [==============================] - 1s 33us/step - loss: 1.4261 - acc: 0.8194 - val_loss: 1.5677 - val_acc: 0.7941\n",
      "Epoch 43/300\n",
      "24420/24420 [==============================] - 1s 34us/step - loss: 1.4255 - acc: 0.8191 - val_loss: 1.5628 - val_acc: 0.7950\n",
      "Epoch 44/300\n",
      "24420/24420 [==============================] - 1s 34us/step - loss: 1.4231 - acc: 0.8212 - val_loss: 1.5763 - val_acc: 0.7945\n",
      "Epoch 45/300\n",
      "24420/24420 [==============================] - 1s 32us/step - loss: 1.4217 - acc: 0.8213 - val_loss: 1.5736 - val_acc: 0.7946\n",
      "Epoch 46/300\n",
      "24420/24420 [==============================] - 1s 34us/step - loss: 1.4195 - acc: 0.8222 - val_loss: 1.5792 - val_acc: 0.7963\n",
      "Epoch 47/300\n",
      "24420/24420 [==============================] - 1s 34us/step - loss: 1.4177 - acc: 0.8228 - val_loss: 1.5771 - val_acc: 0.7888\n",
      "Epoch 48/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.4168 - acc: 0.8240 - val_loss: 1.5970 - val_acc: 0.7915\n",
      "Epoch 49/300\n",
      "24420/24420 [==============================] - 1s 34us/step - loss: 1.4169 - acc: 0.8250 - val_loss: 1.5853 - val_acc: 0.7930\n",
      "Epoch 50/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 1.4147 - acc: 0.8258 - val_loss: 1.5929 - val_acc: 0.7909\n",
      "Epoch 51/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 1.4120 - acc: 0.8256 - val_loss: 1.5911 - val_acc: 0.7924\n",
      "Epoch 52/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 1.4123 - acc: 0.8255 - val_loss: 1.6003 - val_acc: 0.7928\n",
      "Epoch 53/300\n",
      "24420/24420 [==============================] - 1s 32us/step - loss: 1.4106 - acc: 0.8263 - val_loss: 1.5966 - val_acc: 0.7908\n",
      "Epoch 54/300\n",
      "24420/24420 [==============================] - 1s 33us/step - loss: 1.4087 - acc: 0.8287 - val_loss: 1.6163 - val_acc: 0.7890\n",
      "Epoch 55/300\n",
      "24420/24420 [==============================] - 1s 33us/step - loss: 1.4085 - acc: 0.8290 - val_loss: 1.6257 - val_acc: 0.7939\n",
      "Epoch 56/300\n",
      "24420/24420 [==============================] - 1s 33us/step - loss: 1.4065 - acc: 0.8288 - val_loss: 1.6266 - val_acc: 0.7914\n",
      "Epoch 57/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 1.4055 - acc: 0.8290 - val_loss: 1.6228 - val_acc: 0.7900\n",
      "Epoch 58/300\n",
      "24420/24420 [==============================] - 1s 33us/step - loss: 1.4039 - acc: 0.8294 - val_loss: 1.6316 - val_acc: 0.7892\n",
      "Epoch 59/300\n",
      "24420/24420 [==============================] - 1s 34us/step - loss: 1.4020 - acc: 0.8302 - val_loss: 1.6074 - val_acc: 0.7922\n",
      "Epoch 60/300\n",
      "24420/24420 [==============================] - 1s 33us/step - loss: 1.4013 - acc: 0.8305 - val_loss: 1.6272 - val_acc: 0.7895\n",
      "Epoch 61/300\n",
      "24420/24420 [==============================] - 1s 33us/step - loss: 1.3998 - acc: 0.8324 - val_loss: 1.6355 - val_acc: 0.7853\n",
      "Epoch 62/300\n",
      "24420/24420 [==============================] - 1s 33us/step - loss: 1.3999 - acc: 0.8311 - val_loss: 1.6340 - val_acc: 0.7898\n",
      "Epoch 63/300\n",
      "24420/24420 [==============================] - 1s 32us/step - loss: 1.3972 - acc: 0.8338 - val_loss: 1.6245 - val_acc: 0.7879\n",
      "Epoch 64/300\n",
      "24420/24420 [==============================] - 1s 33us/step - loss: 1.3982 - acc: 0.8333 - val_loss: 1.6409 - val_acc: 0.7859\n",
      "Epoch 65/300\n",
      "24420/24420 [==============================] - 1s 33us/step - loss: 1.3968 - acc: 0.8317 - val_loss: 1.6237 - val_acc: 0.7896\n",
      "Epoch 66/300\n",
      "24420/24420 [==============================] - 1s 33us/step - loss: 1.3940 - acc: 0.8346 - val_loss: 1.6570 - val_acc: 0.7928\n",
      "Epoch 67/300\n",
      "24420/24420 [==============================] - 1s 33us/step - loss: 1.3926 - acc: 0.8356 - val_loss: 1.6508 - val_acc: 0.7881\n",
      "Epoch 68/300\n",
      "24420/24420 [==============================] - 1s 34us/step - loss: 1.3933 - acc: 0.8347 - val_loss: 1.6518 - val_acc: 0.7935\n",
      "Epoch 69/300\n",
      "24420/24420 [==============================] - 1s 33us/step - loss: 1.3907 - acc: 0.8358 - val_loss: 1.6592 - val_acc: 0.7875\n",
      "Epoch 70/300\n",
      "24420/24420 [==============================] - 1s 34us/step - loss: 1.3904 - acc: 0.8353 - val_loss: 1.6471 - val_acc: 0.7879\n",
      "Epoch 71/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 1.3885 - acc: 0.8369 - val_loss: 1.6497 - val_acc: 0.7871\n",
      "Epoch 72/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 1.3893 - acc: 0.8367 - val_loss: 1.6760 - val_acc: 0.7893\n",
      "Epoch 73/300\n",
      "24420/24420 [==============================] - 1s 34us/step - loss: 1.3866 - acc: 0.8380 - val_loss: 1.6613 - val_acc: 0.7864\n",
      "Epoch 74/300\n",
      "24420/24420 [==============================] - 1s 34us/step - loss: 1.3865 - acc: 0.8382 - val_loss: 1.6675 - val_acc: 0.7879\n",
      "Epoch 75/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 1.3850 - acc: 0.8400 - val_loss: 1.6633 - val_acc: 0.7901\n",
      "Epoch 76/300\n",
      "24420/24420 [==============================] - 1s 34us/step - loss: 1.3861 - acc: 0.8388 - val_loss: 1.6590 - val_acc: 0.7875\n",
      "Epoch 77/300\n",
      "24420/24420 [==============================] - 1s 34us/step - loss: 1.3838 - acc: 0.8399 - val_loss: 1.6765 - val_acc: 0.7845\n",
      "Epoch 78/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 1.3840 - acc: 0.8377 - val_loss: 1.6664 - val_acc: 0.7882\n",
      "Epoch 79/300\n",
      "24420/24420 [==============================] - 1s 34us/step - loss: 1.3815 - acc: 0.8399 - val_loss: 1.6729 - val_acc: 0.7834\n",
      "Epoch 80/300\n",
      "24420/24420 [==============================] - 1s 34us/step - loss: 1.3805 - acc: 0.8399 - val_loss: 1.6541 - val_acc: 0.7861\n",
      "Epoch 81/300\n",
      "24420/24420 [==============================] - 1s 34us/step - loss: 1.3820 - acc: 0.8410 - val_loss: 1.6593 - val_acc: 0.7860\n",
      "Epoch 82/300\n",
      "24420/24420 [==============================] - 1s 34us/step - loss: 1.3798 - acc: 0.8416 - val_loss: 1.6826 - val_acc: 0.7820\n",
      "Epoch 83/300\n",
      "24420/24420 [==============================] - 1s 34us/step - loss: 1.3782 - acc: 0.8417 - val_loss: 1.7068 - val_acc: 0.7805\n",
      "Epoch 84/300\n",
      "24420/24420 [==============================] - 1s 34us/step - loss: 1.3810 - acc: 0.8399 - val_loss: 1.7025 - val_acc: 0.7838\n",
      "Epoch 85/300\n",
      "24420/24420 [==============================] - 1s 34us/step - loss: 1.3783 - acc: 0.8411 - val_loss: 1.6760 - val_acc: 0.7902\n",
      "Epoch 86/300\n",
      "24420/24420 [==============================] - 1s 34us/step - loss: 1.3763 - acc: 0.8427 - val_loss: 1.7184 - val_acc: 0.7810\n",
      "Epoch 87/300\n",
      "24420/24420 [==============================] - 1s 34us/step - loss: 1.3755 - acc: 0.8435 - val_loss: 1.6946 - val_acc: 0.7865\n",
      "Epoch 88/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 1.3755 - acc: 0.8434 - val_loss: 1.6986 - val_acc: 0.7858\n",
      "Epoch 89/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.3737 - acc: 0.8438 - val_loss: 1.7229 - val_acc: 0.7847\n",
      "Epoch 90/300\n",
      "24420/24420 [==============================] - 1s 41us/step - loss: 1.3736 - acc: 0.8457 - val_loss: 1.6988 - val_acc: 0.7861\n",
      "Epoch 91/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 1.3745 - acc: 0.8434 - val_loss: 1.6911 - val_acc: 0.7828\n",
      "Epoch 92/300\n",
      "24420/24420 [==============================] - 1s 41us/step - loss: 1.3733 - acc: 0.8444 - val_loss: 1.7000 - val_acc: 0.7886\n",
      "Epoch 93/300\n",
      "24420/24420 [==============================] - 1s 39us/step - loss: 1.3723 - acc: 0.8443 - val_loss: 1.7205 - val_acc: 0.7839\n",
      "Epoch 94/300\n",
      "24420/24420 [==============================] - 1s 39us/step - loss: 1.3695 - acc: 0.8463 - val_loss: 1.7004 - val_acc: 0.7885\n",
      "Epoch 95/300\n",
      "24420/24420 [==============================] - 1s 44us/step - loss: 1.3716 - acc: 0.8458 - val_loss: 1.7145 - val_acc: 0.7861\n",
      "Epoch 96/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 1.3700 - acc: 0.8457 - val_loss: 1.7145 - val_acc: 0.7875\n",
      "Epoch 97/300\n",
      "24420/24420 [==============================] - 1s 33us/step - loss: 1.3692 - acc: 0.8468 - val_loss: 1.7402 - val_acc: 0.7791\n",
      "Epoch 98/300\n",
      "24420/24420 [==============================] - 1s 34us/step - loss: 1.3679 - acc: 0.8475 - val_loss: 1.7116 - val_acc: 0.7832\n",
      "Epoch 99/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 1.3687 - acc: 0.8453 - val_loss: 1.7138 - val_acc: 0.7836\n",
      "Epoch 100/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 1.3679 - acc: 0.8470 - val_loss: 1.7051 - val_acc: 0.7860\n",
      "Epoch 101/300\n",
      "24420/24420 [==============================] - 1s 33us/step - loss: 1.3691 - acc: 0.8465 - val_loss: 1.7292 - val_acc: 0.7849\n",
      "Epoch 102/300\n",
      "24420/24420 [==============================] - 1s 33us/step - loss: 1.3669 - acc: 0.8472 - val_loss: 1.7178 - val_acc: 0.7860\n",
      "Epoch 103/300\n",
      "24420/24420 [==============================] - 1s 34us/step - loss: 1.3655 - acc: 0.8473 - val_loss: 1.7552 - val_acc: 0.7848\n",
      "Epoch 104/300\n",
      "24420/24420 [==============================] - 1s 34us/step - loss: 1.3654 - acc: 0.8490 - val_loss: 1.7578 - val_acc: 0.7802\n",
      "Epoch 105/300\n",
      "24420/24420 [==============================] - 1s 34us/step - loss: 1.3654 - acc: 0.8483 - val_loss: 1.7557 - val_acc: 0.7881\n",
      "Epoch 106/300\n",
      "24420/24420 [==============================] - 1s 34us/step - loss: 1.3664 - acc: 0.8484 - val_loss: 1.7166 - val_acc: 0.7857\n",
      "Epoch 107/300\n",
      "24420/24420 [==============================] - 1s 34us/step - loss: 1.3658 - acc: 0.8476 - val_loss: 1.7630 - val_acc: 0.7914\n",
      "Epoch 108/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 1.3641 - acc: 0.8483 - val_loss: 1.7177 - val_acc: 0.7822\n",
      "Epoch 109/300\n",
      "24420/24420 [==============================] - 1s 34us/step - loss: 1.3660 - acc: 0.8489 - val_loss: 1.7680 - val_acc: 0.7836\n",
      "Epoch 110/300\n",
      "24420/24420 [==============================] - 1s 34us/step - loss: 1.3620 - acc: 0.8499 - val_loss: 1.7543 - val_acc: 0.7847\n",
      "Epoch 111/300\n",
      "24420/24420 [==============================] - 1s 34us/step - loss: 1.3630 - acc: 0.8501 - val_loss: 1.7380 - val_acc: 0.7844\n",
      "Epoch 112/300\n",
      "24420/24420 [==============================] - 1s 34us/step - loss: 1.3619 - acc: 0.8494 - val_loss: 1.7715 - val_acc: 0.7793\n",
      "Epoch 113/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 1.3625 - acc: 0.8492 - val_loss: 1.7398 - val_acc: 0.7830\n",
      "Epoch 114/300\n",
      "24420/24420 [==============================] - 1s 34us/step - loss: 1.3598 - acc: 0.8510 - val_loss: 1.7718 - val_acc: 0.7864\n",
      "Epoch 115/300\n",
      "24420/24420 [==============================] - 1s 34us/step - loss: 1.3618 - acc: 0.8496 - val_loss: 1.7662 - val_acc: 0.7837\n",
      "Epoch 116/300\n",
      "24420/24420 [==============================] - 1s 34us/step - loss: 1.3628 - acc: 0.8492 - val_loss: 1.7572 - val_acc: 0.7849\n",
      "Epoch 117/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 1.3604 - acc: 0.8522 - val_loss: 1.7555 - val_acc: 0.7834\n",
      "Epoch 118/300\n",
      "24420/24420 [==============================] - 1s 34us/step - loss: 1.3593 - acc: 0.8504 - val_loss: 1.7420 - val_acc: 0.7789\n",
      "Epoch 119/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 1.3606 - acc: 0.8506 - val_loss: 1.7592 - val_acc: 0.7802\n",
      "Epoch 120/300\n",
      "24420/24420 [==============================] - 1s 34us/step - loss: 1.3588 - acc: 0.8505 - val_loss: 1.7795 - val_acc: 0.7800\n",
      "Epoch 121/300\n",
      "24420/24420 [==============================] - 1s 34us/step - loss: 1.3611 - acc: 0.8500 - val_loss: 1.7921 - val_acc: 0.7802\n",
      "Epoch 122/300\n",
      "24420/24420 [==============================] - 1s 34us/step - loss: 1.3603 - acc: 0.8511 - val_loss: 1.7670 - val_acc: 0.7830\n",
      "Epoch 123/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 1.3571 - acc: 0.8507 - val_loss: 1.7762 - val_acc: 0.7812\n",
      "Epoch 124/300\n",
      "24420/24420 [==============================] - 1s 34us/step - loss: 1.3604 - acc: 0.8505 - val_loss: 1.7814 - val_acc: 0.7838\n",
      "Epoch 125/300\n",
      "24420/24420 [==============================] - 1s 34us/step - loss: 1.3597 - acc: 0.8514 - val_loss: 1.7882 - val_acc: 0.7823\n",
      "Epoch 126/300\n",
      "24420/24420 [==============================] - 1s 34us/step - loss: 1.3584 - acc: 0.8497 - val_loss: 1.7774 - val_acc: 0.7839\n",
      "Epoch 127/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 1.3571 - acc: 0.8507 - val_loss: 1.7508 - val_acc: 0.7821\n",
      "Epoch 128/300\n",
      "24420/24420 [==============================] - 1s 34us/step - loss: 1.3568 - acc: 0.8528 - val_loss: 1.7969 - val_acc: 0.7801\n",
      "Epoch 129/300\n",
      "24420/24420 [==============================] - 1s 34us/step - loss: 1.3566 - acc: 0.8517 - val_loss: 1.8288 - val_acc: 0.7852\n",
      "Epoch 130/300\n",
      "24420/24420 [==============================] - 1s 34us/step - loss: 1.3587 - acc: 0.8510 - val_loss: 1.7652 - val_acc: 0.7790\n",
      "Epoch 131/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 1.3571 - acc: 0.8517 - val_loss: 1.7742 - val_acc: 0.7806\n",
      "Epoch 132/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 1.3545 - acc: 0.8527 - val_loss: 1.7696 - val_acc: 0.7795\n",
      "Epoch 133/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 1.3556 - acc: 0.8537 - val_loss: 1.7883 - val_acc: 0.7823\n",
      "Epoch 134/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 1.3544 - acc: 0.8530 - val_loss: 1.7984 - val_acc: 0.7811\n",
      "Epoch 135/300\n",
      "24420/24420 [==============================] - 1s 34us/step - loss: 1.3566 - acc: 0.8514 - val_loss: 1.8090 - val_acc: 0.7798\n",
      "Epoch 136/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 1.3555 - acc: 0.8532 - val_loss: 1.8091 - val_acc: 0.7784\n",
      "Epoch 137/300\n",
      "24420/24420 [==============================] - 1s 34us/step - loss: 1.3567 - acc: 0.8533 - val_loss: 1.7902 - val_acc: 0.7841\n",
      "Epoch 138/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 1.3542 - acc: 0.8520 - val_loss: 1.7976 - val_acc: 0.7820\n",
      "Epoch 139/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 1.3548 - acc: 0.8531 - val_loss: 1.7921 - val_acc: 0.7816\n",
      "Epoch 140/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 1.3537 - acc: 0.8528 - val_loss: 1.8089 - val_acc: 0.7822\n",
      "Epoch 141/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 1.3543 - acc: 0.8536 - val_loss: 1.8324 - val_acc: 0.7815\n",
      "Epoch 142/300\n",
      "24420/24420 [==============================] - 1s 34us/step - loss: 1.3563 - acc: 0.8529 - val_loss: 1.7829 - val_acc: 0.7804\n",
      "Epoch 143/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 1.3518 - acc: 0.8538 - val_loss: 1.8205 - val_acc: 0.7811\n",
      "Epoch 144/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 1.3539 - acc: 0.8529 - val_loss: 1.8257 - val_acc: 0.7838\n",
      "Epoch 145/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 1.3529 - acc: 0.8530 - val_loss: 1.7891 - val_acc: 0.7805\n",
      "Epoch 146/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 1.3545 - acc: 0.8541 - val_loss: 1.7736 - val_acc: 0.7853\n",
      "Epoch 147/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 1.3528 - acc: 0.8536 - val_loss: 1.8300 - val_acc: 0.7805\n",
      "Epoch 148/300\n",
      "24420/24420 [==============================] - 1s 34us/step - loss: 1.3529 - acc: 0.8537 - val_loss: 1.8125 - val_acc: 0.7742\n",
      "Epoch 149/300\n",
      "24420/24420 [==============================] - 1s 34us/step - loss: 1.3513 - acc: 0.8543 - val_loss: 1.8213 - val_acc: 0.7847\n",
      "Epoch 150/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 1.3508 - acc: 0.8567 - val_loss: 1.8231 - val_acc: 0.7772\n",
      "Epoch 151/300\n",
      "24420/24420 [==============================] - 1s 34us/step - loss: 1.3540 - acc: 0.8530 - val_loss: 1.8313 - val_acc: 0.7823\n",
      "Epoch 152/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 1.3516 - acc: 0.8548 - val_loss: 1.8040 - val_acc: 0.7809\n",
      "Epoch 153/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 1.3493 - acc: 0.8556 - val_loss: 1.8335 - val_acc: 0.7809\n",
      "Epoch 154/300\n",
      "24420/24420 [==============================] - 1s 34us/step - loss: 1.3508 - acc: 0.8547 - val_loss: 1.8096 - val_acc: 0.7782\n",
      "Epoch 155/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 1.3477 - acc: 0.8561 - val_loss: 1.8059 - val_acc: 0.7839\n",
      "Epoch 156/300\n",
      "24420/24420 [==============================] - 1s 34us/step - loss: 1.3508 - acc: 0.8565 - val_loss: 1.8203 - val_acc: 0.7818\n",
      "Epoch 157/300\n",
      "24420/24420 [==============================] - 1s 34us/step - loss: 1.3496 - acc: 0.8554 - val_loss: 1.7998 - val_acc: 0.7823\n",
      "Epoch 158/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 1.3526 - acc: 0.8537 - val_loss: 1.8004 - val_acc: 0.7775\n",
      "Epoch 159/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 1.3503 - acc: 0.8547 - val_loss: 1.7958 - val_acc: 0.7822\n",
      "Epoch 160/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 1.3530 - acc: 0.8544 - val_loss: 1.8288 - val_acc: 0.7782\n",
      "Epoch 161/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 1.3478 - acc: 0.8557 - val_loss: 1.7960 - val_acc: 0.7789\n",
      "Epoch 162/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.3482 - acc: 0.8562 - val_loss: 1.8078 - val_acc: 0.7798\n",
      "Epoch 163/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 1.3494 - acc: 0.8551 - val_loss: 1.8095 - val_acc: 0.7842\n",
      "Epoch 164/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 1.3494 - acc: 0.8550 - val_loss: 1.8381 - val_acc: 0.7809\n",
      "Epoch 165/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 1.3496 - acc: 0.8560 - val_loss: 1.8150 - val_acc: 0.7755\n",
      "Epoch 166/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 1.3481 - acc: 0.8559 - val_loss: 1.8077 - val_acc: 0.7804\n",
      "Epoch 167/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 1.3471 - acc: 0.8552 - val_loss: 1.8162 - val_acc: 0.7787\n",
      "Epoch 168/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 1.3484 - acc: 0.8558 - val_loss: 1.8183 - val_acc: 0.7814\n",
      "Epoch 169/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 1.3553 - acc: 0.8538 - val_loss: 1.8546 - val_acc: 0.7748\n",
      "Epoch 170/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 1.3469 - acc: 0.8563 - val_loss: 1.8575 - val_acc: 0.7790\n",
      "Epoch 171/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 1.3457 - acc: 0.8558 - val_loss: 1.8421 - val_acc: 0.7778\n",
      "Epoch 172/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 1.3472 - acc: 0.8550 - val_loss: 1.8383 - val_acc: 0.7809\n",
      "Epoch 173/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 1.3482 - acc: 0.8574 - val_loss: 1.8301 - val_acc: 0.7798\n",
      "Epoch 174/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 1.3466 - acc: 0.8570 - val_loss: 1.8583 - val_acc: 0.7771\n",
      "Epoch 175/300\n",
      "24420/24420 [==============================] - 1s 34us/step - loss: 1.3474 - acc: 0.8566 - val_loss: 1.8159 - val_acc: 0.7761\n",
      "Epoch 176/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 1.3463 - acc: 0.8571 - val_loss: 1.8481 - val_acc: 0.7778\n",
      "Epoch 177/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 1.3467 - acc: 0.8565 - val_loss: 1.8621 - val_acc: 0.7801\n",
      "Epoch 178/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 1.3445 - acc: 0.8574 - val_loss: 1.8386 - val_acc: 0.7762\n",
      "Epoch 179/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 1.3466 - acc: 0.8561 - val_loss: 1.8432 - val_acc: 0.7832\n",
      "Epoch 180/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 1.3491 - acc: 0.8565 - val_loss: 1.8430 - val_acc: 0.7783\n",
      "Epoch 181/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 1.3448 - acc: 0.8579 - val_loss: 1.8390 - val_acc: 0.7817\n",
      "Epoch 182/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 1.3427 - acc: 0.8590 - val_loss: 1.8454 - val_acc: 0.7802\n",
      "Epoch 183/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 1.3464 - acc: 0.8562 - val_loss: 1.8523 - val_acc: 0.7799\n",
      "Epoch 184/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 1.3461 - acc: 0.8570 - val_loss: 1.8395 - val_acc: 0.7777\n",
      "Epoch 185/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 1.3455 - acc: 0.8568 - val_loss: 1.8377 - val_acc: 0.7833\n",
      "Epoch 186/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 1.3447 - acc: 0.8576 - val_loss: 1.8399 - val_acc: 0.7762\n",
      "Epoch 187/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.3461 - acc: 0.8564 - val_loss: 1.8455 - val_acc: 0.7834\n",
      "Epoch 188/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 1.3466 - acc: 0.8565 - val_loss: 1.8410 - val_acc: 0.7783\n",
      "Epoch 189/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 1.3446 - acc: 0.8571 - val_loss: 1.8416 - val_acc: 0.7804\n",
      "Epoch 190/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 1.3437 - acc: 0.8578 - val_loss: 1.8524 - val_acc: 0.7780\n",
      "Epoch 191/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 1.3426 - acc: 0.8592 - val_loss: 1.8273 - val_acc: 0.7825\n",
      "Epoch 192/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 1.3453 - acc: 0.8576 - val_loss: 1.8496 - val_acc: 0.7761\n",
      "Epoch 193/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 1.3493 - acc: 0.8565 - val_loss: 1.8585 - val_acc: 0.7788\n",
      "Epoch 194/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 1.3422 - acc: 0.8577 - val_loss: 1.8415 - val_acc: 0.7804\n",
      "Epoch 195/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 1.3422 - acc: 0.8586 - val_loss: 1.8796 - val_acc: 0.7764\n",
      "Epoch 196/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 1.3422 - acc: 0.8591 - val_loss: 1.8637 - val_acc: 0.7831\n",
      "Epoch 197/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 1.3422 - acc: 0.8578 - val_loss: 1.8726 - val_acc: 0.7842\n",
      "Epoch 198/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 1.3450 - acc: 0.8577 - val_loss: 1.8287 - val_acc: 0.7794\n",
      "Epoch 199/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 1.3434 - acc: 0.8575 - val_loss: 1.8504 - val_acc: 0.7775\n",
      "Epoch 200/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 1.3435 - acc: 0.8570 - val_loss: 1.8411 - val_acc: 0.7755\n",
      "Epoch 201/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 1.3436 - acc: 0.8578 - val_loss: 1.8308 - val_acc: 0.7831\n",
      "Epoch 202/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 1.3437 - acc: 0.8574 - val_loss: 1.8760 - val_acc: 0.7772\n",
      "Epoch 203/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 1.3409 - acc: 0.8592 - val_loss: 1.8538 - val_acc: 0.7801\n",
      "Epoch 204/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 1.3421 - acc: 0.8578 - val_loss: 1.8546 - val_acc: 0.7830\n",
      "Epoch 205/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 1.3417 - acc: 0.8589 - val_loss: 1.8635 - val_acc: 0.7807\n",
      "Epoch 206/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 1.3453 - acc: 0.8568 - val_loss: 1.8655 - val_acc: 0.7758\n",
      "Epoch 207/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 1.3409 - acc: 0.8587 - val_loss: 1.8552 - val_acc: 0.7809\n",
      "Epoch 208/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 1.3416 - acc: 0.8579 - val_loss: 1.8870 - val_acc: 0.7750\n",
      "Epoch 209/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 1.3432 - acc: 0.8575 - val_loss: 1.8478 - val_acc: 0.7795\n",
      "Epoch 210/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 1.3395 - acc: 0.8599 - val_loss: 1.8252 - val_acc: 0.7826\n",
      "Epoch 211/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 1.3429 - acc: 0.8575 - val_loss: 1.8494 - val_acc: 0.7782\n",
      "Epoch 212/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 1.3418 - acc: 0.8594 - val_loss: 1.8121 - val_acc: 0.7818\n",
      "Epoch 213/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 1.3417 - acc: 0.8581 - val_loss: 1.9328 - val_acc: 0.7793\n",
      "Epoch 214/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 1.3430 - acc: 0.8574 - val_loss: 1.8460 - val_acc: 0.7775\n",
      "Epoch 215/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 1.3391 - acc: 0.8595 - val_loss: 1.8724 - val_acc: 0.7838\n",
      "Epoch 216/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 1.3396 - acc: 0.8593 - val_loss: 1.8844 - val_acc: 0.7811\n",
      "Epoch 217/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 1.3416 - acc: 0.8595 - val_loss: 1.9077 - val_acc: 0.7753\n",
      "Epoch 218/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 1.3420 - acc: 0.8573 - val_loss: 1.8549 - val_acc: 0.7838\n",
      "Epoch 219/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 1.3404 - acc: 0.8594 - val_loss: 1.8773 - val_acc: 0.7788\n",
      "Epoch 220/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 1.3404 - acc: 0.8600 - val_loss: 1.8481 - val_acc: 0.7853\n",
      "Epoch 221/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 1.3409 - acc: 0.8588 - val_loss: 1.8873 - val_acc: 0.7794\n",
      "Epoch 222/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.3443 - acc: 0.8588 - val_loss: 1.8802 - val_acc: 0.7790\n",
      "Epoch 223/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 1.3423 - acc: 0.8584 - val_loss: 1.8917 - val_acc: 0.7791\n",
      "Epoch 224/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 1.3406 - acc: 0.8593 - val_loss: 1.8721 - val_acc: 0.7778\n",
      "Epoch 225/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.3408 - acc: 0.8586 - val_loss: 1.8681 - val_acc: 0.7828\n",
      "Epoch 226/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 1.3382 - acc: 0.8603 - val_loss: 1.8892 - val_acc: 0.7783\n",
      "Epoch 227/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.3385 - acc: 0.8587 - val_loss: 1.8719 - val_acc: 0.7788\n",
      "Epoch 228/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.3413 - acc: 0.8593 - val_loss: 1.8444 - val_acc: 0.7817\n",
      "Epoch 229/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 1.3407 - acc: 0.8593 - val_loss: 1.8647 - val_acc: 0.7825\n",
      "Epoch 230/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 1.3398 - acc: 0.8594 - val_loss: 1.8633 - val_acc: 0.7761\n",
      "Epoch 231/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.3383 - acc: 0.8600 - val_loss: 1.8551 - val_acc: 0.7788\n",
      "Epoch 232/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.3392 - acc: 0.8582 - val_loss: 1.9186 - val_acc: 0.7775\n",
      "Epoch 233/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 1.3396 - acc: 0.8592 - val_loss: 1.8669 - val_acc: 0.7761\n",
      "Epoch 234/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.3399 - acc: 0.8594 - val_loss: 1.8545 - val_acc: 0.7787\n",
      "Epoch 235/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.3394 - acc: 0.8581 - val_loss: 1.9036 - val_acc: 0.7818\n",
      "Epoch 236/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.3404 - acc: 0.8591 - val_loss: 1.8525 - val_acc: 0.7759\n",
      "Epoch 237/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.3364 - acc: 0.8620 - val_loss: 1.8456 - val_acc: 0.7788\n",
      "Epoch 238/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.3388 - acc: 0.8596 - val_loss: 1.8871 - val_acc: 0.7817\n",
      "Epoch 239/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.3402 - acc: 0.8594 - val_loss: 1.9038 - val_acc: 0.7758\n",
      "Epoch 240/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.3395 - acc: 0.8589 - val_loss: 1.8838 - val_acc: 0.7809\n",
      "Epoch 241/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.3385 - acc: 0.8600 - val_loss: 1.8843 - val_acc: 0.7789\n",
      "Epoch 242/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.3371 - acc: 0.8607 - val_loss: 1.8811 - val_acc: 0.7799\n",
      "Epoch 243/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.3412 - acc: 0.8596 - val_loss: 1.8637 - val_acc: 0.7823\n",
      "Epoch 244/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.3373 - acc: 0.8604 - val_loss: 1.9113 - val_acc: 0.7784\n",
      "Epoch 245/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.3376 - acc: 0.8604 - val_loss: 1.9008 - val_acc: 0.7724\n",
      "Epoch 246/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.3425 - acc: 0.8589 - val_loss: 1.8972 - val_acc: 0.7828\n",
      "Epoch 247/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.3369 - acc: 0.8587 - val_loss: 1.9056 - val_acc: 0.7833\n",
      "Epoch 248/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.3368 - acc: 0.8610 - val_loss: 1.8883 - val_acc: 0.7821\n",
      "Epoch 249/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.3374 - acc: 0.8613 - val_loss: 1.8933 - val_acc: 0.7809\n",
      "Epoch 250/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.3370 - acc: 0.8599 - val_loss: 1.9078 - val_acc: 0.7785\n",
      "Epoch 251/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.3393 - acc: 0.8581 - val_loss: 1.9120 - val_acc: 0.7816\n",
      "Epoch 252/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.3378 - acc: 0.8590 - val_loss: 1.9001 - val_acc: 0.7809\n",
      "Epoch 253/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.3387 - acc: 0.8602 - val_loss: 1.8613 - val_acc: 0.7802\n",
      "Epoch 254/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.3376 - acc: 0.8605 - val_loss: 1.9033 - val_acc: 0.7815\n",
      "Epoch 255/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.3361 - acc: 0.8621 - val_loss: 1.9103 - val_acc: 0.7798\n",
      "Epoch 256/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.3363 - acc: 0.8602 - val_loss: 1.9312 - val_acc: 0.7735\n",
      "Epoch 257/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.3378 - acc: 0.8611 - val_loss: 1.9004 - val_acc: 0.7788\n",
      "Epoch 258/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.3359 - acc: 0.8610 - val_loss: 1.9181 - val_acc: 0.7791\n",
      "Epoch 259/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.3381 - acc: 0.8605 - val_loss: 1.8617 - val_acc: 0.7825\n",
      "Epoch 260/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.3339 - acc: 0.8621 - val_loss: 1.9183 - val_acc: 0.7748\n",
      "Epoch 261/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.3402 - acc: 0.8581 - val_loss: 1.9115 - val_acc: 0.7745\n",
      "Epoch 262/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.3366 - acc: 0.8606 - val_loss: 1.9393 - val_acc: 0.7800\n",
      "Epoch 263/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.3364 - acc: 0.8608 - val_loss: 1.8936 - val_acc: 0.7807\n",
      "Epoch 264/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.3367 - acc: 0.8600 - val_loss: 1.9374 - val_acc: 0.7814\n",
      "Epoch 265/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.3369 - acc: 0.8610 - val_loss: 1.8923 - val_acc: 0.7830\n",
      "Epoch 266/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.3362 - acc: 0.8616 - val_loss: 1.8840 - val_acc: 0.7827\n",
      "Epoch 267/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.3362 - acc: 0.8594 - val_loss: 1.9115 - val_acc: 0.7785\n",
      "Epoch 268/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.3397 - acc: 0.8610 - val_loss: 1.9013 - val_acc: 0.7799\n",
      "Epoch 269/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.3367 - acc: 0.8612 - val_loss: 1.8904 - val_acc: 0.7838\n",
      "Epoch 270/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.3359 - acc: 0.8613 - val_loss: 1.9143 - val_acc: 0.7778\n",
      "Epoch 271/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.3342 - acc: 0.8609 - val_loss: 1.9145 - val_acc: 0.7763\n",
      "Epoch 272/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.3361 - acc: 0.8600 - val_loss: 1.8699 - val_acc: 0.7810\n",
      "Epoch 273/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.3369 - acc: 0.8598 - val_loss: 1.8854 - val_acc: 0.7811\n",
      "Epoch 274/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.3361 - acc: 0.8619 - val_loss: 1.9000 - val_acc: 0.7740\n",
      "Epoch 275/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.3372 - acc: 0.8602 - val_loss: 1.9182 - val_acc: 0.7807\n",
      "Epoch 276/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.3358 - acc: 0.8627 - val_loss: 1.9004 - val_acc: 0.7782\n",
      "Epoch 277/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.3359 - acc: 0.8610 - val_loss: 1.9230 - val_acc: 0.7798\n",
      "Epoch 278/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.3345 - acc: 0.8601 - val_loss: 1.8922 - val_acc: 0.7782\n",
      "Epoch 279/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.3345 - acc: 0.8613 - val_loss: 1.9157 - val_acc: 0.7774\n",
      "Epoch 280/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.3359 - acc: 0.8617 - val_loss: 1.9099 - val_acc: 0.7796\n",
      "Epoch 281/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.3374 - acc: 0.8606 - val_loss: 1.9111 - val_acc: 0.7787\n",
      "Epoch 282/300\n",
      "24420/24420 [==============================] - 1s 39us/step - loss: 1.3344 - acc: 0.8613 - val_loss: 1.9101 - val_acc: 0.7772\n",
      "Epoch 283/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.3374 - acc: 0.8614 - val_loss: 1.9188 - val_acc: 0.7816\n",
      "Epoch 284/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.3395 - acc: 0.8602 - val_loss: 1.9126 - val_acc: 0.7772\n",
      "Epoch 285/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.3345 - acc: 0.8609 - val_loss: 1.9280 - val_acc: 0.7804\n",
      "Epoch 286/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.3323 - acc: 0.8617 - val_loss: 1.9300 - val_acc: 0.7814\n",
      "Epoch 287/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.3341 - acc: 0.8605 - val_loss: 1.8896 - val_acc: 0.7826\n",
      "Epoch 288/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.3355 - acc: 0.8593 - val_loss: 1.9333 - val_acc: 0.7784\n",
      "Epoch 289/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.3350 - acc: 0.8628 - val_loss: 1.9139 - val_acc: 0.7804\n",
      "Epoch 290/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.3349 - acc: 0.8616 - val_loss: 1.9048 - val_acc: 0.7789\n",
      "Epoch 291/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.3365 - acc: 0.8602 - val_loss: 1.9318 - val_acc: 0.7818\n",
      "Epoch 292/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.3384 - acc: 0.8604 - val_loss: 1.9273 - val_acc: 0.7780\n",
      "Epoch 293/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.3337 - acc: 0.8613 - val_loss: 1.9227 - val_acc: 0.7806\n",
      "Epoch 294/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.3348 - acc: 0.8620 - val_loss: 1.9202 - val_acc: 0.7785\n",
      "Epoch 295/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.3322 - acc: 0.8629 - val_loss: 1.8849 - val_acc: 0.7788\n",
      "Epoch 296/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.3334 - acc: 0.8628 - val_loss: 1.9082 - val_acc: 0.7789\n",
      "Epoch 297/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.3334 - acc: 0.8618 - val_loss: 1.9135 - val_acc: 0.7777\n",
      "Epoch 298/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.3358 - acc: 0.8618 - val_loss: 1.9052 - val_acc: 0.7783\n",
      "Epoch 299/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.3341 - acc: 0.8619 - val_loss: 1.9260 - val_acc: 0.7787\n",
      "Epoch 300/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.3338 - acc: 0.8607 - val_loss: 1.8861 - val_acc: 0.7811\n"
     ]
    }
   ],
   "source": [
    "model = build_model(X_train, Y_train, X_val, Y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report classification accuracy and ∆ DP on the test set for your trained classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is:  0.7774706713017356\n"
     ]
    }
   ],
   "source": [
    "print('accuracy is: ', evaluate_model(model, X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12024473069228425"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = predict(model, X_test)\n",
    "compute_delta_DP(y_hat, a_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove the 10 attributes that you identified in the first part as being most highly correlated with A, and retrain. Report accuracy and ∆ DP on this retrained classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top_attributes = [att for att in top_10['income'].index]\n",
    "df_without_10 = df.drop(top_attributes, axis=1)\n",
    "X_train = df_without_10\n",
    "X_test = df_test.drop(top_attributes, axis=1)\n",
    "\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "\n",
    "\n",
    "#train_ind = np.random.choice(X_train.shape[0], 3*X_train.shape[0]//4, replace=False)\n",
    "X_train = X_train[train_ind]\n",
    "X_val= df_without_10.drop(train_ind, axis=0)\n",
    "X_val = np.array(X_val)\n",
    "\n",
    "# X_train = scaling_data(X_train)\n",
    "# X_val = scaling_data(X_val)\n",
    "# X_test = scaling_data(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24420 samples, validate on 8141 samples\n",
      "Epoch 1/300\n",
      "24420/24420 [==============================] - 1s 46us/step - loss: 0.7407 - acc: 0.8115 - val_loss: 0.7434 - val_acc: 0.8165\n",
      "Epoch 2/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 0.7213 - acc: 0.8221 - val_loss: 0.7344 - val_acc: 0.8194\n",
      "Epoch 3/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.7155 - acc: 0.8241 - val_loss: 0.7355 - val_acc: 0.8171\n",
      "Epoch 4/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7096 - acc: 0.8266 - val_loss: 0.7386 - val_acc: 0.8202\n",
      "Epoch 5/300\n",
      "24420/24420 [==============================] - 1s 34us/step - loss: 0.7040 - acc: 0.8295 - val_loss: 0.7499 - val_acc: 0.8197\n",
      "Epoch 6/300\n",
      "24420/24420 [==============================] - 1s 34us/step - loss: 0.6989 - acc: 0.8327 - val_loss: 0.7494 - val_acc: 0.8188\n",
      "Epoch 7/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 0.6934 - acc: 0.8346 - val_loss: 0.7498 - val_acc: 0.8169\n",
      "Epoch 8/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 0.6869 - acc: 0.8364 - val_loss: 0.7532 - val_acc: 0.8156\n",
      "Epoch 9/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 0.6805 - acc: 0.8385 - val_loss: 0.7805 - val_acc: 0.8048\n",
      "Epoch 10/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.6756 - acc: 0.8394 - val_loss: 0.7745 - val_acc: 0.8122\n",
      "Epoch 11/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.6702 - acc: 0.8416 - val_loss: 0.7820 - val_acc: 0.8135\n",
      "Epoch 12/300\n",
      "24420/24420 [==============================] - 1s 34us/step - loss: 0.6654 - acc: 0.8425 - val_loss: 0.7956 - val_acc: 0.8139\n",
      "Epoch 13/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 0.6607 - acc: 0.8450 - val_loss: 0.7983 - val_acc: 0.8121\n",
      "Epoch 14/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 0.6551 - acc: 0.8469 - val_loss: 0.8146 - val_acc: 0.8112\n",
      "Epoch 15/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.6528 - acc: 0.8481 - val_loss: 0.8170 - val_acc: 0.8139\n",
      "Epoch 16/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.6484 - acc: 0.8507 - val_loss: 0.8349 - val_acc: 0.8114\n",
      "Epoch 17/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 0.6451 - acc: 0.8523 - val_loss: 0.8407 - val_acc: 0.8014\n",
      "Epoch 18/300\n",
      "24420/24420 [==============================] - 1s 34us/step - loss: 0.6427 - acc: 0.8516 - val_loss: 0.8573 - val_acc: 0.8084\n",
      "Epoch 19/300\n",
      "24420/24420 [==============================] - 1s 34us/step - loss: 0.6402 - acc: 0.8527 - val_loss: 0.8584 - val_acc: 0.8056\n",
      "Epoch 20/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 0.6383 - acc: 0.8546 - val_loss: 0.8772 - val_acc: 0.8054\n",
      "Epoch 21/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 0.6358 - acc: 0.8552 - val_loss: 0.8638 - val_acc: 0.8103\n",
      "Epoch 22/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 0.6333 - acc: 0.8563 - val_loss: 0.8796 - val_acc: 0.8081\n",
      "Epoch 23/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 0.6311 - acc: 0.8573 - val_loss: 0.8863 - val_acc: 0.8051\n",
      "Epoch 24/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 0.6302 - acc: 0.8586 - val_loss: 0.8935 - val_acc: 0.8049\n",
      "Epoch 25/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.6288 - acc: 0.8571 - val_loss: 0.9060 - val_acc: 0.8042\n",
      "Epoch 26/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.6265 - acc: 0.8593 - val_loss: 0.9174 - val_acc: 0.8030\n",
      "Epoch 27/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.6244 - acc: 0.8615 - val_loss: 0.9211 - val_acc: 0.8041\n",
      "Epoch 28/300\n",
      "24420/24420 [==============================] - 1s 34us/step - loss: 0.6241 - acc: 0.8604 - val_loss: 0.9236 - val_acc: 0.8076\n",
      "Epoch 29/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 0.6221 - acc: 0.8602 - val_loss: 0.9281 - val_acc: 0.8100\n",
      "Epoch 30/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 0.6212 - acc: 0.8606 - val_loss: 0.9279 - val_acc: 0.8035\n",
      "Epoch 31/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 0.6210 - acc: 0.8605 - val_loss: 0.9298 - val_acc: 0.8054\n",
      "Epoch 32/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 0.6206 - acc: 0.8602 - val_loss: 0.9747 - val_acc: 0.8033\n",
      "Epoch 33/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 0.6187 - acc: 0.8618 - val_loss: 0.9478 - val_acc: 0.8047\n",
      "Epoch 34/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 0.6172 - acc: 0.8608 - val_loss: 0.9570 - val_acc: 0.8040\n",
      "Epoch 35/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 0.6174 - acc: 0.8614 - val_loss: 0.9513 - val_acc: 0.8043\n",
      "Epoch 36/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 0.6177 - acc: 0.8631 - val_loss: 0.9616 - val_acc: 0.8067\n",
      "Epoch 37/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 0.6146 - acc: 0.8620 - val_loss: 0.9710 - val_acc: 0.8027\n",
      "Epoch 38/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.6146 - acc: 0.8627 - val_loss: 0.9606 - val_acc: 0.8021\n",
      "Epoch 39/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.6143 - acc: 0.8620 - val_loss: 0.9848 - val_acc: 0.8025\n",
      "Epoch 40/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.6134 - acc: 0.8628 - val_loss: 0.9922 - val_acc: 0.8000\n",
      "Epoch 41/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.6130 - acc: 0.8630 - val_loss: 0.9916 - val_acc: 0.8057\n",
      "Epoch 42/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 0.6130 - acc: 0.8633 - val_loss: 1.0101 - val_acc: 0.8000\n",
      "Epoch 43/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.6124 - acc: 0.8637 - val_loss: 1.0111 - val_acc: 0.8087\n",
      "Epoch 44/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.6116 - acc: 0.8635 - val_loss: 0.9817 - val_acc: 0.8021\n",
      "Epoch 45/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.6105 - acc: 0.8641 - val_loss: 1.0131 - val_acc: 0.8022\n",
      "Epoch 46/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 0.6102 - acc: 0.8643 - val_loss: 1.0140 - val_acc: 0.8014\n",
      "Epoch 47/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 0.6112 - acc: 0.8629 - val_loss: 1.0094 - val_acc: 0.7962\n",
      "Epoch 48/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 0.6095 - acc: 0.8648 - val_loss: 1.0182 - val_acc: 0.8024\n",
      "Epoch 49/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.6095 - acc: 0.8641 - val_loss: 1.0292 - val_acc: 0.7993\n",
      "Epoch 50/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 0.6095 - acc: 0.8650 - val_loss: 1.0192 - val_acc: 0.8005\n",
      "Epoch 51/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 0.6088 - acc: 0.8643 - val_loss: 1.0116 - val_acc: 0.8044\n",
      "Epoch 52/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 0.6074 - acc: 0.8650 - val_loss: 1.0170 - val_acc: 0.8013\n",
      "Epoch 53/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.6085 - acc: 0.8644 - val_loss: 1.0399 - val_acc: 0.8064\n",
      "Epoch 54/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 0.6082 - acc: 0.8644 - val_loss: 1.0361 - val_acc: 0.7988\n",
      "Epoch 55/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.6066 - acc: 0.8643 - val_loss: 1.0442 - val_acc: 0.8011\n",
      "Epoch 56/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.6071 - acc: 0.8643 - val_loss: 1.0282 - val_acc: 0.8028\n",
      "Epoch 57/300\n",
      "24420/24420 [==============================] - 1s 34us/step - loss: 0.6068 - acc: 0.8653 - val_loss: 1.0417 - val_acc: 0.7955\n",
      "Epoch 58/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 0.6069 - acc: 0.8641 - val_loss: 1.0455 - val_acc: 0.8011\n",
      "Epoch 59/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 0.6065 - acc: 0.8649 - val_loss: 1.0427 - val_acc: 0.8013\n",
      "Epoch 60/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 0.6050 - acc: 0.8646 - val_loss: 1.0798 - val_acc: 0.8035\n",
      "Epoch 61/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 0.6053 - acc: 0.8655 - val_loss: 1.0529 - val_acc: 0.7999\n",
      "Epoch 62/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.6047 - acc: 0.8645 - val_loss: 1.0229 - val_acc: 0.8032\n",
      "Epoch 63/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.6059 - acc: 0.8655 - val_loss: 1.0486 - val_acc: 0.7993\n",
      "Epoch 64/300\n",
      "24420/24420 [==============================] - 1s 34us/step - loss: 0.6048 - acc: 0.8644 - val_loss: 1.0644 - val_acc: 0.8068\n",
      "Epoch 65/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.6044 - acc: 0.8654 - val_loss: 1.0917 - val_acc: 0.8042\n",
      "Epoch 66/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.6040 - acc: 0.8663 - val_loss: 1.0643 - val_acc: 0.8048\n",
      "Epoch 67/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 0.6046 - acc: 0.8656 - val_loss: 1.0727 - val_acc: 0.8046\n",
      "Epoch 68/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.6039 - acc: 0.8650 - val_loss: 1.0722 - val_acc: 0.7992\n",
      "Epoch 69/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.6033 - acc: 0.8647 - val_loss: 1.0718 - val_acc: 0.7999\n",
      "Epoch 70/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 0.6037 - acc: 0.8653 - val_loss: 1.0778 - val_acc: 0.8046\n",
      "Epoch 71/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 0.6029 - acc: 0.8649 - val_loss: 1.1006 - val_acc: 0.8008\n",
      "Epoch 72/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.6045 - acc: 0.8649 - val_loss: 1.0883 - val_acc: 0.7986\n",
      "Epoch 73/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 0.6025 - acc: 0.8665 - val_loss: 1.0746 - val_acc: 0.8000\n",
      "Epoch 74/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 0.6026 - acc: 0.8663 - val_loss: 1.0960 - val_acc: 0.8035\n",
      "Epoch 75/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 0.6020 - acc: 0.8665 - val_loss: 1.0943 - val_acc: 0.8022\n",
      "Epoch 76/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 0.6022 - acc: 0.8663 - val_loss: 1.0867 - val_acc: 0.8010\n",
      "Epoch 77/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.6025 - acc: 0.8655 - val_loss: 1.1128 - val_acc: 0.7982\n",
      "Epoch 78/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.6019 - acc: 0.8654 - val_loss: 1.1209 - val_acc: 0.8006\n",
      "Epoch 79/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 0.6015 - acc: 0.8651 - val_loss: 1.1221 - val_acc: 0.8016\n",
      "Epoch 80/300\n",
      "24420/24420 [==============================] - 1s 40us/step - loss: 0.6021 - acc: 0.8663 - val_loss: 1.1197 - val_acc: 0.8025\n",
      "Epoch 81/300\n",
      "24420/24420 [==============================] - 1s 34us/step - loss: 0.6019 - acc: 0.8660 - val_loss: 1.1169 - val_acc: 0.7998\n",
      "Epoch 82/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 0.6023 - acc: 0.8653 - val_loss: 1.1269 - val_acc: 0.8015\n",
      "Epoch 83/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.6013 - acc: 0.8665 - val_loss: 1.1273 - val_acc: 0.7994\n",
      "Epoch 84/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 0.6006 - acc: 0.8664 - val_loss: 1.1163 - val_acc: 0.7966\n",
      "Epoch 85/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.6002 - acc: 0.8669 - val_loss: 1.1286 - val_acc: 0.8030\n",
      "Epoch 86/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 0.6009 - acc: 0.8663 - val_loss: 1.1389 - val_acc: 0.8017\n",
      "Epoch 87/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 0.6008 - acc: 0.8661 - val_loss: 1.1124 - val_acc: 0.7981\n",
      "Epoch 88/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 0.6011 - acc: 0.8664 - val_loss: 1.1156 - val_acc: 0.7982\n",
      "Epoch 89/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.6010 - acc: 0.8663 - val_loss: 1.1486 - val_acc: 0.7977\n",
      "Epoch 90/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.6005 - acc: 0.8655 - val_loss: 1.1429 - val_acc: 0.8008\n",
      "Epoch 91/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.6001 - acc: 0.8659 - val_loss: 1.1315 - val_acc: 0.8005\n",
      "Epoch 92/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 0.5999 - acc: 0.8662 - val_loss: 1.1357 - val_acc: 0.7981\n",
      "Epoch 93/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 0.6020 - acc: 0.8665 - val_loss: 1.1315 - val_acc: 0.8011\n",
      "Epoch 94/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.6026 - acc: 0.8670 - val_loss: 1.1583 - val_acc: 0.8043\n",
      "Epoch 95/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 0.6002 - acc: 0.8671 - val_loss: 1.1393 - val_acc: 0.8030\n",
      "Epoch 96/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5994 - acc: 0.8667 - val_loss: 1.1661 - val_acc: 0.8013\n",
      "Epoch 97/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5987 - acc: 0.8659 - val_loss: 1.1430 - val_acc: 0.8003\n",
      "Epoch 98/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.5987 - acc: 0.8668 - val_loss: 1.1612 - val_acc: 0.7968\n",
      "Epoch 99/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 0.5996 - acc: 0.8664 - val_loss: 1.1741 - val_acc: 0.7998\n",
      "Epoch 100/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 0.5994 - acc: 0.8673 - val_loss: 1.1596 - val_acc: 0.7994\n",
      "Epoch 101/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 0.5995 - acc: 0.8666 - val_loss: 1.1763 - val_acc: 0.7990\n",
      "Epoch 102/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 0.6002 - acc: 0.8670 - val_loss: 1.1611 - val_acc: 0.8011\n",
      "Epoch 103/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 0.6017 - acc: 0.8668 - val_loss: 1.1699 - val_acc: 0.7992\n",
      "Epoch 104/300\n",
      "24420/24420 [==============================] - 1s 39us/step - loss: 0.5983 - acc: 0.8673 - val_loss: 1.1734 - val_acc: 0.8024\n",
      "Epoch 105/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 0.5982 - acc: 0.8668 - val_loss: 1.1858 - val_acc: 0.8025\n",
      "Epoch 106/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 0.5979 - acc: 0.8669 - val_loss: 1.1792 - val_acc: 0.8031\n",
      "Epoch 107/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.6021 - acc: 0.8664 - val_loss: 1.1428 - val_acc: 0.7983\n",
      "Epoch 108/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5992 - acc: 0.8654 - val_loss: 1.1516 - val_acc: 0.8001\n",
      "Epoch 109/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5974 - acc: 0.8665 - val_loss: 1.1821 - val_acc: 0.8025\n",
      "Epoch 110/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5981 - acc: 0.8664 - val_loss: 1.1688 - val_acc: 0.8004\n",
      "Epoch 111/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5983 - acc: 0.8652 - val_loss: 1.1758 - val_acc: 0.8021\n",
      "Epoch 112/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 0.5993 - acc: 0.8661 - val_loss: 1.1824 - val_acc: 0.8036\n",
      "Epoch 113/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 0.6006 - acc: 0.8665 - val_loss: 1.1723 - val_acc: 0.8017\n",
      "Epoch 114/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5978 - acc: 0.8676 - val_loss: 1.1626 - val_acc: 0.7983\n",
      "Epoch 115/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.5978 - acc: 0.8665 - val_loss: 1.1685 - val_acc: 0.7998\n",
      "Epoch 116/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5974 - acc: 0.8676 - val_loss: 1.1584 - val_acc: 0.7965\n",
      "Epoch 117/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 0.5984 - acc: 0.8674 - val_loss: 1.1732 - val_acc: 0.8005\n",
      "Epoch 118/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5982 - acc: 0.8662 - val_loss: 1.1930 - val_acc: 0.7982\n",
      "Epoch 119/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 0.5987 - acc: 0.8661 - val_loss: 1.1909 - val_acc: 0.7992\n",
      "Epoch 120/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5979 - acc: 0.8664 - val_loss: 1.2069 - val_acc: 0.8005\n",
      "Epoch 121/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 0.5973 - acc: 0.8657 - val_loss: 1.2008 - val_acc: 0.8014\n",
      "Epoch 122/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5987 - acc: 0.8671 - val_loss: 1.1951 - val_acc: 0.8016\n",
      "Epoch 123/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 0.5985 - acc: 0.8661 - val_loss: 1.2083 - val_acc: 0.7971\n",
      "Epoch 124/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5976 - acc: 0.8679 - val_loss: 1.2143 - val_acc: 0.7988\n",
      "Epoch 125/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.5971 - acc: 0.8664 - val_loss: 1.1966 - val_acc: 0.7974\n",
      "Epoch 126/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 0.5977 - acc: 0.8681 - val_loss: 1.1930 - val_acc: 0.7986\n",
      "Epoch 127/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 0.5989 - acc: 0.8676 - val_loss: 1.1916 - val_acc: 0.8020\n",
      "Epoch 128/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5977 - acc: 0.8673 - val_loss: 1.2323 - val_acc: 0.7993\n",
      "Epoch 129/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5987 - acc: 0.8666 - val_loss: 1.2019 - val_acc: 0.7993\n",
      "Epoch 130/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5999 - acc: 0.8671 - val_loss: 1.1963 - val_acc: 0.7981\n",
      "Epoch 131/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 0.5967 - acc: 0.8674 - val_loss: 1.2303 - val_acc: 0.7971\n",
      "Epoch 132/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5971 - acc: 0.8663 - val_loss: 1.1772 - val_acc: 0.7972\n",
      "Epoch 133/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5969 - acc: 0.8670 - val_loss: 1.2140 - val_acc: 0.7966\n",
      "Epoch 134/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 0.5973 - acc: 0.8670 - val_loss: 1.2204 - val_acc: 0.8004\n",
      "Epoch 135/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5981 - acc: 0.8676 - val_loss: 1.1969 - val_acc: 0.8000\n",
      "Epoch 136/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5978 - acc: 0.8674 - val_loss: 1.2073 - val_acc: 0.7994\n",
      "Epoch 137/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5969 - acc: 0.8674 - val_loss: 1.2018 - val_acc: 0.7999\n",
      "Epoch 138/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5971 - acc: 0.8676 - val_loss: 1.1976 - val_acc: 0.8048\n",
      "Epoch 139/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5968 - acc: 0.8670 - val_loss: 1.2100 - val_acc: 0.7998\n",
      "Epoch 140/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 0.5966 - acc: 0.8672 - val_loss: 1.2331 - val_acc: 0.8004\n",
      "Epoch 141/300\n",
      "24420/24420 [==============================] - 1s 46us/step - loss: 0.5975 - acc: 0.8674 - val_loss: 1.1960 - val_acc: 0.8015\n",
      "Epoch 142/300\n",
      "24420/24420 [==============================] - 1s 39us/step - loss: 0.5971 - acc: 0.8667 - val_loss: 1.2288 - val_acc: 0.8001\n",
      "Epoch 143/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 0.5962 - acc: 0.8673 - val_loss: 1.2511 - val_acc: 0.8027\n",
      "Epoch 144/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 0.5968 - acc: 0.8676 - val_loss: 1.2458 - val_acc: 0.7997\n",
      "Epoch 145/300\n",
      "24420/24420 [==============================] - 1s 39us/step - loss: 0.5976 - acc: 0.8670 - val_loss: 1.2261 - val_acc: 0.8033\n",
      "Epoch 146/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 0.5987 - acc: 0.8672 - val_loss: 1.2002 - val_acc: 0.8003\n",
      "Epoch 147/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.5984 - acc: 0.8670 - val_loss: 1.2266 - val_acc: 0.7967\n",
      "Epoch 148/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.5965 - acc: 0.8671 - val_loss: 1.2168 - val_acc: 0.8024\n",
      "Epoch 149/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5960 - acc: 0.8677 - val_loss: 1.2392 - val_acc: 0.8036\n",
      "Epoch 150/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 0.5962 - acc: 0.8671 - val_loss: 1.2461 - val_acc: 0.8005\n",
      "Epoch 151/300\n",
      "24420/24420 [==============================] - 1s 39us/step - loss: 0.5959 - acc: 0.8676 - val_loss: 1.2478 - val_acc: 0.8019\n",
      "Epoch 152/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 0.5962 - acc: 0.8676 - val_loss: 1.2600 - val_acc: 0.8009\n",
      "Epoch 153/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5962 - acc: 0.8684 - val_loss: 1.2414 - val_acc: 0.7987\n",
      "Epoch 154/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.5966 - acc: 0.8672 - val_loss: 1.2241 - val_acc: 0.7998\n",
      "Epoch 155/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5962 - acc: 0.8676 - val_loss: 1.2419 - val_acc: 0.7981\n",
      "Epoch 156/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5967 - acc: 0.8677 - val_loss: 1.2281 - val_acc: 0.8011\n",
      "Epoch 157/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5972 - acc: 0.8679 - val_loss: 1.2314 - val_acc: 0.8009\n",
      "Epoch 158/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 0.5960 - acc: 0.8680 - val_loss: 1.2647 - val_acc: 0.8043\n",
      "Epoch 159/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5959 - acc: 0.8679 - val_loss: 1.2366 - val_acc: 0.8006\n",
      "Epoch 160/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5969 - acc: 0.8677 - val_loss: 1.2478 - val_acc: 0.8027\n",
      "Epoch 161/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5964 - acc: 0.8676 - val_loss: 1.2260 - val_acc: 0.8015\n",
      "Epoch 162/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5993 - acc: 0.8674 - val_loss: 1.2313 - val_acc: 0.7994\n",
      "Epoch 163/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5975 - acc: 0.8670 - val_loss: 1.2348 - val_acc: 0.7995\n",
      "Epoch 164/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5965 - acc: 0.8690 - val_loss: 1.2641 - val_acc: 0.8005\n",
      "Epoch 165/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5974 - acc: 0.8687 - val_loss: 1.2415 - val_acc: 0.7966\n",
      "Epoch 166/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 0.5970 - acc: 0.8686 - val_loss: 1.2370 - val_acc: 0.8022\n",
      "Epoch 167/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 0.5949 - acc: 0.8688 - val_loss: 1.2455 - val_acc: 0.8000\n",
      "Epoch 168/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5953 - acc: 0.8675 - val_loss: 1.2244 - val_acc: 0.8046\n",
      "Epoch 169/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5955 - acc: 0.8676 - val_loss: 1.2616 - val_acc: 0.8027\n",
      "Epoch 170/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5962 - acc: 0.8670 - val_loss: 1.2369 - val_acc: 0.8031\n",
      "Epoch 171/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5987 - acc: 0.8672 - val_loss: 1.2337 - val_acc: 0.7950\n",
      "Epoch 172/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5979 - acc: 0.8674 - val_loss: 1.2684 - val_acc: 0.8010\n",
      "Epoch 173/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 0.5953 - acc: 0.8678 - val_loss: 1.2577 - val_acc: 0.7997\n",
      "Epoch 174/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5952 - acc: 0.8674 - val_loss: 1.2536 - val_acc: 0.7977\n",
      "Epoch 175/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 0.5959 - acc: 0.8680 - val_loss: 1.2563 - val_acc: 0.8008\n",
      "Epoch 176/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 0.5956 - acc: 0.8677 - val_loss: 1.2405 - val_acc: 0.7986\n",
      "Epoch 177/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5970 - acc: 0.8671 - val_loss: 1.2458 - val_acc: 0.8022\n",
      "Epoch 178/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5954 - acc: 0.8670 - val_loss: 1.2704 - val_acc: 0.7968\n",
      "Epoch 179/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 0.5954 - acc: 0.8674 - val_loss: 1.2591 - val_acc: 0.7951\n",
      "Epoch 180/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 0.5950 - acc: 0.8682 - val_loss: 1.2756 - val_acc: 0.7987\n",
      "Epoch 181/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5957 - acc: 0.8688 - val_loss: 1.2503 - val_acc: 0.8014\n",
      "Epoch 182/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 0.5963 - acc: 0.8678 - val_loss: 1.2345 - val_acc: 0.7990\n",
      "Epoch 183/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 0.5992 - acc: 0.8672 - val_loss: 1.2522 - val_acc: 0.7992\n",
      "Epoch 184/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5953 - acc: 0.8693 - val_loss: 1.2774 - val_acc: 0.8010\n",
      "Epoch 185/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5944 - acc: 0.8683 - val_loss: 1.2560 - val_acc: 0.8026\n",
      "Epoch 186/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5941 - acc: 0.8687 - val_loss: 1.2631 - val_acc: 0.8010\n",
      "Epoch 187/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5948 - acc: 0.8668 - val_loss: 1.2647 - val_acc: 0.7981\n",
      "Epoch 188/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5950 - acc: 0.8668 - val_loss: 1.2520 - val_acc: 0.7995\n",
      "Epoch 189/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5979 - acc: 0.8677 - val_loss: 1.2568 - val_acc: 0.7986\n",
      "Epoch 190/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.5965 - acc: 0.8680 - val_loss: 1.2496 - val_acc: 0.8001\n",
      "Epoch 191/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5954 - acc: 0.8676 - val_loss: 1.2428 - val_acc: 0.7998\n",
      "Epoch 192/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.5952 - acc: 0.8683 - val_loss: 1.2615 - val_acc: 0.8015\n",
      "Epoch 193/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.5957 - acc: 0.8687 - val_loss: 1.2643 - val_acc: 0.7990\n",
      "Epoch 194/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 0.5950 - acc: 0.8685 - val_loss: 1.2572 - val_acc: 0.8019\n",
      "Epoch 195/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5948 - acc: 0.8690 - val_loss: 1.2733 - val_acc: 0.8021\n",
      "Epoch 196/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5966 - acc: 0.8672 - val_loss: 1.2814 - val_acc: 0.8003\n",
      "Epoch 197/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5997 - acc: 0.8666 - val_loss: 1.2617 - val_acc: 0.7982\n",
      "Epoch 198/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5974 - acc: 0.8672 - val_loss: 1.2518 - val_acc: 0.8000\n",
      "Epoch 199/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5950 - acc: 0.8670 - val_loss: 1.2887 - val_acc: 0.8006\n",
      "Epoch 200/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5942 - acc: 0.8690 - val_loss: 1.2933 - val_acc: 0.8017\n",
      "Epoch 201/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5944 - acc: 0.8695 - val_loss: 1.2868 - val_acc: 0.7957\n",
      "Epoch 202/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.5952 - acc: 0.8686 - val_loss: 1.2832 - val_acc: 0.7984\n",
      "Epoch 203/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5948 - acc: 0.8690 - val_loss: 1.2531 - val_acc: 0.8011\n",
      "Epoch 204/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5950 - acc: 0.8678 - val_loss: 1.2908 - val_acc: 0.7977\n",
      "Epoch 205/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5957 - acc: 0.8674 - val_loss: 1.2807 - val_acc: 0.7967\n",
      "Epoch 206/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5962 - acc: 0.8680 - val_loss: 1.2772 - val_acc: 0.7986\n",
      "Epoch 207/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5954 - acc: 0.8677 - val_loss: 1.2584 - val_acc: 0.8006\n",
      "Epoch 208/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5954 - acc: 0.8680 - val_loss: 1.2675 - val_acc: 0.8011\n",
      "Epoch 209/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5951 - acc: 0.8683 - val_loss: 1.2858 - val_acc: 0.7995\n",
      "Epoch 210/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5949 - acc: 0.8683 - val_loss: 1.2850 - val_acc: 0.8005\n",
      "Epoch 211/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5949 - acc: 0.8676 - val_loss: 1.2958 - val_acc: 0.8021\n",
      "Epoch 212/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5957 - acc: 0.8686 - val_loss: 1.2810 - val_acc: 0.8003\n",
      "Epoch 213/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5990 - acc: 0.8675 - val_loss: 1.2546 - val_acc: 0.8021\n",
      "Epoch 214/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5962 - acc: 0.8679 - val_loss: 1.2348 - val_acc: 0.8017\n",
      "Epoch 215/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5974 - acc: 0.8675 - val_loss: 1.2516 - val_acc: 0.8004\n",
      "Epoch 216/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5949 - acc: 0.8685 - val_loss: 1.2570 - val_acc: 0.8010\n",
      "Epoch 217/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5937 - acc: 0.8688 - val_loss: 1.3057 - val_acc: 0.8009\n",
      "Epoch 218/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5944 - acc: 0.8686 - val_loss: 1.2879 - val_acc: 0.8015\n",
      "Epoch 219/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.5940 - acc: 0.8687 - val_loss: 1.3223 - val_acc: 0.8032\n",
      "Epoch 220/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.5953 - acc: 0.8684 - val_loss: 1.3015 - val_acc: 0.8017\n",
      "Epoch 221/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5953 - acc: 0.8678 - val_loss: 1.2894 - val_acc: 0.8003\n",
      "Epoch 222/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5958 - acc: 0.8683 - val_loss: 1.2452 - val_acc: 0.8033\n",
      "Epoch 223/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5954 - acc: 0.8683 - val_loss: 1.2783 - val_acc: 0.7987\n",
      "Epoch 224/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5946 - acc: 0.8679 - val_loss: 1.2906 - val_acc: 0.8028\n",
      "Epoch 225/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5953 - acc: 0.8694 - val_loss: 1.2988 - val_acc: 0.7992\n",
      "Epoch 226/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5967 - acc: 0.8680 - val_loss: 1.2581 - val_acc: 0.8015\n",
      "Epoch 227/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5975 - acc: 0.8686 - val_loss: 1.3429 - val_acc: 0.7993\n",
      "Epoch 228/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5954 - acc: 0.8690 - val_loss: 1.2720 - val_acc: 0.8028\n",
      "Epoch 229/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5963 - acc: 0.8679 - val_loss: 1.2559 - val_acc: 0.8009\n",
      "Epoch 230/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5968 - acc: 0.8679 - val_loss: 1.2875 - val_acc: 0.7988\n",
      "Epoch 231/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5935 - acc: 0.8685 - val_loss: 1.2881 - val_acc: 0.8021\n",
      "Epoch 232/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5938 - acc: 0.8681 - val_loss: 1.3286 - val_acc: 0.7989\n",
      "Epoch 233/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5951 - acc: 0.8681 - val_loss: 1.2831 - val_acc: 0.8024\n",
      "Epoch 234/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5942 - acc: 0.8676 - val_loss: 1.2963 - val_acc: 0.8016\n",
      "Epoch 235/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.5943 - acc: 0.8681 - val_loss: 1.2882 - val_acc: 0.7987\n",
      "Epoch 236/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5951 - acc: 0.8680 - val_loss: 1.2672 - val_acc: 0.8011\n",
      "Epoch 237/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.5949 - acc: 0.8688 - val_loss: 1.2861 - val_acc: 0.8005\n",
      "Epoch 238/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5978 - acc: 0.8667 - val_loss: 1.3513 - val_acc: 0.7976\n",
      "Epoch 239/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5996 - acc: 0.8683 - val_loss: 1.2849 - val_acc: 0.7984\n",
      "Epoch 240/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5951 - acc: 0.8685 - val_loss: 1.3112 - val_acc: 0.7993\n",
      "Epoch 241/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5943 - acc: 0.8679 - val_loss: 1.3036 - val_acc: 0.8011\n",
      "Epoch 242/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5937 - acc: 0.8690 - val_loss: 1.3085 - val_acc: 0.8001\n",
      "Epoch 243/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5943 - acc: 0.8682 - val_loss: 1.2943 - val_acc: 0.8013\n",
      "Epoch 244/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.5950 - acc: 0.8685 - val_loss: 1.2764 - val_acc: 0.7997\n",
      "Epoch 245/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5940 - acc: 0.8694 - val_loss: 1.3093 - val_acc: 0.8019\n",
      "Epoch 246/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.5937 - acc: 0.8687 - val_loss: 1.3222 - val_acc: 0.8016\n",
      "Epoch 247/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5948 - acc: 0.8685 - val_loss: 1.3046 - val_acc: 0.7986\n",
      "Epoch 248/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.5951 - acc: 0.8687 - val_loss: 1.2548 - val_acc: 0.8010\n",
      "Epoch 249/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.5955 - acc: 0.8682 - val_loss: 1.3220 - val_acc: 0.7977\n",
      "Epoch 250/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5958 - acc: 0.8692 - val_loss: 1.2975 - val_acc: 0.7970\n",
      "Epoch 251/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5956 - acc: 0.8683 - val_loss: 1.2968 - val_acc: 0.7984\n",
      "Epoch 252/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5974 - acc: 0.8682 - val_loss: 1.3046 - val_acc: 0.7990\n",
      "Epoch 253/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 0.5943 - acc: 0.8692 - val_loss: 1.3073 - val_acc: 0.7990\n",
      "Epoch 254/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5936 - acc: 0.8684 - val_loss: 1.3045 - val_acc: 0.7983\n",
      "Epoch 255/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5933 - acc: 0.8686 - val_loss: 1.3448 - val_acc: 0.8013\n",
      "Epoch 256/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.5936 - acc: 0.8685 - val_loss: 1.3166 - val_acc: 0.7965\n",
      "Epoch 257/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.5942 - acc: 0.8683 - val_loss: 1.3269 - val_acc: 0.7981\n",
      "Epoch 258/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.5950 - acc: 0.8687 - val_loss: 1.3211 - val_acc: 0.7981\n",
      "Epoch 259/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5963 - acc: 0.8676 - val_loss: 1.2768 - val_acc: 0.8024\n",
      "Epoch 260/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 0.5942 - acc: 0.8687 - val_loss: 1.3127 - val_acc: 0.8025\n",
      "Epoch 261/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5946 - acc: 0.8683 - val_loss: 1.3035 - val_acc: 0.8031\n",
      "Epoch 262/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5952 - acc: 0.8674 - val_loss: 1.3452 - val_acc: 0.8033\n",
      "Epoch 263/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5951 - acc: 0.8688 - val_loss: 1.3329 - val_acc: 0.7973\n",
      "Epoch 264/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5953 - acc: 0.8681 - val_loss: 1.2891 - val_acc: 0.8014\n",
      "Epoch 265/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.5941 - acc: 0.8681 - val_loss: 1.3136 - val_acc: 0.8003\n",
      "Epoch 266/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5950 - acc: 0.8682 - val_loss: 1.3114 - val_acc: 0.7967\n",
      "Epoch 267/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5968 - acc: 0.8680 - val_loss: 1.2818 - val_acc: 0.7972\n",
      "Epoch 268/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.5938 - acc: 0.8679 - val_loss: 1.3290 - val_acc: 0.7977\n",
      "Epoch 269/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.5942 - acc: 0.8693 - val_loss: 1.3381 - val_acc: 0.8008\n",
      "Epoch 270/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5953 - acc: 0.8679 - val_loss: 1.3449 - val_acc: 0.7989\n",
      "Epoch 271/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5941 - acc: 0.8688 - val_loss: 1.3180 - val_acc: 0.7970\n",
      "Epoch 272/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.5940 - acc: 0.8682 - val_loss: 1.3293 - val_acc: 0.7979\n",
      "Epoch 273/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5940 - acc: 0.8677 - val_loss: 1.3244 - val_acc: 0.7987\n",
      "Epoch 274/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5949 - acc: 0.8686 - val_loss: 1.3174 - val_acc: 0.8040\n",
      "Epoch 275/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.6040 - acc: 0.8677 - val_loss: 1.2898 - val_acc: 0.8013\n",
      "Epoch 276/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.5947 - acc: 0.8692 - val_loss: 1.3255 - val_acc: 0.7992\n",
      "Epoch 277/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5946 - acc: 0.8687 - val_loss: 1.3318 - val_acc: 0.7981\n",
      "Epoch 278/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5933 - acc: 0.8691 - val_loss: 1.3312 - val_acc: 0.7983\n",
      "Epoch 279/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5946 - acc: 0.8683 - val_loss: 1.3099 - val_acc: 0.8028\n",
      "Epoch 280/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.5933 - acc: 0.8690 - val_loss: 1.3278 - val_acc: 0.7982\n",
      "Epoch 281/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.5944 - acc: 0.8675 - val_loss: 1.3346 - val_acc: 0.7983\n",
      "Epoch 282/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 0.5950 - acc: 0.8679 - val_loss: 1.2865 - val_acc: 0.8015\n",
      "Epoch 283/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5945 - acc: 0.8674 - val_loss: 1.3201 - val_acc: 0.8001\n",
      "Epoch 284/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5945 - acc: 0.8683 - val_loss: 1.3440 - val_acc: 0.7965\n",
      "Epoch 285/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.5939 - acc: 0.8699 - val_loss: 1.3409 - val_acc: 0.8003\n",
      "Epoch 286/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5937 - acc: 0.8686 - val_loss: 1.3527 - val_acc: 0.7999\n",
      "Epoch 287/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5946 - acc: 0.8691 - val_loss: 1.3190 - val_acc: 0.8020\n",
      "Epoch 288/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5966 - acc: 0.8676 - val_loss: 1.3519 - val_acc: 0.8006\n",
      "Epoch 289/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.5934 - acc: 0.8681 - val_loss: 1.3205 - val_acc: 0.7998\n",
      "Epoch 290/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5934 - acc: 0.8678 - val_loss: 1.3397 - val_acc: 0.8026\n",
      "Epoch 291/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.5938 - acc: 0.8679 - val_loss: 1.3377 - val_acc: 0.8001\n",
      "Epoch 292/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5949 - acc: 0.8677 - val_loss: 1.3497 - val_acc: 0.7994\n",
      "Epoch 293/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.5951 - acc: 0.8671 - val_loss: 1.3257 - val_acc: 0.8000\n",
      "Epoch 294/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5957 - acc: 0.8676 - val_loss: 1.3111 - val_acc: 0.7993\n",
      "Epoch 295/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5962 - acc: 0.8677 - val_loss: 1.3535 - val_acc: 0.8033\n",
      "Epoch 296/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5949 - acc: 0.8696 - val_loss: 1.2835 - val_acc: 0.8009\n",
      "Epoch 297/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5944 - acc: 0.8691 - val_loss: 1.3386 - val_acc: 0.8008\n",
      "Epoch 298/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.5931 - acc: 0.8690 - val_loss: 1.3383 - val_acc: 0.8003\n",
      "Epoch 299/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5928 - acc: 0.8683 - val_loss: 1.4216 - val_acc: 0.7940\n",
      "Epoch 300/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.5944 - acc: 0.8677 - val_loss: 1.3679 - val_acc: 0.8008\n"
     ]
    }
   ],
   "source": [
    "model1 = build_model(X_train, Y_train, X_val, Y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report classification accuracy and ∆ DP on the test set for your trained classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.8019163442305284\n"
     ]
    }
   ],
   "source": [
    "score = evaluate_model(model1, X_test, Y_test)\n",
    "print('Test accuracy:', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delta DP 0.12579532633986307\n"
     ]
    }
   ],
   "source": [
    "y_hat = predict(model1, X_test)\n",
    "print('delta DP', compute_delta_DP(y_hat, a_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which sensitive group has higher values of Ŷ , on average?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let’s take a look at how the features in our data correlate with the learned predictor Ŷ . Which three features in the data are most correlated with Ŷ ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_hat_df = pd.DataFrame(y_hat)\n",
    "y_hat_df.columns = ['predicted_income']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_u20</th>\n",
       "      <th>age_u30</th>\n",
       "      <th>age_u40</th>\n",
       "      <th>age_u50</th>\n",
       "      <th>age_u60</th>\n",
       "      <th>age_u70</th>\n",
       "      <th>age_u80</th>\n",
       "      <th>workclass_Private</th>\n",
       "      <th>workclass_Self-emp-not-inc</th>\n",
       "      <th>workclass_Self-emp-inc</th>\n",
       "      <th>...</th>\n",
       "      <th>country_Scotland</th>\n",
       "      <th>country_Thailand</th>\n",
       "      <th>country_Yugoslavia</th>\n",
       "      <th>country_El-Salvador</th>\n",
       "      <th>country_Trinadad&amp;Tobago</th>\n",
       "      <th>country_Peru</th>\n",
       "      <th>country_Hong</th>\n",
       "      <th>country_Holand-Netherlands</th>\n",
       "      <th>country_?</th>\n",
       "      <th>predicted_income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age_u20</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.133104</td>\n",
       "      <td>-0.141223</td>\n",
       "      <td>-0.124144</td>\n",
       "      <td>-0.092967</td>\n",
       "      <td>-0.061391</td>\n",
       "      <td>-0.035956</td>\n",
       "      <td>0.021240</td>\n",
       "      <td>-0.053719</td>\n",
       "      <td>-0.030268</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005530</td>\n",
       "      <td>-0.006386</td>\n",
       "      <td>0.008420</td>\n",
       "      <td>0.002178</td>\n",
       "      <td>-0.005214</td>\n",
       "      <td>0.001945</td>\n",
       "      <td>-0.005829</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.020049</td>\n",
       "      <td>-0.112211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age_u30</th>\n",
       "      <td>-0.133104</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.339982</td>\n",
       "      <td>-0.298866</td>\n",
       "      <td>-0.223811</td>\n",
       "      <td>-0.147795</td>\n",
       "      <td>-0.086561</td>\n",
       "      <td>0.110328</td>\n",
       "      <td>-0.105246</td>\n",
       "      <td>-0.074662</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007217</td>\n",
       "      <td>-0.004815</td>\n",
       "      <td>-0.011740</td>\n",
       "      <td>0.013363</td>\n",
       "      <td>0.000379</td>\n",
       "      <td>0.001699</td>\n",
       "      <td>-0.002468</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009475</td>\n",
       "      <td>-0.245038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age_u40</th>\n",
       "      <td>-0.141223</td>\n",
       "      <td>-0.339982</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.317095</td>\n",
       "      <td>-0.237461</td>\n",
       "      <td>-0.156809</td>\n",
       "      <td>-0.091841</td>\n",
       "      <td>0.055679</td>\n",
       "      <td>-0.008761</td>\n",
       "      <td>-0.009385</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008205</td>\n",
       "      <td>0.004199</td>\n",
       "      <td>-0.005744</td>\n",
       "      <td>0.020349</td>\n",
       "      <td>0.011800</td>\n",
       "      <td>-0.009065</td>\n",
       "      <td>0.018810</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.002851</td>\n",
       "      <td>0.010768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age_u50</th>\n",
       "      <td>-0.124144</td>\n",
       "      <td>-0.298866</td>\n",
       "      <td>-0.317095</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.208744</td>\n",
       "      <td>-0.137845</td>\n",
       "      <td>-0.080734</td>\n",
       "      <td>-0.044525</td>\n",
       "      <td>0.041431</td>\n",
       "      <td>0.046419</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012417</td>\n",
       "      <td>0.002106</td>\n",
       "      <td>-0.003774</td>\n",
       "      <td>-0.012713</td>\n",
       "      <td>-0.004993</td>\n",
       "      <td>0.008484</td>\n",
       "      <td>-0.001080</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006098</td>\n",
       "      <td>0.194016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age_u60</th>\n",
       "      <td>-0.092967</td>\n",
       "      <td>-0.223811</td>\n",
       "      <td>-0.237461</td>\n",
       "      <td>-0.208744</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.103228</td>\n",
       "      <td>-0.060459</td>\n",
       "      <td>-0.063406</td>\n",
       "      <td>0.043695</td>\n",
       "      <td>0.042412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013629</td>\n",
       "      <td>0.009119</td>\n",
       "      <td>0.026460</td>\n",
       "      <td>-0.015164</td>\n",
       "      <td>-0.000661</td>\n",
       "      <td>0.005756</td>\n",
       "      <td>-0.009802</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.001455</td>\n",
       "      <td>0.142030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 114 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          age_u20   age_u30   age_u40   age_u50   age_u60   age_u70   age_u80  \\\n",
       "age_u20  1.000000 -0.133104 -0.141223 -0.124144 -0.092967 -0.061391 -0.035956   \n",
       "age_u30 -0.133104  1.000000 -0.339982 -0.298866 -0.223811 -0.147795 -0.086561   \n",
       "age_u40 -0.141223 -0.339982  1.000000 -0.317095 -0.237461 -0.156809 -0.091841   \n",
       "age_u50 -0.124144 -0.298866 -0.317095  1.000000 -0.208744 -0.137845 -0.080734   \n",
       "age_u60 -0.092967 -0.223811 -0.237461 -0.208744  1.000000 -0.103228 -0.060459   \n",
       "\n",
       "         workclass_Private  workclass_Self-emp-not-inc  \\\n",
       "age_u20           0.021240                   -0.053719   \n",
       "age_u30           0.110328                   -0.105246   \n",
       "age_u40           0.055679                   -0.008761   \n",
       "age_u50          -0.044525                    0.041431   \n",
       "age_u60          -0.063406                    0.043695   \n",
       "\n",
       "         workclass_Self-emp-inc        ...         country_Scotland  \\\n",
       "age_u20               -0.030268        ...                -0.005530   \n",
       "age_u30               -0.074662        ...                -0.007217   \n",
       "age_u40               -0.009385        ...                -0.008205   \n",
       "age_u50                0.046419        ...                -0.012417   \n",
       "age_u60                0.042412        ...                 0.013629   \n",
       "\n",
       "         country_Thailand  country_Yugoslavia  country_El-Salvador  \\\n",
       "age_u20         -0.006386            0.008420             0.002178   \n",
       "age_u30         -0.004815           -0.011740             0.013363   \n",
       "age_u40          0.004199           -0.005744             0.020349   \n",
       "age_u50          0.002106           -0.003774            -0.012713   \n",
       "age_u60          0.009119            0.026460            -0.015164   \n",
       "\n",
       "         country_Trinadad&Tobago  country_Peru  country_Hong  \\\n",
       "age_u20                -0.005214      0.001945     -0.005829   \n",
       "age_u30                 0.000379      0.001699     -0.002468   \n",
       "age_u40                 0.011800     -0.009065      0.018810   \n",
       "age_u50                -0.004993      0.008484     -0.001080   \n",
       "age_u60                -0.000661      0.005756     -0.009802   \n",
       "\n",
       "         country_Holand-Netherlands  country_?  predicted_income  \n",
       "age_u20                         NaN  -0.020049         -0.112211  \n",
       "age_u30                         NaN   0.009475         -0.245038  \n",
       "age_u40                         NaN  -0.002851          0.010768  \n",
       "age_u50                         NaN   0.006098          0.194016  \n",
       "age_u60                         NaN  -0.001455          0.142030  \n",
       "\n",
       "[5 rows x 114 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adult_dataset_pred_incom = pd.concat([df_test, y_hat_df], axis=1)\n",
    "adult_dataset_pred_incom.corr().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>marital-status_Married-civ-spouse</th>\n",
       "      <td>0.389969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education_num</th>\n",
       "      <td>0.381473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relationship_Husband</th>\n",
       "      <td>0.334888</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   predicted_income\n",
       "marital-status_Married-civ-spouse          0.389969\n",
       "education_num                              0.381473\n",
       "relationship_Husband                       0.334888"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_incom = pd.DataFrame(np.abs(adult_dataset_pred_incom.corr()['predicted_income']))\n",
    "corr_pred_income = predicted_incom.sort_values(by='predicted_income',  ascending=False)\n",
    "top_10_predicted = corr_pred_income[1:4] #the first row is y itself\n",
    "top_10_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAl8AAAGACAYAAACTPwd6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe1332946a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels = [att for att in top_10_predicted['predicted_income'].index]\n",
    "\n",
    "#labels = ['Cookies', 'Jellybean', 'Milkshake', 'Cheesecake']\n",
    "sizes = [top_10_predicted['predicted_income'][i]*100/3 for i in range(3)]\n",
    "#colors = ['yellowgreen', 'gold', 'lightskyblue', 'lightcoral']\n",
    "explode = (0.1, 0, 0)  \n",
    "colors = ['yellowgreen', 'gold', 'lightskyblue']\n",
    "#fig1, ax1 = plt.subplots()\n",
    "plt.pie(sizes, explode=explode, labels=labels, colors=colors, autopct='%1.1f%%',\n",
    "        shadow=False, startangle=90)\n",
    "\n",
    "# Equal aspect ratio ensures that pie is drawn as a circle\n",
    "plt.axis('equal')  \n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('corr3_y.png', dpi= 500 )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which three features are most correlated with Ŷ , only looking at examples where A = 0?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>relationship_Wife</th>\n",
       "      <td>0.486388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>marital-status_Married-civ-spouse</th>\n",
       "      <td>0.452018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education_num</th>\n",
       "      <td>0.283427</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   predicted_income\n",
       "relationship_Wife                          0.486388\n",
       "marital-status_Married-civ-spouse          0.452018\n",
       "education_num                              0.283427"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adult_dataset_pred_incom_0 = adult_dataset_pred_incom.drop(np.where(a_test==1)[0], axis=0)\n",
    "predicted_incom_0 = pd.DataFrame(np.abs(adult_dataset_pred_incom_0.corr()['predicted_income']))\n",
    "corr_pred_income_0 = predicted_incom_0.sort_values(by='predicted_income',  ascending=False)\n",
    "top_10_predicted_0 = corr_pred_income_0[1:4] #the first row is y itself\n",
    "top_10_predicted_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjQAAAGACAYAAAC6OPj9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe139071940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels = [att for att in top_10_predicted_0['predicted_income'].index]\n",
    "\n",
    "#labels = ['Cookies', 'Jellybean', 'Milkshake', 'Cheesecake']\n",
    "sizes = [top_10_predicted_0['predicted_income'][i]*100/3 for i in range(3)]\n",
    "#colors = ['yellowgreen', 'gold', 'lightskyblue', 'lightcoral']\n",
    "explode = (0.1, 0, 0)  \n",
    "colors = ['lightskyblue', 'lightcoral', 'green']\n",
    "#fig1, ax1 = plt.subplots()\n",
    "plt.pie(sizes, explode=explode, labels=labels, colors=colors, autopct='%1.1f%%',\n",
    "        shadow=False, startangle=90)\n",
    "\n",
    "# Equal aspect ratio ensures that pie is drawn as a circle\n",
    "plt.axis('equal')  \n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('corr3_a0.png', dpi= 500 )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which three features are most correlated with Ŷ , only looking at examples where A = 1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>education_num</th>\n",
       "      <td>0.420568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relationship_Husband</th>\n",
       "      <td>0.344111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>marital-status_Married-civ-spouse</th>\n",
       "      <td>0.340377</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   predicted_income\n",
       "education_num                              0.420568\n",
       "relationship_Husband                       0.344111\n",
       "marital-status_Married-civ-spouse          0.340377"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adult_dataset_pred_incom_1 = adult_dataset_pred_incom.drop(np.where(a_test==0)[0], axis=0)\n",
    "predicted_incom_1 = pd.DataFrame(np.abs(adult_dataset_pred_incom_1.corr()['predicted_income']))\n",
    "corr_pred_income_1 = predicted_incom_1.sort_values(by='predicted_income',  ascending=False)\n",
    "top_10_predicted_1 = corr_pred_income_1[1:4] #the first row is y itself\n",
    "top_10_predicted_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAAGACAYAAABr3/yNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRERExE8qVCIiIiJ+UqESERER8dP/AGrxzCVfBQjbAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe13908bd68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels = [att for att in top_10_predicted_1['predicted_income'].index]\n",
    "\n",
    "#labels = ['Cookies', 'Jellybean', 'Milkshake', 'Cheesecake']\n",
    "sizes = [top_10_predicted_1['predicted_income'][i]*100/3 for i in range(3)]\n",
    "#colors = ['yellowgreen', 'gold', 'lightskyblue', 'lightcoral']\n",
    "explode = (0.1, 0, 0)  \n",
    "colors = ['lightcoral', 'gold', 'lightskyblue']\n",
    "#fig1, ax1 = plt.subplots()\n",
    "plt.pie(sizes, explode=explode, labels=labels, colors=colors, autopct='%1.1f%%',\n",
    "        shadow=False, startangle=90)\n",
    "\n",
    "# Equal aspect ratio ensures that pie is drawn as a circle\n",
    "plt.axis('equal')  \n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('corr3_a1.png', dpi= 500 )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, make a version of this data, but with the attributes called “sex Female” and “sex Male” removed. Train a classifier on this data, exactly as in the previous section, but with the goal of predicting A instead of Y ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_without_male_female = df.drop(['sex_Male', 'sex_Female'], axis=1)\n",
    "df_test_without_male_female = df_test.drop(['sex_Male', 'sex_Female'], axis=1)\n",
    "#get the training data\n",
    "\n",
    "X_train_a = df_without_male_female  #contents only attributes in x\n",
    "A_train = df_a\n",
    "\n",
    "##loading test data\n",
    "npz_test = np.load('adult/adult_test.npz')\n",
    "df_test = pd.DataFrame(list(npz_test['x']))\n",
    "df_test.columns = headers[0:len(headers)-1]\n",
    "\n",
    "X_test_a = df_test_without_male_female \n",
    "A_test =  pd.DataFrame(list(npz_test['a']))\n",
    "A_test.columns = ['sexe']\n",
    "\n",
    "\n",
    "X_train_a = np.array(X_train_a)\n",
    "A_train = np.array(A_train)\n",
    "A_train = A_train.flatten()\n",
    "\n",
    "X_test_a = np.array(X_test_a)\n",
    "A_test = np.array(A_test)\n",
    "A_test = A_test.flatten()\n",
    "\n",
    "train_ind_a = np.random.choice(X_train_a.shape[0], 3*X_train_a.shape[0]//4, replace=False) ## choose indexes for train and validation set\n",
    "#train_ind\n",
    "\n",
    "#splitting the train data into train and val usin tain_ind_a\n",
    "X_train_a, A_train = X_train_a[train_ind_a], A_train[train_ind_a]\n",
    "X_val_a= df_without_male_female.drop(train_ind_a, axis=0)\n",
    "A_val = df_a.drop(train_ind_a)\n",
    "X_val_a = np.array(X_val_a)\n",
    "A_val = np.array(A_val)\n",
    "A_val = A_val.flatten()\n",
    "\n",
    "\n",
    "##scaling the data using MinMaxScaler\n",
    "\n",
    "# X_train_a = scaling_data(X_train_a)\n",
    "# X_val_a = scaling_data(X_val_a)\n",
    "# X_test_a = scaling_data(X_test_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24420 samples, validate on 8141 samples\n",
      "Epoch 1/300\n",
      "24420/24420 [==============================] - 1s 48us/step - loss: 1.5188 - acc: 0.7503 - val_loss: 1.5212 - val_acc: 0.7618\n",
      "Epoch 2/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.5109 - acc: 0.7743 - val_loss: 1.4773 - val_acc: 0.7705\n",
      "Epoch 3/300\n",
      "24420/24420 [==============================] - 1s 34us/step - loss: 1.5071 - acc: 0.7743 - val_loss: 1.4548 - val_acc: 0.7826\n",
      "Epoch 4/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 1.4979 - acc: 0.7794 - val_loss: 1.4931 - val_acc: 0.7680\n",
      "Epoch 5/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 1.4978 - acc: 0.7814 - val_loss: 1.4539 - val_acc: 0.7821\n",
      "Epoch 6/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.4942 - acc: 0.7828 - val_loss: 1.4652 - val_acc: 0.7725\n",
      "Epoch 7/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.4934 - acc: 0.7815 - val_loss: 1.4572 - val_acc: 0.7802\n",
      "Epoch 8/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 1.4915 - acc: 0.7842 - val_loss: 1.4543 - val_acc: 0.7817\n",
      "Epoch 9/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 1.4904 - acc: 0.7864 - val_loss: 1.4547 - val_acc: 0.7807\n",
      "Epoch 10/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 1.4877 - acc: 0.7862 - val_loss: 1.4556 - val_acc: 0.7841\n",
      "Epoch 11/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.5857 - acc: 0.7803 - val_loss: 1.8792 - val_acc: 0.7551\n",
      "Epoch 12/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 1.8620 - acc: 0.7651 - val_loss: 1.8770 - val_acc: 0.7592\n",
      "Epoch 13/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.8598 - acc: 0.7654 - val_loss: 1.8784 - val_acc: 0.7590\n",
      "Epoch 14/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 1.8587 - acc: 0.7684 - val_loss: 1.9013 - val_acc: 0.7466\n",
      "Epoch 15/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.8571 - acc: 0.7693 - val_loss: 1.8798 - val_acc: 0.7542\n",
      "Epoch 16/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 1.8535 - acc: 0.7712 - val_loss: 1.8901 - val_acc: 0.7554\n",
      "Epoch 17/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 1.8527 - acc: 0.7735 - val_loss: 1.9060 - val_acc: 0.7413\n",
      "Epoch 18/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.8519 - acc: 0.7719 - val_loss: 1.8854 - val_acc: 0.7575\n",
      "Epoch 19/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 1.8482 - acc: 0.7742 - val_loss: 1.8964 - val_acc: 0.7492\n",
      "Epoch 20/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 1.8478 - acc: 0.7767 - val_loss: 1.8878 - val_acc: 0.7533\n",
      "Epoch 21/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 1.8449 - acc: 0.7758 - val_loss: 1.8952 - val_acc: 0.7529\n",
      "Epoch 22/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.8434 - acc: 0.7777 - val_loss: 1.8887 - val_acc: 0.7567\n",
      "Epoch 23/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.8413 - acc: 0.7801 - val_loss: 1.8975 - val_acc: 0.7557\n",
      "Epoch 24/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 1.8398 - acc: 0.7778 - val_loss: 1.9093 - val_acc: 0.7492\n",
      "Epoch 25/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 1.8379 - acc: 0.7801 - val_loss: 1.9064 - val_acc: 0.7537\n",
      "Epoch 26/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.8356 - acc: 0.7822 - val_loss: 1.9065 - val_acc: 0.7553\n",
      "Epoch 27/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.8342 - acc: 0.7826 - val_loss: 1.9130 - val_acc: 0.7503\n",
      "Epoch 28/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 1.8318 - acc: 0.7833 - val_loss: 1.9226 - val_acc: 0.7483\n",
      "Epoch 29/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.8299 - acc: 0.7856 - val_loss: 1.9161 - val_acc: 0.7515\n",
      "Epoch 30/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 1.8285 - acc: 0.7863 - val_loss: 1.9242 - val_acc: 0.7553\n",
      "Epoch 31/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 1.8270 - acc: 0.7870 - val_loss: 1.9325 - val_acc: 0.7470\n",
      "Epoch 32/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.8243 - acc: 0.7884 - val_loss: 1.9294 - val_acc: 0.7533\n",
      "Epoch 33/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.8235 - acc: 0.7896 - val_loss: 1.9393 - val_acc: 0.7548\n",
      "Epoch 34/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.8215 - acc: 0.7898 - val_loss: 1.9376 - val_acc: 0.7543\n",
      "Epoch 35/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 1.8201 - acc: 0.7916 - val_loss: 1.9361 - val_acc: 0.7511\n",
      "Epoch 36/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.8179 - acc: 0.7903 - val_loss: 1.9404 - val_acc: 0.7511\n",
      "Epoch 37/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 1.8162 - acc: 0.7917 - val_loss: 1.9616 - val_acc: 0.7482\n",
      "Epoch 38/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.8159 - acc: 0.7928 - val_loss: 1.9458 - val_acc: 0.7477\n",
      "Epoch 39/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.8124 - acc: 0.7938 - val_loss: 1.9593 - val_acc: 0.7506\n",
      "Epoch 40/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.8102 - acc: 0.7966 - val_loss: 1.9666 - val_acc: 0.7498\n",
      "Epoch 41/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.8078 - acc: 0.7957 - val_loss: 1.9666 - val_acc: 0.7520\n",
      "Epoch 42/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 1.8066 - acc: 0.7977 - val_loss: 1.9822 - val_acc: 0.7525\n",
      "Epoch 43/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 1.8056 - acc: 0.7966 - val_loss: 1.9806 - val_acc: 0.7500\n",
      "Epoch 44/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 1.8042 - acc: 0.7979 - val_loss: 1.9977 - val_acc: 0.7468\n",
      "Epoch 45/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.8013 - acc: 0.8001 - val_loss: 1.9866 - val_acc: 0.7519\n",
      "Epoch 46/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 1.8000 - acc: 0.8004 - val_loss: 2.0009 - val_acc: 0.7536\n",
      "Epoch 47/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 1.7974 - acc: 0.8034 - val_loss: 2.0091 - val_acc: 0.7466\n",
      "Epoch 48/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.7967 - acc: 0.8037 - val_loss: 2.0238 - val_acc: 0.7499\n",
      "Epoch 49/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 1.7940 - acc: 0.8023 - val_loss: 2.0352 - val_acc: 0.7462\n",
      "Epoch 50/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.7934 - acc: 0.8043 - val_loss: 2.0338 - val_acc: 0.7459\n",
      "Epoch 51/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 1.7930 - acc: 0.8051 - val_loss: 2.0568 - val_acc: 0.7436\n",
      "Epoch 52/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7900 - acc: 0.8048 - val_loss: 2.0436 - val_acc: 0.7470\n",
      "Epoch 53/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7871 - acc: 0.8070 - val_loss: 2.0713 - val_acc: 0.7503\n",
      "Epoch 54/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7858 - acc: 0.8090 - val_loss: 2.0569 - val_acc: 0.7509\n",
      "Epoch 55/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7853 - acc: 0.8081 - val_loss: 2.0430 - val_acc: 0.7470\n",
      "Epoch 56/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7850 - acc: 0.8092 - val_loss: 2.0743 - val_acc: 0.7420\n",
      "Epoch 57/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 1.7824 - acc: 0.8098 - val_loss: 2.0731 - val_acc: 0.7456\n",
      "Epoch 58/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.7818 - acc: 0.8102 - val_loss: 2.0765 - val_acc: 0.7450\n",
      "Epoch 59/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7807 - acc: 0.8102 - val_loss: 2.0620 - val_acc: 0.7459\n",
      "Epoch 60/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 1.7793 - acc: 0.8103 - val_loss: 2.0755 - val_acc: 0.7434\n",
      "Epoch 61/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 1.7772 - acc: 0.8120 - val_loss: 2.1024 - val_acc: 0.7454\n",
      "Epoch 62/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.7767 - acc: 0.8131 - val_loss: 2.0831 - val_acc: 0.7435\n",
      "Epoch 63/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 1.7741 - acc: 0.8133 - val_loss: 2.0822 - val_acc: 0.7487\n",
      "Epoch 64/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 1.7734 - acc: 0.8140 - val_loss: 2.1047 - val_acc: 0.7455\n",
      "Epoch 65/300\n",
      "24420/24420 [==============================] - 1s 39us/step - loss: 1.7732 - acc: 0.8147 - val_loss: 2.1179 - val_acc: 0.7447\n",
      "Epoch 66/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7719 - acc: 0.8163 - val_loss: 2.1141 - val_acc: 0.7499\n",
      "Epoch 67/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.7703 - acc: 0.8149 - val_loss: 2.1396 - val_acc: 0.7470\n",
      "Epoch 68/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 1.7683 - acc: 0.8168 - val_loss: 2.1083 - val_acc: 0.7473\n",
      "Epoch 69/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7694 - acc: 0.8166 - val_loss: 2.1365 - val_acc: 0.7481\n",
      "Epoch 70/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7668 - acc: 0.8176 - val_loss: 2.1301 - val_acc: 0.7511\n",
      "Epoch 71/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7683 - acc: 0.8176 - val_loss: 2.0946 - val_acc: 0.7500\n",
      "Epoch 72/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7632 - acc: 0.8196 - val_loss: 2.1724 - val_acc: 0.7455\n",
      "Epoch 73/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7630 - acc: 0.8186 - val_loss: 2.1493 - val_acc: 0.7473\n",
      "Epoch 74/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 1.7639 - acc: 0.8185 - val_loss: 2.1193 - val_acc: 0.7397\n",
      "Epoch 75/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 1.7601 - acc: 0.8206 - val_loss: 2.1517 - val_acc: 0.7425\n",
      "Epoch 76/300\n",
      "24420/24420 [==============================] - 1s 39us/step - loss: 1.7605 - acc: 0.8203 - val_loss: 2.1550 - val_acc: 0.7473\n",
      "Epoch 77/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.7600 - acc: 0.8211 - val_loss: 2.1542 - val_acc: 0.7434\n",
      "Epoch 78/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7600 - acc: 0.8217 - val_loss: 2.1520 - val_acc: 0.7430\n",
      "Epoch 79/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7584 - acc: 0.8224 - val_loss: 2.1923 - val_acc: 0.7445\n",
      "Epoch 80/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.7580 - acc: 0.8218 - val_loss: 2.1327 - val_acc: 0.7447\n",
      "Epoch 81/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7590 - acc: 0.8222 - val_loss: 2.1709 - val_acc: 0.7481\n",
      "Epoch 82/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.7559 - acc: 0.8239 - val_loss: 2.1694 - val_acc: 0.7447\n",
      "Epoch 83/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 1.7543 - acc: 0.8234 - val_loss: 2.1625 - val_acc: 0.7473\n",
      "Epoch 84/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7571 - acc: 0.8222 - val_loss: 2.1821 - val_acc: 0.7343\n",
      "Epoch 85/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 1.7538 - acc: 0.8240 - val_loss: 2.1768 - val_acc: 0.7443\n",
      "Epoch 86/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 1.7590 - acc: 0.8229 - val_loss: 2.1724 - val_acc: 0.7418\n",
      "Epoch 87/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7513 - acc: 0.8263 - val_loss: 2.2053 - val_acc: 0.7436\n",
      "Epoch 88/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7510 - acc: 0.8259 - val_loss: 2.1955 - val_acc: 0.7400\n",
      "Epoch 89/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7508 - acc: 0.8258 - val_loss: 2.1739 - val_acc: 0.7422\n",
      "Epoch 90/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 1.7496 - acc: 0.8263 - val_loss: 2.2194 - val_acc: 0.7397\n",
      "Epoch 91/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7556 - acc: 0.8256 - val_loss: 2.2056 - val_acc: 0.7509\n",
      "Epoch 92/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 1.7512 - acc: 0.8269 - val_loss: 2.2095 - val_acc: 0.7408\n",
      "Epoch 93/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7509 - acc: 0.8256 - val_loss: 2.2133 - val_acc: 0.7427\n",
      "Epoch 94/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7469 - acc: 0.8274 - val_loss: 2.2002 - val_acc: 0.7408\n",
      "Epoch 95/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7476 - acc: 0.8267 - val_loss: 2.2168 - val_acc: 0.7412\n",
      "Epoch 96/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.7473 - acc: 0.8266 - val_loss: 2.2253 - val_acc: 0.7402\n",
      "Epoch 97/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 1.7455 - acc: 0.8273 - val_loss: 2.2673 - val_acc: 0.7398\n",
      "Epoch 98/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7452 - acc: 0.8280 - val_loss: 2.2144 - val_acc: 0.7406\n",
      "Epoch 99/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7462 - acc: 0.8281 - val_loss: 2.2014 - val_acc: 0.7409\n",
      "Epoch 100/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7446 - acc: 0.8292 - val_loss: 2.2292 - val_acc: 0.7414\n",
      "Epoch 101/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7447 - acc: 0.8277 - val_loss: 2.2251 - val_acc: 0.7366\n",
      "Epoch 102/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 1.7448 - acc: 0.8298 - val_loss: 2.2275 - val_acc: 0.7407\n",
      "Epoch 103/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7452 - acc: 0.8297 - val_loss: 2.2180 - val_acc: 0.7406\n",
      "Epoch 104/300\n",
      "24420/24420 [==============================] - 1s 39us/step - loss: 1.7412 - acc: 0.8306 - val_loss: 2.2398 - val_acc: 0.7454\n",
      "Epoch 105/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7424 - acc: 0.8305 - val_loss: 2.2531 - val_acc: 0.7409\n",
      "Epoch 106/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 1.7414 - acc: 0.8305 - val_loss: 2.2427 - val_acc: 0.7370\n",
      "Epoch 107/300\n",
      "24420/24420 [==============================] - 1s 40us/step - loss: 1.7410 - acc: 0.8311 - val_loss: 2.2619 - val_acc: 0.7382\n",
      "Epoch 108/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 1.7395 - acc: 0.8330 - val_loss: 2.2336 - val_acc: 0.7377\n",
      "Epoch 109/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7428 - acc: 0.8315 - val_loss: 2.2554 - val_acc: 0.7411\n",
      "Epoch 110/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 1.7396 - acc: 0.8328 - val_loss: 2.2586 - val_acc: 0.7403\n",
      "Epoch 111/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7402 - acc: 0.8310 - val_loss: 2.2579 - val_acc: 0.7461\n",
      "Epoch 112/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7395 - acc: 0.8315 - val_loss: 2.2591 - val_acc: 0.7430\n",
      "Epoch 113/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7392 - acc: 0.8313 - val_loss: 2.2889 - val_acc: 0.7407\n",
      "Epoch 114/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7391 - acc: 0.8323 - val_loss: 2.2774 - val_acc: 0.7381\n",
      "Epoch 115/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.7380 - acc: 0.8314 - val_loss: 2.3062 - val_acc: 0.7349\n",
      "Epoch 116/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 1.7382 - acc: 0.8310 - val_loss: 2.2541 - val_acc: 0.7451\n",
      "Epoch 117/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7393 - acc: 0.8320 - val_loss: 2.2846 - val_acc: 0.7455\n",
      "Epoch 118/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7361 - acc: 0.8314 - val_loss: 2.2588 - val_acc: 0.7395\n",
      "Epoch 119/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.7369 - acc: 0.8328 - val_loss: 2.3155 - val_acc: 0.7422\n",
      "Epoch 120/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7354 - acc: 0.8330 - val_loss: 2.2887 - val_acc: 0.7389\n",
      "Epoch 121/300\n",
      "24420/24420 [==============================] - 1s 39us/step - loss: 1.7382 - acc: 0.8337 - val_loss: 2.3291 - val_acc: 0.7407\n",
      "Epoch 122/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7361 - acc: 0.8331 - val_loss: 2.3164 - val_acc: 0.7352\n",
      "Epoch 123/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 1.7365 - acc: 0.8339 - val_loss: 2.3180 - val_acc: 0.7409\n",
      "Epoch 124/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 1.7331 - acc: 0.8334 - val_loss: 2.3020 - val_acc: 0.7418\n",
      "Epoch 125/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7354 - acc: 0.8344 - val_loss: 2.2785 - val_acc: 0.7407\n",
      "Epoch 126/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 1.7349 - acc: 0.8340 - val_loss: 2.3083 - val_acc: 0.7390\n",
      "Epoch 127/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 1.7372 - acc: 0.8321 - val_loss: 2.2851 - val_acc: 0.7381\n",
      "Epoch 128/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.7323 - acc: 0.8351 - val_loss: 2.3256 - val_acc: 0.7369\n",
      "Epoch 129/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7324 - acc: 0.8342 - val_loss: 2.3096 - val_acc: 0.7423\n",
      "Epoch 130/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7355 - acc: 0.8336 - val_loss: 2.3154 - val_acc: 0.7325\n",
      "Epoch 131/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7371 - acc: 0.8351 - val_loss: 2.3394 - val_acc: 0.7436\n",
      "Epoch 132/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7307 - acc: 0.8366 - val_loss: 2.3100 - val_acc: 0.7402\n",
      "Epoch 133/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.7310 - acc: 0.8349 - val_loss: 2.3234 - val_acc: 0.7391\n",
      "Epoch 134/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7362 - acc: 0.8339 - val_loss: 2.3229 - val_acc: 0.7423\n",
      "Epoch 135/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.7317 - acc: 0.8353 - val_loss: 2.2947 - val_acc: 0.7404\n",
      "Epoch 136/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 1.7330 - acc: 0.8344 - val_loss: 2.3106 - val_acc: 0.7386\n",
      "Epoch 137/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7351 - acc: 0.8336 - val_loss: 2.3218 - val_acc: 0.7409\n",
      "Epoch 138/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.7320 - acc: 0.8340 - val_loss: 2.3531 - val_acc: 0.7384\n",
      "Epoch 139/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7323 - acc: 0.8342 - val_loss: 2.3205 - val_acc: 0.7411\n",
      "Epoch 140/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7316 - acc: 0.8346 - val_loss: 2.3404 - val_acc: 0.7391\n",
      "Epoch 141/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7307 - acc: 0.8366 - val_loss: 2.3473 - val_acc: 0.7414\n",
      "Epoch 142/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 1.7318 - acc: 0.8348 - val_loss: 2.3367 - val_acc: 0.7368\n",
      "Epoch 143/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7314 - acc: 0.8350 - val_loss: 2.3619 - val_acc: 0.7401\n",
      "Epoch 144/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7301 - acc: 0.8364 - val_loss: 2.3072 - val_acc: 0.7390\n",
      "Epoch 145/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7297 - acc: 0.8350 - val_loss: 2.3585 - val_acc: 0.7422\n",
      "Epoch 146/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7299 - acc: 0.8332 - val_loss: 2.3375 - val_acc: 0.7395\n",
      "Epoch 147/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.7297 - acc: 0.8355 - val_loss: 2.3367 - val_acc: 0.7343\n",
      "Epoch 148/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7300 - acc: 0.8365 - val_loss: 2.2984 - val_acc: 0.7382\n",
      "Epoch 149/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7293 - acc: 0.8365 - val_loss: 2.3616 - val_acc: 0.7377\n",
      "Epoch 150/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7324 - acc: 0.8346 - val_loss: 2.3352 - val_acc: 0.7406\n",
      "Epoch 151/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7305 - acc: 0.8357 - val_loss: 2.3328 - val_acc: 0.7419\n",
      "Epoch 152/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7260 - acc: 0.8375 - val_loss: 2.3346 - val_acc: 0.7409\n",
      "Epoch 153/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7338 - acc: 0.8351 - val_loss: 2.3473 - val_acc: 0.7413\n",
      "Epoch 154/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7292 - acc: 0.8362 - val_loss: 2.3522 - val_acc: 0.7409\n",
      "Epoch 155/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7307 - acc: 0.8351 - val_loss: 2.3316 - val_acc: 0.7336\n",
      "Epoch 156/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 1.7284 - acc: 0.8371 - val_loss: 2.3452 - val_acc: 0.7348\n",
      "Epoch 157/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7327 - acc: 0.8375 - val_loss: 2.3316 - val_acc: 0.7389\n",
      "Epoch 158/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.7309 - acc: 0.8344 - val_loss: 2.3478 - val_acc: 0.7368\n",
      "Epoch 159/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7307 - acc: 0.8367 - val_loss: 2.3767 - val_acc: 0.7363\n",
      "Epoch 160/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7270 - acc: 0.8380 - val_loss: 2.3611 - val_acc: 0.7360\n",
      "Epoch 161/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7257 - acc: 0.8379 - val_loss: 2.3704 - val_acc: 0.7402\n",
      "Epoch 162/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7267 - acc: 0.8367 - val_loss: 2.3555 - val_acc: 0.7370\n",
      "Epoch 163/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.7279 - acc: 0.8373 - val_loss: 2.3736 - val_acc: 0.7371\n",
      "Epoch 164/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7261 - acc: 0.8377 - val_loss: 2.3632 - val_acc: 0.7396\n",
      "Epoch 165/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7283 - acc: 0.8357 - val_loss: 2.3706 - val_acc: 0.7397\n",
      "Epoch 166/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7271 - acc: 0.8364 - val_loss: 2.3643 - val_acc: 0.7366\n",
      "Epoch 167/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7257 - acc: 0.8379 - val_loss: 2.3791 - val_acc: 0.7417\n",
      "Epoch 168/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.7254 - acc: 0.8370 - val_loss: 2.3702 - val_acc: 0.7403\n",
      "Epoch 169/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.7243 - acc: 0.8376 - val_loss: 2.4021 - val_acc: 0.7401\n",
      "Epoch 170/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7277 - acc: 0.8373 - val_loss: 2.3523 - val_acc: 0.7403\n",
      "Epoch 171/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7264 - acc: 0.8365 - val_loss: 2.3909 - val_acc: 0.7343\n",
      "Epoch 172/300\n",
      "24420/24420 [==============================] - 1s 39us/step - loss: 1.7275 - acc: 0.8373 - val_loss: 2.3556 - val_acc: 0.7385\n",
      "Epoch 173/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7268 - acc: 0.8385 - val_loss: 2.3876 - val_acc: 0.7380\n",
      "Epoch 174/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.7252 - acc: 0.8388 - val_loss: 2.4131 - val_acc: 0.7350\n",
      "Epoch 175/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7253 - acc: 0.8382 - val_loss: 2.3717 - val_acc: 0.7402\n",
      "Epoch 176/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.7247 - acc: 0.8386 - val_loss: 2.3973 - val_acc: 0.7392\n",
      "Epoch 177/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7262 - acc: 0.8362 - val_loss: 2.3656 - val_acc: 0.7319\n",
      "Epoch 178/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7262 - acc: 0.8377 - val_loss: 2.3917 - val_acc: 0.7400\n",
      "Epoch 179/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.7251 - acc: 0.8380 - val_loss: 2.3901 - val_acc: 0.7400\n",
      "Epoch 180/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7237 - acc: 0.8378 - val_loss: 2.3907 - val_acc: 0.7366\n",
      "Epoch 181/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7256 - acc: 0.8370 - val_loss: 2.3917 - val_acc: 0.7365\n",
      "Epoch 182/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7266 - acc: 0.8375 - val_loss: 2.3645 - val_acc: 0.7369\n",
      "Epoch 183/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.7230 - acc: 0.8389 - val_loss: 2.4184 - val_acc: 0.7396\n",
      "Epoch 184/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7243 - acc: 0.8374 - val_loss: 2.4126 - val_acc: 0.7385\n",
      "Epoch 185/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.7219 - acc: 0.8389 - val_loss: 2.4146 - val_acc: 0.7341\n",
      "Epoch 186/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.7230 - acc: 0.8396 - val_loss: 2.3726 - val_acc: 0.7381\n",
      "Epoch 187/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7260 - acc: 0.8382 - val_loss: 2.3710 - val_acc: 0.7380\n",
      "Epoch 188/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.7215 - acc: 0.8389 - val_loss: 2.4137 - val_acc: 0.7373\n",
      "Epoch 189/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.7239 - acc: 0.8396 - val_loss: 2.4068 - val_acc: 0.7379\n",
      "Epoch 190/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7221 - acc: 0.8395 - val_loss: 2.4029 - val_acc: 0.7382\n",
      "Epoch 191/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7225 - acc: 0.8396 - val_loss: 2.4111 - val_acc: 0.7360\n",
      "Epoch 192/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7230 - acc: 0.8378 - val_loss: 2.3963 - val_acc: 0.7427\n",
      "Epoch 193/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.7223 - acc: 0.8395 - val_loss: 2.4603 - val_acc: 0.7341\n",
      "Epoch 194/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.7215 - acc: 0.8404 - val_loss: 2.3810 - val_acc: 0.7398\n",
      "Epoch 195/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7244 - acc: 0.8378 - val_loss: 2.4201 - val_acc: 0.7390\n",
      "Epoch 196/300\n",
      "24420/24420 [==============================] - 1s 41us/step - loss: 1.7220 - acc: 0.8393 - val_loss: 2.4381 - val_acc: 0.7397\n",
      "Epoch 197/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7214 - acc: 0.8403 - val_loss: 2.3917 - val_acc: 0.7392\n",
      "Epoch 198/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7224 - acc: 0.8384 - val_loss: 2.4301 - val_acc: 0.7375\n",
      "Epoch 199/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7248 - acc: 0.8387 - val_loss: 2.4547 - val_acc: 0.7371\n",
      "Epoch 200/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.7247 - acc: 0.8385 - val_loss: 2.3974 - val_acc: 0.7386\n",
      "Epoch 201/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7218 - acc: 0.8402 - val_loss: 2.4296 - val_acc: 0.7397\n",
      "Epoch 202/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7183 - acc: 0.8410 - val_loss: 2.4282 - val_acc: 0.7366\n",
      "Epoch 203/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.7222 - acc: 0.8385 - val_loss: 2.4258 - val_acc: 0.7389\n",
      "Epoch 204/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7212 - acc: 0.8388 - val_loss: 2.4371 - val_acc: 0.7407\n",
      "Epoch 205/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.7208 - acc: 0.8403 - val_loss: 2.4487 - val_acc: 0.7386\n",
      "Epoch 206/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7202 - acc: 0.8400 - val_loss: 2.4321 - val_acc: 0.7391\n",
      "Epoch 207/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.7249 - acc: 0.8382 - val_loss: 2.4485 - val_acc: 0.7433\n",
      "Epoch 208/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.7196 - acc: 0.8403 - val_loss: 2.3995 - val_acc: 0.7391\n",
      "Epoch 209/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7208 - acc: 0.8393 - val_loss: 2.4462 - val_acc: 0.7365\n",
      "Epoch 210/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.7202 - acc: 0.8401 - val_loss: 2.4244 - val_acc: 0.7376\n",
      "Epoch 211/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.7201 - acc: 0.8414 - val_loss: 2.4163 - val_acc: 0.7359\n",
      "Epoch 212/300\n",
      "24420/24420 [==============================] - 1s 39us/step - loss: 1.7229 - acc: 0.8387 - val_loss: 2.3907 - val_acc: 0.7406\n",
      "Epoch 213/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.7198 - acc: 0.8403 - val_loss: 2.4419 - val_acc: 0.7401\n",
      "Epoch 214/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.7195 - acc: 0.8411 - val_loss: 2.4484 - val_acc: 0.7419\n",
      "Epoch 215/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7237 - acc: 0.8389 - val_loss: 2.4004 - val_acc: 0.7397\n",
      "Epoch 216/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7230 - acc: 0.8392 - val_loss: 2.4380 - val_acc: 0.7344\n",
      "Epoch 217/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.7207 - acc: 0.8398 - val_loss: 2.4133 - val_acc: 0.7330\n",
      "Epoch 218/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7180 - acc: 0.8411 - val_loss: 2.4843 - val_acc: 0.7366\n",
      "Epoch 219/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7209 - acc: 0.8403 - val_loss: 2.4318 - val_acc: 0.7374\n",
      "Epoch 220/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.7208 - acc: 0.8398 - val_loss: 2.4254 - val_acc: 0.7370\n",
      "Epoch 221/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7192 - acc: 0.8397 - val_loss: 2.3933 - val_acc: 0.7391\n",
      "Epoch 222/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7192 - acc: 0.8415 - val_loss: 2.4206 - val_acc: 0.7363\n",
      "Epoch 223/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7242 - acc: 0.8403 - val_loss: 2.4332 - val_acc: 0.7370\n",
      "Epoch 224/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7275 - acc: 0.8380 - val_loss: 2.3884 - val_acc: 0.7408\n",
      "Epoch 225/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.7198 - acc: 0.8411 - val_loss: 2.4781 - val_acc: 0.7334\n",
      "Epoch 226/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7195 - acc: 0.8393 - val_loss: 2.4351 - val_acc: 0.7392\n",
      "Epoch 227/300\n",
      "24420/24420 [==============================] - 1s 39us/step - loss: 1.7205 - acc: 0.8392 - val_loss: 2.4242 - val_acc: 0.7401\n",
      "Epoch 228/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.7204 - acc: 0.8395 - val_loss: 2.4676 - val_acc: 0.7402\n",
      "Epoch 229/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.7168 - acc: 0.8403 - val_loss: 2.4546 - val_acc: 0.7411\n",
      "Epoch 230/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7192 - acc: 0.8392 - val_loss: 2.4554 - val_acc: 0.7355\n",
      "Epoch 231/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.7201 - acc: 0.8405 - val_loss: 2.4483 - val_acc: 0.7381\n",
      "Epoch 232/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.7190 - acc: 0.8415 - val_loss: 2.4035 - val_acc: 0.7379\n",
      "Epoch 233/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7248 - acc: 0.8379 - val_loss: 2.4286 - val_acc: 0.7384\n",
      "Epoch 234/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.7176 - acc: 0.8416 - val_loss: 2.4182 - val_acc: 0.7322\n",
      "Epoch 235/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.7207 - acc: 0.8406 - val_loss: 2.4258 - val_acc: 0.7397\n",
      "Epoch 236/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.7186 - acc: 0.8396 - val_loss: 2.4665 - val_acc: 0.7377\n",
      "Epoch 237/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7201 - acc: 0.8401 - val_loss: 2.4221 - val_acc: 0.7393\n",
      "Epoch 238/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.7173 - acc: 0.8423 - val_loss: 2.4607 - val_acc: 0.7390\n",
      "Epoch 239/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7180 - acc: 0.8418 - val_loss: 2.4484 - val_acc: 0.7400\n",
      "Epoch 240/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.7210 - acc: 0.8402 - val_loss: 2.4514 - val_acc: 0.7344\n",
      "Epoch 241/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.7189 - acc: 0.8411 - val_loss: 2.4221 - val_acc: 0.7362\n",
      "Epoch 242/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.7172 - acc: 0.8408 - val_loss: 2.4498 - val_acc: 0.7322\n",
      "Epoch 243/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7202 - acc: 0.8400 - val_loss: 2.4734 - val_acc: 0.7346\n",
      "Epoch 244/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.7192 - acc: 0.8411 - val_loss: 2.4517 - val_acc: 0.7377\n",
      "Epoch 245/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7171 - acc: 0.8415 - val_loss: 2.4377 - val_acc: 0.7358\n",
      "Epoch 246/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.7168 - acc: 0.8421 - val_loss: 2.4829 - val_acc: 0.7347\n",
      "Epoch 247/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.7182 - acc: 0.8400 - val_loss: 2.4704 - val_acc: 0.7338\n",
      "Epoch 248/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7199 - acc: 0.8395 - val_loss: 2.4748 - val_acc: 0.7391\n",
      "Epoch 249/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7171 - acc: 0.8403 - val_loss: 2.4543 - val_acc: 0.7371\n",
      "Epoch 250/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7177 - acc: 0.8426 - val_loss: 2.4446 - val_acc: 0.7342\n",
      "Epoch 251/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.7187 - acc: 0.8410 - val_loss: 2.4073 - val_acc: 0.7360\n",
      "Epoch 252/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.7171 - acc: 0.8407 - val_loss: 2.4682 - val_acc: 0.7363\n",
      "Epoch 253/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7170 - acc: 0.8409 - val_loss: 2.4227 - val_acc: 0.7357\n",
      "Epoch 254/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.7165 - acc: 0.8412 - val_loss: 2.4553 - val_acc: 0.7386\n",
      "Epoch 255/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7182 - acc: 0.8423 - val_loss: 2.4398 - val_acc: 0.7389\n",
      "Epoch 256/300\n",
      "24420/24420 [==============================] - 1s 41us/step - loss: 1.7228 - acc: 0.8418 - val_loss: 2.4530 - val_acc: 0.7363\n",
      "Epoch 257/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7163 - acc: 0.8413 - val_loss: 2.4666 - val_acc: 0.7365\n",
      "Epoch 258/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.7155 - acc: 0.8419 - val_loss: 2.4621 - val_acc: 0.7380\n",
      "Epoch 259/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7175 - acc: 0.8410 - val_loss: 2.4614 - val_acc: 0.7387\n",
      "Epoch 260/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.7156 - acc: 0.8424 - val_loss: 2.4694 - val_acc: 0.7359\n",
      "Epoch 261/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.7186 - acc: 0.8421 - val_loss: 2.4527 - val_acc: 0.7392\n",
      "Epoch 262/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7167 - acc: 0.8410 - val_loss: 2.4395 - val_acc: 0.7373\n",
      "Epoch 263/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7176 - acc: 0.8410 - val_loss: 2.4522 - val_acc: 0.7344\n",
      "Epoch 264/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7140 - acc: 0.8421 - val_loss: 2.4742 - val_acc: 0.7358\n",
      "Epoch 265/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7152 - acc: 0.8426 - val_loss: 2.4744 - val_acc: 0.7358\n",
      "Epoch 266/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.7173 - acc: 0.8417 - val_loss: 2.4773 - val_acc: 0.7352\n",
      "Epoch 267/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.7195 - acc: 0.8410 - val_loss: 2.4922 - val_acc: 0.7341\n",
      "Epoch 268/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.7156 - acc: 0.8430 - val_loss: 2.4934 - val_acc: 0.7380\n",
      "Epoch 269/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.7163 - acc: 0.8429 - val_loss: 2.4586 - val_acc: 0.7359\n",
      "Epoch 270/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7160 - acc: 0.8412 - val_loss: 2.4930 - val_acc: 0.7360\n",
      "Epoch 271/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.7162 - acc: 0.8415 - val_loss: 2.4614 - val_acc: 0.7366\n",
      "Epoch 272/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7145 - acc: 0.8419 - val_loss: 2.4644 - val_acc: 0.7376\n",
      "Epoch 273/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7148 - acc: 0.8421 - val_loss: 2.5060 - val_acc: 0.7382\n",
      "Epoch 274/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7164 - acc: 0.8413 - val_loss: 2.4590 - val_acc: 0.7368\n",
      "Epoch 275/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7151 - acc: 0.8419 - val_loss: 2.4782 - val_acc: 0.7380\n",
      "Epoch 276/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7160 - acc: 0.8408 - val_loss: 2.4538 - val_acc: 0.7381\n",
      "Epoch 277/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7148 - acc: 0.8428 - val_loss: 2.5023 - val_acc: 0.7366\n",
      "Epoch 278/300\n",
      "24420/24420 [==============================] - 1s 39us/step - loss: 1.7137 - acc: 0.8418 - val_loss: 2.5477 - val_acc: 0.7377\n",
      "Epoch 279/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7206 - acc: 0.8404 - val_loss: 2.5166 - val_acc: 0.7331\n",
      "Epoch 280/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7161 - acc: 0.8418 - val_loss: 2.5210 - val_acc: 0.7348\n",
      "Epoch 281/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.7143 - acc: 0.8416 - val_loss: 2.4575 - val_acc: 0.7396\n",
      "Epoch 282/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.7140 - acc: 0.8431 - val_loss: 2.4516 - val_acc: 0.7417\n",
      "Epoch 283/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7146 - acc: 0.8422 - val_loss: 2.4930 - val_acc: 0.7375\n",
      "Epoch 284/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7228 - acc: 0.8412 - val_loss: 2.5329 - val_acc: 0.7344\n",
      "Epoch 285/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.7142 - acc: 0.8416 - val_loss: 2.5155 - val_acc: 0.7396\n",
      "Epoch 286/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7138 - acc: 0.8424 - val_loss: 2.4622 - val_acc: 0.7389\n",
      "Epoch 287/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.7131 - acc: 0.8434 - val_loss: 2.4699 - val_acc: 0.7409\n",
      "Epoch 288/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7138 - acc: 0.8434 - val_loss: 2.4908 - val_acc: 0.7387\n",
      "Epoch 289/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7136 - acc: 0.8427 - val_loss: 2.5111 - val_acc: 0.7391\n",
      "Epoch 290/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7138 - acc: 0.8433 - val_loss: 2.5021 - val_acc: 0.7353\n",
      "Epoch 291/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7126 - acc: 0.8421 - val_loss: 2.5192 - val_acc: 0.7391\n",
      "Epoch 292/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7146 - acc: 0.8430 - val_loss: 2.5069 - val_acc: 0.7357\n",
      "Epoch 293/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7161 - acc: 0.8417 - val_loss: 2.4875 - val_acc: 0.7363\n",
      "Epoch 294/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7163 - acc: 0.8428 - val_loss: 2.4887 - val_acc: 0.7381\n",
      "Epoch 295/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7226 - acc: 0.8419 - val_loss: 2.4529 - val_acc: 0.7357\n",
      "Epoch 296/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 1.7117 - acc: 0.8432 - val_loss: 2.4823 - val_acc: 0.7377\n",
      "Epoch 297/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7108 - acc: 0.8441 - val_loss: 2.4610 - val_acc: 0.7404\n",
      "Epoch 298/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7133 - acc: 0.8430 - val_loss: 2.5121 - val_acc: 0.7395\n",
      "Epoch 299/300\n",
      "24420/24420 [==============================] - 1s 39us/step - loss: 1.7117 - acc: 0.8449 - val_loss: 2.5332 - val_acc: 0.7393\n",
      "Epoch 300/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 1.7133 - acc: 0.8430 - val_loss: 2.4887 - val_acc: 0.7366\n"
     ]
    }
   ],
   "source": [
    "model2 = build_model(X_train_a, A_train, X_val_a, A_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report accuracy and reweighted accuracy on the test set of your trained classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.7383453105285459\n"
     ]
    }
   ],
   "source": [
    "score = evaluate_model(model2, X_test_a, A_test)\n",
    "print('Test accuracy:', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reweighted accuracy 0.7421068415136144\n"
     ]
    }
   ],
   "source": [
    "#A_hat=model3.predict(X_test_a)\n",
    "A_hat = predict(model2, X_test_a)\n",
    "\n",
    "print('reweighted accuracy', reweighted_accuracy(A_hat.flatten(), A_test, A_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing 10 most correlated features with A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_attributes = [att for att in top_10_corr_a['sexe'].index]\n",
    "dfa_without_10 = df.drop(top_attributes, axis=1)\n",
    "X_train = df_without_10\n",
    "X_test = df_test.drop(top_attributes, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "#len(X_train)\n",
    "A_train = df_a\n",
    "A_train = np.array(A_train)\n",
    "A_train = A_train.flatten()\n",
    "\n",
    "train_ind = np.random.choice(X_train.shape[0], 3*X_train.shape[0]//4, replace=False) ## choose indexes for train and validation set\n",
    "#A_train[train_ind]\n",
    "#train_ind = np.random.choice(X_train.shape[0], 3*X_train.shape[0]//4, replace=False)\n",
    "X_train, A_train = X_train[train_ind], A_train[train_ind]\n",
    "X_val= dfa_without_10.drop(train_ind, axis=0)\n",
    "A_val = df_a.drop(train_ind)\n",
    "X_val= np.array(X_val)\n",
    "A_val = np.array(A_val)\n",
    "A_val = A_val.flatten()\n",
    "\n",
    "\n",
    "##scaling the data using MinMaxScaler\n",
    "\n",
    "# X_train= scaling_data(X_train)\n",
    "\n",
    "\n",
    "# X_val = scaling_data(X_val)\n",
    "\n",
    "# X_test = scaling_data(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24420 samples, validate on 8141 samples\n",
      "Epoch 1/300\n",
      "24420/24420 [==============================] - 1s 50us/step - loss: 0.5384 - acc: 0.8087 - val_loss: 3.0221 - val_acc: 0.3985\n",
      "Epoch 2/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.5001 - acc: 0.8258 - val_loss: 5.5114 - val_acc: 0.3974\n",
      "Epoch 3/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.4916 - acc: 0.8301 - val_loss: 5.0116 - val_acc: 0.3985\n",
      "Epoch 4/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.4847 - acc: 0.8371 - val_loss: 7.2809 - val_acc: 0.3976\n",
      "Epoch 5/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.4798 - acc: 0.8387 - val_loss: 5.6933 - val_acc: 0.3987\n",
      "Epoch 6/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.4720 - acc: 0.8425 - val_loss: 6.5605 - val_acc: 0.4004\n",
      "Epoch 7/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.4661 - acc: 0.8455 - val_loss: 7.9929 - val_acc: 0.3988\n",
      "Epoch 8/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 0.4595 - acc: 0.8495 - val_loss: 8.9955 - val_acc: 0.3979\n",
      "Epoch 9/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.4539 - acc: 0.8535 - val_loss: 8.4410 - val_acc: 0.3982\n",
      "Epoch 10/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.4487 - acc: 0.8562 - val_loss: 6.1335 - val_acc: 0.4167\n",
      "Epoch 11/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.4427 - acc: 0.8570 - val_loss: 9.2043 - val_acc: 0.3980\n",
      "Epoch 12/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 0.4378 - acc: 0.8593 - val_loss: 8.6659 - val_acc: 0.4028\n",
      "Epoch 13/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.4323 - acc: 0.8620 - val_loss: 9.4006 - val_acc: 0.3986\n",
      "Epoch 14/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.4283 - acc: 0.8637 - val_loss: 9.5569 - val_acc: 0.3979\n",
      "Epoch 15/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.4237 - acc: 0.8668 - val_loss: 8.8207 - val_acc: 0.4076\n",
      "Epoch 16/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.4193 - acc: 0.8684 - val_loss: 9.5620 - val_acc: 0.3984\n",
      "Epoch 17/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.4157 - acc: 0.8696 - val_loss: 9.3106 - val_acc: 0.4033\n",
      "Epoch 18/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 0.4128 - acc: 0.8711 - val_loss: 9.5961 - val_acc: 0.3986\n",
      "Epoch 19/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.4080 - acc: 0.8738 - val_loss: 9.4777 - val_acc: 0.4003\n",
      "Epoch 20/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 0.4074 - acc: 0.8740 - val_loss: 9.5524 - val_acc: 0.3993\n",
      "Epoch 21/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.4020 - acc: 0.8760 - val_loss: 9.6073 - val_acc: 0.3988\n",
      "Epoch 22/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.4013 - acc: 0.8776 - val_loss: 9.6172 - val_acc: 0.3987\n",
      "Epoch 23/300\n",
      "24420/24420 [==============================] - 1s 39us/step - loss: 0.3986 - acc: 0.8783 - val_loss: 9.5292 - val_acc: 0.4017\n",
      "Epoch 24/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 0.3962 - acc: 0.8789 - val_loss: 9.5659 - val_acc: 0.4002\n",
      "Epoch 25/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 0.3946 - acc: 0.8789 - val_loss: 9.6667 - val_acc: 0.3981\n",
      "Epoch 26/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 0.3935 - acc: 0.8806 - val_loss: 9.6167 - val_acc: 0.3995\n",
      "Epoch 27/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.3912 - acc: 0.8809 - val_loss: 9.4299 - val_acc: 0.4031\n",
      "Epoch 28/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 0.3896 - acc: 0.8831 - val_loss: 9.6182 - val_acc: 0.3992\n",
      "Epoch 29/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.3887 - acc: 0.8823 - val_loss: 9.5502 - val_acc: 0.4013\n",
      "Epoch 30/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.3866 - acc: 0.8837 - val_loss: 9.6308 - val_acc: 0.3995\n",
      "Epoch 31/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.3866 - acc: 0.8838 - val_loss: 9.2852 - val_acc: 0.4087\n",
      "Epoch 32/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.3846 - acc: 0.8849 - val_loss: 9.5513 - val_acc: 0.4018\n",
      "Epoch 33/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.3860 - acc: 0.8856 - val_loss: 9.6660 - val_acc: 0.3987\n",
      "Epoch 34/300\n",
      "24420/24420 [==============================] - 1s 46us/step - loss: 0.3831 - acc: 0.8845 - val_loss: 9.4614 - val_acc: 0.4047\n",
      "Epoch 35/300\n",
      "24420/24420 [==============================] - 1s 51us/step - loss: 0.7368 - acc: 0.8615 - val_loss: 9.9868 - val_acc: 0.3771\n",
      "Epoch 36/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 0.7748 - acc: 0.8627 - val_loss: 10.0236 - val_acc: 0.3764\n",
      "Epoch 37/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 0.7746 - acc: 0.8625 - val_loss: 10.0006 - val_acc: 0.3767\n",
      "Epoch 38/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 0.7743 - acc: 0.8624 - val_loss: 9.7082 - val_acc: 0.3829\n",
      "Epoch 39/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7735 - acc: 0.8606 - val_loss: 9.9285 - val_acc: 0.3792\n",
      "Epoch 40/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.7717 - acc: 0.8623 - val_loss: 10.0282 - val_acc: 0.3764\n",
      "Epoch 41/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 0.7722 - acc: 0.8619 - val_loss: 9.9863 - val_acc: 0.3776\n",
      "Epoch 42/300\n",
      "24420/24420 [==============================] - 1s 39us/step - loss: 0.7722 - acc: 0.8612 - val_loss: 9.9496 - val_acc: 0.3789\n",
      "Epoch 43/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 0.7705 - acc: 0.8619 - val_loss: 10.0172 - val_acc: 0.3767\n",
      "Epoch 44/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 0.7705 - acc: 0.8624 - val_loss: 9.8909 - val_acc: 0.3794\n",
      "Epoch 45/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.7704 - acc: 0.8633 - val_loss: 10.0072 - val_acc: 0.3766\n",
      "Epoch 46/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.7699 - acc: 0.8620 - val_loss: 10.0485 - val_acc: 0.3751\n",
      "Epoch 47/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 0.7684 - acc: 0.8626 - val_loss: 9.9887 - val_acc: 0.3778\n",
      "Epoch 48/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.7706 - acc: 0.8621 - val_loss: 10.0520 - val_acc: 0.3750\n",
      "Epoch 49/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7702 - acc: 0.8608 - val_loss: 10.0223 - val_acc: 0.3762\n",
      "Epoch 50/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7678 - acc: 0.8634 - val_loss: 10.0450 - val_acc: 0.3754\n",
      "Epoch 51/300\n",
      "24420/24420 [==============================] - 1s 35us/step - loss: 0.7678 - acc: 0.8617 - val_loss: 10.0256 - val_acc: 0.3764\n",
      "Epoch 52/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.7678 - acc: 0.8624 - val_loss: 10.0017 - val_acc: 0.3776\n",
      "Epoch 53/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7674 - acc: 0.8635 - val_loss: 9.9532 - val_acc: 0.3791\n",
      "Epoch 54/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.7674 - acc: 0.8640 - val_loss: 10.0310 - val_acc: 0.3764\n",
      "Epoch 55/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.7662 - acc: 0.8648 - val_loss: 10.0224 - val_acc: 0.3769\n",
      "Epoch 56/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.7656 - acc: 0.8628 - val_loss: 9.9722 - val_acc: 0.3785\n",
      "Epoch 57/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 0.7660 - acc: 0.8633 - val_loss: 9.9882 - val_acc: 0.3776\n",
      "Epoch 58/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.7651 - acc: 0.8638 - val_loss: 9.9625 - val_acc: 0.3788\n",
      "Epoch 59/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.7653 - acc: 0.8631 - val_loss: 9.9940 - val_acc: 0.3773\n",
      "Epoch 60/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7657 - acc: 0.8634 - val_loss: 9.9767 - val_acc: 0.3792\n",
      "Epoch 61/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.7653 - acc: 0.8631 - val_loss: 9.9834 - val_acc: 0.3783\n",
      "Epoch 62/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.7667 - acc: 0.8656 - val_loss: 10.0064 - val_acc: 0.3772\n",
      "Epoch 63/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.7639 - acc: 0.8650 - val_loss: 9.9738 - val_acc: 0.3796\n",
      "Epoch 64/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 0.7641 - acc: 0.8645 - val_loss: 9.9365 - val_acc: 0.3799\n",
      "Epoch 65/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.7633 - acc: 0.8636 - val_loss: 9.9782 - val_acc: 0.3791\n",
      "Epoch 66/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7634 - acc: 0.8639 - val_loss: 9.9187 - val_acc: 0.3805\n",
      "Epoch 67/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.7632 - acc: 0.8624 - val_loss: 9.9722 - val_acc: 0.3794\n",
      "Epoch 68/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.7625 - acc: 0.8644 - val_loss: 9.9818 - val_acc: 0.3789\n",
      "Epoch 69/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.7635 - acc: 0.8645 - val_loss: 9.9903 - val_acc: 0.3778\n",
      "Epoch 70/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.7627 - acc: 0.8643 - val_loss: 9.8014 - val_acc: 0.3847\n",
      "Epoch 71/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.7622 - acc: 0.8635 - val_loss: 9.9862 - val_acc: 0.3786\n",
      "Epoch 72/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.7624 - acc: 0.8649 - val_loss: 9.9904 - val_acc: 0.3780\n",
      "Epoch 73/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7622 - acc: 0.8656 - val_loss: 9.9520 - val_acc: 0.3791\n",
      "Epoch 74/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7618 - acc: 0.8636 - val_loss: 9.8509 - val_acc: 0.3839\n",
      "Epoch 75/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.7616 - acc: 0.8645 - val_loss: 9.9689 - val_acc: 0.3788\n",
      "Epoch 76/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7609 - acc: 0.8641 - val_loss: 10.0294 - val_acc: 0.3766\n",
      "Epoch 77/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.7610 - acc: 0.8640 - val_loss: 10.0131 - val_acc: 0.3769\n",
      "Epoch 78/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.7603 - acc: 0.8632 - val_loss: 9.9625 - val_acc: 0.3793\n",
      "Epoch 79/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.7618 - acc: 0.8653 - val_loss: 10.0018 - val_acc: 0.3778\n",
      "Epoch 80/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 0.7624 - acc: 0.8636 - val_loss: 9.9048 - val_acc: 0.3820\n",
      "Epoch 81/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.7594 - acc: 0.8659 - val_loss: 10.0010 - val_acc: 0.3775\n",
      "Epoch 82/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.7596 - acc: 0.8654 - val_loss: 9.9276 - val_acc: 0.3801\n",
      "Epoch 83/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.7594 - acc: 0.8657 - val_loss: 9.9760 - val_acc: 0.3793\n",
      "Epoch 84/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7596 - acc: 0.8648 - val_loss: 10.0113 - val_acc: 0.3775\n",
      "Epoch 85/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 0.7599 - acc: 0.8641 - val_loss: 9.9761 - val_acc: 0.3789\n",
      "Epoch 86/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.7596 - acc: 0.8649 - val_loss: 10.0213 - val_acc: 0.3772\n",
      "Epoch 87/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7588 - acc: 0.8649 - val_loss: 9.9868 - val_acc: 0.3789\n",
      "Epoch 88/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.7592 - acc: 0.8651 - val_loss: 9.9833 - val_acc: 0.3791\n",
      "Epoch 89/300\n",
      "24420/24420 [==============================] - 1s 41us/step - loss: 0.7592 - acc: 0.8653 - val_loss: 9.9999 - val_acc: 0.3781\n",
      "Epoch 90/300\n",
      "24420/24420 [==============================] - 1s 45us/step - loss: 0.7590 - acc: 0.8647 - val_loss: 9.9845 - val_acc: 0.3793\n",
      "Epoch 91/300\n",
      "24420/24420 [==============================] - 1s 46us/step - loss: 0.7590 - acc: 0.8653 - val_loss: 10.0223 - val_acc: 0.3770\n",
      "Epoch 92/300\n",
      "24420/24420 [==============================] - 1s 45us/step - loss: 0.7629 - acc: 0.8643 - val_loss: 9.9436 - val_acc: 0.3805\n",
      "Epoch 93/300\n",
      "24420/24420 [==============================] - 1s 44us/step - loss: 0.7632 - acc: 0.8645 - val_loss: 10.0227 - val_acc: 0.3767\n",
      "Epoch 94/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.7573 - acc: 0.8649 - val_loss: 9.9752 - val_acc: 0.3796\n",
      "Epoch 95/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.7563 - acc: 0.8659 - val_loss: 10.0103 - val_acc: 0.3773\n",
      "Epoch 96/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7568 - acc: 0.8644 - val_loss: 10.0203 - val_acc: 0.3769\n",
      "Epoch 97/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7576 - acc: 0.8659 - val_loss: 9.9909 - val_acc: 0.3791\n",
      "Epoch 98/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7578 - acc: 0.8657 - val_loss: 10.0040 - val_acc: 0.3781\n",
      "Epoch 99/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7581 - acc: 0.8648 - val_loss: 10.0062 - val_acc: 0.3773\n",
      "Epoch 100/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7618 - acc: 0.8649 - val_loss: 10.0325 - val_acc: 0.3769\n",
      "Epoch 101/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.7602 - acc: 0.8656 - val_loss: 10.0482 - val_acc: 0.3754\n",
      "Epoch 102/300\n",
      "24420/24420 [==============================] - 1s 39us/step - loss: 0.7562 - acc: 0.8667 - val_loss: 10.0342 - val_acc: 0.3765\n",
      "Epoch 103/300\n",
      "24420/24420 [==============================] - 1s 42us/step - loss: 0.7561 - acc: 0.8658 - val_loss: 10.0196 - val_acc: 0.3773\n",
      "Epoch 104/300\n",
      "24420/24420 [==============================] - 1s 39us/step - loss: 0.7569 - acc: 0.8663 - val_loss: 10.0100 - val_acc: 0.3777\n",
      "Epoch 105/300\n",
      "24420/24420 [==============================] - 1s 40us/step - loss: 0.7561 - acc: 0.8658 - val_loss: 10.0166 - val_acc: 0.3771\n",
      "Epoch 106/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7614 - acc: 0.8650 - val_loss: 10.0364 - val_acc: 0.3764\n",
      "Epoch 107/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7577 - acc: 0.8654 - val_loss: 10.0428 - val_acc: 0.3764\n",
      "Epoch 108/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7564 - acc: 0.8665 - val_loss: 10.0329 - val_acc: 0.3761\n",
      "Epoch 109/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7561 - acc: 0.8666 - val_loss: 10.0346 - val_acc: 0.3765\n",
      "Epoch 110/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7563 - acc: 0.8658 - val_loss: 10.0454 - val_acc: 0.3760\n",
      "Epoch 111/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7560 - acc: 0.8649 - val_loss: 10.0309 - val_acc: 0.3765\n",
      "Epoch 112/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7563 - acc: 0.8662 - val_loss: 10.0515 - val_acc: 0.3759\n",
      "Epoch 113/300\n",
      "24420/24420 [==============================] - 1s 44us/step - loss: 0.7564 - acc: 0.8661 - val_loss: 10.0129 - val_acc: 0.3776\n",
      "Epoch 114/300\n",
      "24420/24420 [==============================] - 1s 44us/step - loss: 0.7567 - acc: 0.8663 - val_loss: 10.0121 - val_acc: 0.3780\n",
      "Epoch 115/300\n",
      "24420/24420 [==============================] - 1s 41us/step - loss: 0.7560 - acc: 0.8661 - val_loss: 10.0143 - val_acc: 0.3775\n",
      "Epoch 116/300\n",
      "24420/24420 [==============================] - 1s 43us/step - loss: 0.7564 - acc: 0.8659 - val_loss: 9.9978 - val_acc: 0.3786\n",
      "Epoch 117/300\n",
      "24420/24420 [==============================] - 1s 41us/step - loss: 0.7553 - acc: 0.8661 - val_loss: 10.0142 - val_acc: 0.3775\n",
      "Epoch 118/300\n",
      "24420/24420 [==============================] - 1s 39us/step - loss: 0.7559 - acc: 0.8661 - val_loss: 10.0081 - val_acc: 0.3776\n",
      "Epoch 119/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.7557 - acc: 0.8663 - val_loss: 9.9857 - val_acc: 0.3792\n",
      "Epoch 120/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 0.7560 - acc: 0.8665 - val_loss: 10.0245 - val_acc: 0.3770\n",
      "Epoch 121/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7561 - acc: 0.8663 - val_loss: 10.0469 - val_acc: 0.3761\n",
      "Epoch 122/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7554 - acc: 0.8659 - val_loss: 10.0192 - val_acc: 0.3772\n",
      "Epoch 123/300\n",
      "24420/24420 [==============================] - 1s 42us/step - loss: 0.7550 - acc: 0.8659 - val_loss: 10.0393 - val_acc: 0.3764\n",
      "Epoch 124/300\n",
      "24420/24420 [==============================] - 1s 40us/step - loss: 0.7585 - acc: 0.8656 - val_loss: 9.9646 - val_acc: 0.3804\n",
      "Epoch 125/300\n",
      "24420/24420 [==============================] - 1s 40us/step - loss: 0.7568 - acc: 0.8652 - val_loss: 10.0296 - val_acc: 0.3764\n",
      "Epoch 126/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 0.7543 - acc: 0.8664 - val_loss: 10.0317 - val_acc: 0.3761\n",
      "Epoch 127/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 0.7540 - acc: 0.8665 - val_loss: 10.0270 - val_acc: 0.3764\n",
      "Epoch 128/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 0.7546 - acc: 0.8664 - val_loss: 10.0525 - val_acc: 0.3758\n",
      "Epoch 129/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7543 - acc: 0.8679 - val_loss: 10.0188 - val_acc: 0.3767\n",
      "Epoch 130/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 0.7575 - acc: 0.8661 - val_loss: 10.0487 - val_acc: 0.3759\n",
      "Epoch 131/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 0.7578 - acc: 0.8672 - val_loss: 10.0335 - val_acc: 0.3760\n",
      "Epoch 132/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7554 - acc: 0.8671 - val_loss: 10.0576 - val_acc: 0.3753\n",
      "Epoch 133/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 0.7541 - acc: 0.8667 - val_loss: 10.0434 - val_acc: 0.3760\n",
      "Epoch 134/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 0.7536 - acc: 0.8672 - val_loss: 10.0191 - val_acc: 0.3771\n",
      "Epoch 135/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7538 - acc: 0.8667 - val_loss: 10.0181 - val_acc: 0.3771\n",
      "Epoch 136/300\n",
      "24420/24420 [==============================] - 1s 42us/step - loss: 0.7539 - acc: 0.8673 - val_loss: 10.0391 - val_acc: 0.3761\n",
      "Epoch 137/300\n",
      "24420/24420 [==============================] - 1s 43us/step - loss: 0.7542 - acc: 0.8669 - val_loss: 10.0495 - val_acc: 0.3758\n",
      "Epoch 138/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 0.7570 - acc: 0.8671 - val_loss: 10.0409 - val_acc: 0.3761\n",
      "Epoch 139/300\n",
      "24420/24420 [==============================] - 1s 41us/step - loss: 0.7573 - acc: 0.8662 - val_loss: 9.8341 - val_acc: 0.3861\n",
      "Epoch 140/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7549 - acc: 0.8671 - val_loss: 10.0075 - val_acc: 0.3778\n",
      "Epoch 141/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7534 - acc: 0.8675 - val_loss: 10.0124 - val_acc: 0.3776\n",
      "Epoch 142/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7534 - acc: 0.8676 - val_loss: 10.0230 - val_acc: 0.3765\n",
      "Epoch 143/300\n",
      "24420/24420 [==============================] - 1s 41us/step - loss: 0.7532 - acc: 0.8670 - val_loss: 10.0326 - val_acc: 0.3764\n",
      "Epoch 144/300\n",
      "24420/24420 [==============================] - 1s 40us/step - loss: 0.7548 - acc: 0.8665 - val_loss: 10.0370 - val_acc: 0.3764\n",
      "Epoch 145/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7552 - acc: 0.8671 - val_loss: 9.9632 - val_acc: 0.3807\n",
      "Epoch 146/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.7533 - acc: 0.8674 - val_loss: 9.9853 - val_acc: 0.3788\n",
      "Epoch 147/300\n",
      "24420/24420 [==============================] - 1s 39us/step - loss: 0.7537 - acc: 0.8673 - val_loss: 10.0220 - val_acc: 0.3770\n",
      "Epoch 148/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7536 - acc: 0.8679 - val_loss: 10.0412 - val_acc: 0.3762\n",
      "Epoch 149/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.7545 - acc: 0.8672 - val_loss: 10.0076 - val_acc: 0.3780\n",
      "Epoch 150/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7537 - acc: 0.8662 - val_loss: 10.0384 - val_acc: 0.3764\n",
      "Epoch 151/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7545 - acc: 0.8661 - val_loss: 10.0475 - val_acc: 0.3760\n",
      "Epoch 152/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7540 - acc: 0.8672 - val_loss: 10.0377 - val_acc: 0.3765\n",
      "Epoch 153/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.7534 - acc: 0.8677 - val_loss: 10.0270 - val_acc: 0.3773\n",
      "Epoch 154/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 0.7549 - acc: 0.8670 - val_loss: 9.9898 - val_acc: 0.3796\n",
      "Epoch 155/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7548 - acc: 0.8677 - val_loss: 10.0154 - val_acc: 0.3777\n",
      "Epoch 156/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7528 - acc: 0.8678 - val_loss: 9.9770 - val_acc: 0.3798\n",
      "Epoch 157/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 0.7533 - acc: 0.8676 - val_loss: 9.9447 - val_acc: 0.3815\n",
      "Epoch 158/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7530 - acc: 0.8676 - val_loss: 10.0134 - val_acc: 0.3776\n",
      "Epoch 159/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 0.7547 - acc: 0.8665 - val_loss: 9.7686 - val_acc: 0.3889\n",
      "Epoch 160/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.7537 - acc: 0.8675 - val_loss: 10.0104 - val_acc: 0.3778\n",
      "Epoch 161/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.7527 - acc: 0.8682 - val_loss: 10.0388 - val_acc: 0.3766\n",
      "Epoch 162/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7528 - acc: 0.8675 - val_loss: 10.0206 - val_acc: 0.3772\n",
      "Epoch 163/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7533 - acc: 0.8669 - val_loss: 9.9909 - val_acc: 0.3787\n",
      "Epoch 164/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7533 - acc: 0.8676 - val_loss: 9.9951 - val_acc: 0.3786\n",
      "Epoch 165/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7528 - acc: 0.8680 - val_loss: 9.9738 - val_acc: 0.3801\n",
      "Epoch 166/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7537 - acc: 0.8674 - val_loss: 9.9913 - val_acc: 0.3792\n",
      "Epoch 167/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7531 - acc: 0.8681 - val_loss: 9.9454 - val_acc: 0.3818\n",
      "Epoch 168/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7573 - acc: 0.8665 - val_loss: 9.9385 - val_acc: 0.3820\n",
      "Epoch 169/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7545 - acc: 0.8670 - val_loss: 9.9930 - val_acc: 0.3786\n",
      "Epoch 170/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.7523 - acc: 0.8675 - val_loss: 9.9794 - val_acc: 0.3801\n",
      "Epoch 171/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 0.7518 - acc: 0.8680 - val_loss: 9.9660 - val_acc: 0.3808\n",
      "Epoch 172/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.7517 - acc: 0.8682 - val_loss: 9.9526 - val_acc: 0.3812\n",
      "Epoch 173/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7530 - acc: 0.8681 - val_loss: 10.0170 - val_acc: 0.3776\n",
      "Epoch 174/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.7531 - acc: 0.8672 - val_loss: 9.9613 - val_acc: 0.3809\n",
      "Epoch 175/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.7534 - acc: 0.8676 - val_loss: 10.0007 - val_acc: 0.3785\n",
      "Epoch 176/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.7526 - acc: 0.8678 - val_loss: 9.9940 - val_acc: 0.3787\n",
      "Epoch 177/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7522 - acc: 0.8668 - val_loss: 9.9911 - val_acc: 0.3792\n",
      "Epoch 178/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.7530 - acc: 0.8666 - val_loss: 9.9684 - val_acc: 0.3803\n",
      "Epoch 179/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.7534 - acc: 0.8683 - val_loss: 10.0146 - val_acc: 0.3777\n",
      "Epoch 180/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.7541 - acc: 0.8667 - val_loss: 10.0147 - val_acc: 0.3776\n",
      "Epoch 181/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7519 - acc: 0.8686 - val_loss: 10.0147 - val_acc: 0.3778\n",
      "Epoch 182/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7518 - acc: 0.8672 - val_loss: 10.0059 - val_acc: 0.3783\n",
      "Epoch 183/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 0.7518 - acc: 0.8672 - val_loss: 9.9893 - val_acc: 0.3787\n",
      "Epoch 184/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7534 - acc: 0.8676 - val_loss: 10.0179 - val_acc: 0.3778\n",
      "Epoch 185/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7544 - acc: 0.8670 - val_loss: 9.9675 - val_acc: 0.3804\n",
      "Epoch 186/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7526 - acc: 0.8677 - val_loss: 10.0545 - val_acc: 0.3756\n",
      "Epoch 187/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7514 - acc: 0.8676 - val_loss: 10.0160 - val_acc: 0.3775\n",
      "Epoch 188/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7539 - acc: 0.8674 - val_loss: 10.0395 - val_acc: 0.3762\n",
      "Epoch 189/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.7520 - acc: 0.8686 - val_loss: 10.0505 - val_acc: 0.3759\n",
      "Epoch 190/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7516 - acc: 0.8673 - val_loss: 10.0344 - val_acc: 0.3767\n",
      "Epoch 191/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.7554 - acc: 0.8670 - val_loss: 10.0222 - val_acc: 0.3772\n",
      "Epoch 192/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7524 - acc: 0.8681 - val_loss: 10.0434 - val_acc: 0.3764\n",
      "Epoch 193/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7511 - acc: 0.8681 - val_loss: 10.0260 - val_acc: 0.3770\n",
      "Epoch 194/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.7519 - acc: 0.8676 - val_loss: 10.0006 - val_acc: 0.3785\n",
      "Epoch 195/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7517 - acc: 0.8686 - val_loss: 10.0318 - val_acc: 0.3766\n",
      "Epoch 196/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 0.7520 - acc: 0.8688 - val_loss: 10.0362 - val_acc: 0.3765\n",
      "Epoch 197/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7519 - acc: 0.8686 - val_loss: 10.0229 - val_acc: 0.3771\n",
      "Epoch 198/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7524 - acc: 0.8676 - val_loss: 10.0495 - val_acc: 0.3760\n",
      "Epoch 199/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7549 - acc: 0.8675 - val_loss: 10.0547 - val_acc: 0.3759\n",
      "Epoch 200/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7547 - acc: 0.8680 - val_loss: 10.0213 - val_acc: 0.3777\n",
      "Epoch 201/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7537 - acc: 0.8677 - val_loss: 10.0449 - val_acc: 0.3764\n",
      "Epoch 202/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 0.7527 - acc: 0.8676 - val_loss: 10.0453 - val_acc: 0.3764\n",
      "Epoch 203/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7536 - acc: 0.8681 - val_loss: 10.0138 - val_acc: 0.3780\n",
      "Epoch 204/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7521 - acc: 0.8682 - val_loss: 10.0178 - val_acc: 0.3778\n",
      "Epoch 205/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7501 - acc: 0.8683 - val_loss: 10.0192 - val_acc: 0.3777\n",
      "Epoch 206/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.7508 - acc: 0.8679 - val_loss: 10.0169 - val_acc: 0.3778\n",
      "Epoch 207/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7513 - acc: 0.8683 - val_loss: 10.0084 - val_acc: 0.3781\n",
      "Epoch 208/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7516 - acc: 0.8681 - val_loss: 10.0073 - val_acc: 0.3783\n",
      "Epoch 209/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.7517 - acc: 0.8692 - val_loss: 10.0383 - val_acc: 0.3769\n",
      "Epoch 210/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7540 - acc: 0.8676 - val_loss: 10.0574 - val_acc: 0.3756\n",
      "Epoch 211/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.7567 - acc: 0.8674 - val_loss: 10.0077 - val_acc: 0.3776\n",
      "Epoch 212/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7541 - acc: 0.8691 - val_loss: 9.9928 - val_acc: 0.3793\n",
      "Epoch 213/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7515 - acc: 0.8674 - val_loss: 10.0299 - val_acc: 0.3767\n",
      "Epoch 214/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7507 - acc: 0.8683 - val_loss: 10.0227 - val_acc: 0.3770\n",
      "Epoch 215/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7509 - acc: 0.8690 - val_loss: 10.0084 - val_acc: 0.3782\n",
      "Epoch 216/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7516 - acc: 0.8685 - val_loss: 10.0164 - val_acc: 0.3780\n",
      "Epoch 217/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7512 - acc: 0.8684 - val_loss: 9.9581 - val_acc: 0.3816\n",
      "Epoch 218/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7512 - acc: 0.8686 - val_loss: 9.9474 - val_acc: 0.3816\n",
      "Epoch 219/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7525 - acc: 0.8686 - val_loss: 9.9590 - val_acc: 0.3812\n",
      "Epoch 220/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7568 - acc: 0.8671 - val_loss: 10.0275 - val_acc: 0.3776\n",
      "Epoch 221/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.7521 - acc: 0.8679 - val_loss: 10.0285 - val_acc: 0.3771\n",
      "Epoch 222/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7538 - acc: 0.8681 - val_loss: 10.0491 - val_acc: 0.3758\n",
      "Epoch 223/300\n",
      "24420/24420 [==============================] - 1s 39us/step - loss: 0.7509 - acc: 0.8690 - val_loss: 10.0345 - val_acc: 0.3767\n",
      "Epoch 224/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7506 - acc: 0.8690 - val_loss: 10.0140 - val_acc: 0.3777\n",
      "Epoch 225/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.7503 - acc: 0.8683 - val_loss: 10.0393 - val_acc: 0.3764\n",
      "Epoch 226/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 0.7512 - acc: 0.8691 - val_loss: 10.0299 - val_acc: 0.3771\n",
      "Epoch 227/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7509 - acc: 0.8676 - val_loss: 10.0192 - val_acc: 0.3776\n",
      "Epoch 228/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7514 - acc: 0.8683 - val_loss: 9.9824 - val_acc: 0.3796\n",
      "Epoch 229/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7519 - acc: 0.8681 - val_loss: 10.0004 - val_acc: 0.3788\n",
      "Epoch 230/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7518 - acc: 0.8679 - val_loss: 10.0135 - val_acc: 0.3777\n",
      "Epoch 231/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7522 - acc: 0.8690 - val_loss: 10.0266 - val_acc: 0.3773\n",
      "Epoch 232/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7510 - acc: 0.8684 - val_loss: 10.0100 - val_acc: 0.3785\n",
      "Epoch 233/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7507 - acc: 0.8693 - val_loss: 10.0328 - val_acc: 0.3767\n",
      "Epoch 234/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7524 - acc: 0.8684 - val_loss: 10.0477 - val_acc: 0.3760\n",
      "Epoch 235/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7560 - acc: 0.8681 - val_loss: 10.0134 - val_acc: 0.3781\n",
      "Epoch 236/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7523 - acc: 0.8688 - val_loss: 9.9721 - val_acc: 0.3802\n",
      "Epoch 237/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7513 - acc: 0.8688 - val_loss: 9.9975 - val_acc: 0.3791\n",
      "Epoch 238/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7501 - acc: 0.8681 - val_loss: 10.0042 - val_acc: 0.3785\n",
      "Epoch 239/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7501 - acc: 0.8683 - val_loss: 9.9942 - val_acc: 0.3793\n",
      "Epoch 240/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7504 - acc: 0.8682 - val_loss: 9.9623 - val_acc: 0.3810\n",
      "Epoch 241/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7529 - acc: 0.8687 - val_loss: 10.0139 - val_acc: 0.3778\n",
      "Epoch 242/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7513 - acc: 0.8688 - val_loss: 9.9595 - val_acc: 0.3814\n",
      "Epoch 243/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7523 - acc: 0.8686 - val_loss: 9.9791 - val_acc: 0.3802\n",
      "Epoch 244/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7515 - acc: 0.8688 - val_loss: 9.9162 - val_acc: 0.3835\n",
      "Epoch 245/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7502 - acc: 0.8690 - val_loss: 9.9766 - val_acc: 0.3801\n",
      "Epoch 246/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7506 - acc: 0.8676 - val_loss: 10.0253 - val_acc: 0.3771\n",
      "Epoch 247/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7517 - acc: 0.8688 - val_loss: 9.9492 - val_acc: 0.3816\n",
      "Epoch 248/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 0.7522 - acc: 0.8684 - val_loss: 10.0342 - val_acc: 0.3771\n",
      "Epoch 249/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7540 - acc: 0.8673 - val_loss: 10.0458 - val_acc: 0.3762\n",
      "Epoch 250/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7519 - acc: 0.8681 - val_loss: 10.0314 - val_acc: 0.3771\n",
      "Epoch 251/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7502 - acc: 0.8697 - val_loss: 10.0116 - val_acc: 0.3781\n",
      "Epoch 252/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7499 - acc: 0.8694 - val_loss: 10.0137 - val_acc: 0.3781\n",
      "Epoch 253/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7501 - acc: 0.8689 - val_loss: 9.9938 - val_acc: 0.3788\n",
      "Epoch 254/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7509 - acc: 0.8673 - val_loss: 10.0167 - val_acc: 0.3778\n",
      "Epoch 255/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7513 - acc: 0.8687 - val_loss: 10.0042 - val_acc: 0.3783\n",
      "Epoch 256/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7515 - acc: 0.8695 - val_loss: 9.9835 - val_acc: 0.3799\n",
      "Epoch 257/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 0.7552 - acc: 0.8670 - val_loss: 9.4624 - val_acc: 0.4103\n",
      "Epoch 258/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7551 - acc: 0.8682 - val_loss: 9.8447 - val_acc: 0.3880\n",
      "Epoch 259/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 0.7504 - acc: 0.8687 - val_loss: 9.9337 - val_acc: 0.3828\n",
      "Epoch 260/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7525 - acc: 0.8685 - val_loss: 9.9847 - val_acc: 0.3796\n",
      "Epoch 261/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7538 - acc: 0.8681 - val_loss: 9.9418 - val_acc: 0.3821\n",
      "Epoch 262/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7499 - acc: 0.8698 - val_loss: 9.9405 - val_acc: 0.3821\n",
      "Epoch 263/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7493 - acc: 0.8697 - val_loss: 9.9666 - val_acc: 0.3809\n",
      "Epoch 264/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 0.7500 - acc: 0.8695 - val_loss: 9.9434 - val_acc: 0.3821\n",
      "Epoch 265/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 0.7510 - acc: 0.8688 - val_loss: 9.9715 - val_acc: 0.3807\n",
      "Epoch 266/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 0.7506 - acc: 0.8692 - val_loss: 9.9686 - val_acc: 0.3808\n",
      "Epoch 267/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7519 - acc: 0.8696 - val_loss: 9.9817 - val_acc: 0.3801\n",
      "Epoch 268/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7508 - acc: 0.8690 - val_loss: 9.9862 - val_acc: 0.3798\n",
      "Epoch 269/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 0.7509 - acc: 0.8691 - val_loss: 9.9564 - val_acc: 0.3814\n",
      "Epoch 270/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7526 - acc: 0.8679 - val_loss: 9.4322 - val_acc: 0.4092\n",
      "Epoch 271/300\n",
      "24420/24420 [==============================] - 1s 39us/step - loss: 0.7533 - acc: 0.8687 - val_loss: 9.8832 - val_acc: 0.3848\n",
      "Epoch 272/300\n",
      "24420/24420 [==============================] - 1s 39us/step - loss: 0.7527 - acc: 0.8688 - val_loss: 10.0143 - val_acc: 0.3783\n",
      "Epoch 273/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 0.7504 - acc: 0.8697 - val_loss: 10.0062 - val_acc: 0.3781\n",
      "Epoch 274/300\n",
      "24420/24420 [==============================] - 1s 39us/step - loss: 0.7498 - acc: 0.8690 - val_loss: 9.9991 - val_acc: 0.3788\n",
      "Epoch 275/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7502 - acc: 0.8687 - val_loss: 9.9696 - val_acc: 0.3804\n",
      "Epoch 276/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 0.7501 - acc: 0.8697 - val_loss: 9.9855 - val_acc: 0.3797\n",
      "Epoch 277/300\n",
      "24420/24420 [==============================] - 1s 40us/step - loss: 0.7504 - acc: 0.8695 - val_loss: 9.9308 - val_acc: 0.3828\n",
      "Epoch 278/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 0.7512 - acc: 0.8709 - val_loss: 9.9865 - val_acc: 0.3797\n",
      "Epoch 279/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7508 - acc: 0.8695 - val_loss: 9.9825 - val_acc: 0.3799\n",
      "Epoch 280/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 0.7512 - acc: 0.8696 - val_loss: 10.0359 - val_acc: 0.3769\n",
      "Epoch 281/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7526 - acc: 0.8676 - val_loss: 10.0596 - val_acc: 0.3754\n",
      "Epoch 282/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7517 - acc: 0.8690 - val_loss: 9.9639 - val_acc: 0.3805\n",
      "Epoch 283/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 0.7514 - acc: 0.8697 - val_loss: 9.8499 - val_acc: 0.3878\n",
      "Epoch 284/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7499 - acc: 0.8686 - val_loss: 9.9243 - val_acc: 0.3829\n",
      "Epoch 285/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7498 - acc: 0.8696 - val_loss: 9.9690 - val_acc: 0.3807\n",
      "Epoch 286/300\n",
      "24420/24420 [==============================] - 1s 39us/step - loss: 0.7499 - acc: 0.8690 - val_loss: 9.9791 - val_acc: 0.3801\n",
      "Epoch 287/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 0.7511 - acc: 0.8698 - val_loss: 9.9835 - val_acc: 0.3798\n",
      "Epoch 288/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7505 - acc: 0.8690 - val_loss: 9.9824 - val_acc: 0.3798\n",
      "Epoch 289/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7511 - acc: 0.8682 - val_loss: 10.0196 - val_acc: 0.3778\n",
      "Epoch 290/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7513 - acc: 0.8684 - val_loss: 9.5717 - val_acc: 0.4034\n",
      "Epoch 291/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7523 - acc: 0.8694 - val_loss: 9.9876 - val_acc: 0.3797\n",
      "Epoch 292/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7533 - acc: 0.8688 - val_loss: 9.3804 - val_acc: 0.4153\n",
      "Epoch 293/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7519 - acc: 0.8686 - val_loss: 9.9609 - val_acc: 0.3814\n",
      "Epoch 294/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7546 - acc: 0.8691 - val_loss: 9.8979 - val_acc: 0.3845\n",
      "Epoch 295/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 0.7505 - acc: 0.8697 - val_loss: 9.9586 - val_acc: 0.3810\n",
      "Epoch 296/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7493 - acc: 0.8701 - val_loss: 9.9495 - val_acc: 0.3818\n",
      "Epoch 297/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7495 - acc: 0.8695 - val_loss: 9.9308 - val_acc: 0.3825\n",
      "Epoch 298/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7497 - acc: 0.8699 - val_loss: 9.9315 - val_acc: 0.3826\n",
      "Epoch 299/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.7497 - acc: 0.8691 - val_loss: 9.9118 - val_acc: 0.3835\n",
      "Epoch 300/300\n",
      "24420/24420 [==============================] - 1s 36us/step - loss: 0.7531 - acc: 0.8685 - val_loss: 9.9563 - val_acc: 0.3809\n"
     ]
    }
   ],
   "source": [
    "model3 = build_model(X_train, A_train, X_val, A_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.3843744241717582\n",
      "reweighted accuracy 0.5235692533945644\n"
     ]
    }
   ],
   "source": [
    "score = evaluate_model(model3, X_test, A_test)\n",
    "print('Test accuracy:', score)\n",
    "\n",
    "#A_hat=model3.predict(X_test_a)\n",
    "A_hat = predict(model3, X_test)\n",
    "\n",
    "print('reweighted accuracy', reweighted_accuracy(A_hat.flatten(), A_test, A_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Representation Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Data Pre-processing using Gaussian distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def normalize_data(data, a):\n",
    "    data1 = data\n",
    "    n_a0 = np.where(a==0)[0]\n",
    "    n_a1 = np.where(a==1)[0]\n",
    "    for col_name in data1.columns:\n",
    "        mean_0 = np.mean(data1[col_name][n_a0])\n",
    "        std_0 = np.std(data1[col_name][n_a0])\n",
    "        if std_0 < 1e-4:   #to avoid divide by 0\n",
    "            std_0 = 1\n",
    "        \n",
    "        data1[col_name][n_a0] = (data1[col_name][n_a0] - mean_0)/std_0\n",
    "       \n",
    "            \n",
    "        mean_1 = np.mean(data1[col_name][np.where(a==1)[0]])\n",
    "        std_1 = np.std(data1[col_name][np.where(a==1)[0]])\n",
    "        if np.isnan(mean_1):\n",
    "            mean_1=0\n",
    "        if std_1 < 1e-4:\n",
    "            std_1 = 1\n",
    "        data1[col_name][n_a1] = (data1[col_name][n_a1] - mean_1)/std_1\n",
    "        \n",
    "    return data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_normalize = normalize_data(df, df_a)\n",
    "normalized_X_train = df_normalize\n",
    "normalized_X_test = normalize_data(df_test, a_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### classifier g to predict Y from this pre-processed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "normalized_X_train = np.array(normalized_X_train)\n",
    "Y_train = df_y\n",
    "Y_train = np.array(Y_train)\n",
    "Y_train = Y_train.flatten()\n",
    "\n",
    "\n",
    "Y_test = pd.DataFrame(list(npz_test['y']))\n",
    "\n",
    "normalized_X_test = np.array(normalized_X_test)\n",
    "Y_test = np.array(Y_test)\n",
    "Y_test = Y_test.flatten()\n",
    "\n",
    "a_test =  pd.DataFrame(list(npz_test['a']))\n",
    "a_test.columns = ['sexe']\n",
    "\n",
    "train_ind = np.random.choice(normalized_X_train.shape[0], 3*X_train.shape[0]//4, replace=False) ## choose indexes for train and validation set\n",
    "\n",
    "normalized_X_train, Y_train = normalized_X_train[train_ind], Y_train[train_ind]\n",
    "normalized_X_val= df_normalize.drop(train_ind, axis=0)\n",
    "Y_val = df_y.drop(train_ind)\n",
    "normalized_X_val = np.array(normalized_X_val)\n",
    "Y_val = np.array(Y_val)\n",
    "Y_val = Y_val.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 18315 samples, validate on 14246 samples\n",
      "Epoch 1/300\n",
      "18315/18315 [==============================] - 1s 65us/step - loss: 0.3689 - acc: 0.8351 - val_loss: 0.3347 - val_acc: 0.8484\n",
      "Epoch 2/300\n",
      "18315/18315 [==============================] - 1s 42us/step - loss: 0.3260 - acc: 0.8503 - val_loss: 0.3251 - val_acc: 0.8522\n",
      "Epoch 3/300\n",
      "18315/18315 [==============================] - 1s 43us/step - loss: 0.3101 - acc: 0.8561 - val_loss: 0.3240 - val_acc: 0.8503\n",
      "Epoch 4/300\n",
      "18315/18315 [==============================] - 1s 42us/step - loss: 0.3026 - acc: 0.8584 - val_loss: 0.3269 - val_acc: 0.8536\n",
      "Epoch 5/300\n",
      "18315/18315 [==============================] - 1s 42us/step - loss: 0.2959 - acc: 0.8622 - val_loss: 0.3306 - val_acc: 0.8522\n",
      "Epoch 6/300\n",
      "18315/18315 [==============================] - 1s 42us/step - loss: 0.2877 - acc: 0.8645 - val_loss: 0.3256 - val_acc: 0.8529\n",
      "Epoch 7/300\n",
      "18315/18315 [==============================] - 1s 42us/step - loss: 0.2807 - acc: 0.8670 - val_loss: 0.3339 - val_acc: 0.8522\n",
      "Epoch 8/300\n",
      "18315/18315 [==============================] - 1s 43us/step - loss: 0.2744 - acc: 0.8732 - val_loss: 0.3334 - val_acc: 0.8520\n",
      "Epoch 9/300\n",
      "18315/18315 [==============================] - 1s 44us/step - loss: 0.2675 - acc: 0.8746 - val_loss: 0.3492 - val_acc: 0.8476\n",
      "Epoch 10/300\n",
      "18315/18315 [==============================] - 1s 42us/step - loss: 0.2610 - acc: 0.8768 - val_loss: 0.3542 - val_acc: 0.8478\n",
      "Epoch 11/300\n",
      "18315/18315 [==============================] - 1s 42us/step - loss: 0.2540 - acc: 0.8824 - val_loss: 0.3547 - val_acc: 0.8454\n",
      "Epoch 12/300\n",
      "18315/18315 [==============================] - 1s 41us/step - loss: 0.2458 - acc: 0.8866 - val_loss: 0.3751 - val_acc: 0.8458\n",
      "Epoch 13/300\n",
      "18315/18315 [==============================] - 1s 41us/step - loss: 0.2373 - acc: 0.8917 - val_loss: 0.3797 - val_acc: 0.8423\n",
      "Epoch 14/300\n",
      "18315/18315 [==============================] - 1s 42us/step - loss: 0.2326 - acc: 0.8939 - val_loss: 0.3910 - val_acc: 0.8398\n",
      "Epoch 15/300\n",
      "18315/18315 [==============================] - 1s 42us/step - loss: 0.2246 - acc: 0.8957 - val_loss: 0.3947 - val_acc: 0.8407\n",
      "Epoch 16/300\n",
      "18315/18315 [==============================] - 1s 44us/step - loss: 0.2190 - acc: 0.8997 - val_loss: 0.4073 - val_acc: 0.8404\n",
      "Epoch 17/300\n",
      "18315/18315 [==============================] - 1s 43us/step - loss: 0.2136 - acc: 0.9014 - val_loss: 0.4078 - val_acc: 0.8379\n",
      "Epoch 18/300\n",
      "18315/18315 [==============================] - 1s 42us/step - loss: 0.2080 - acc: 0.9044 - val_loss: 0.4295 - val_acc: 0.8428\n",
      "Epoch 19/300\n",
      "18315/18315 [==============================] - 1s 42us/step - loss: 0.2044 - acc: 0.9041 - val_loss: 0.4370 - val_acc: 0.8367\n",
      "Epoch 20/300\n",
      "18315/18315 [==============================] - 1s 44us/step - loss: 0.1990 - acc: 0.9079 - val_loss: 0.4494 - val_acc: 0.8381\n",
      "Epoch 21/300\n",
      "18315/18315 [==============================] - 1s 44us/step - loss: 0.1944 - acc: 0.9095 - val_loss: 0.4584 - val_acc: 0.8406\n",
      "Epoch 22/300\n",
      "18315/18315 [==============================] - 1s 42us/step - loss: 0.1920 - acc: 0.9109 - val_loss: 0.4785 - val_acc: 0.8385\n",
      "Epoch 23/300\n",
      "18315/18315 [==============================] - 1s 43us/step - loss: 0.1891 - acc: 0.9099 - val_loss: 0.4832 - val_acc: 0.8366\n",
      "Epoch 24/300\n",
      "18315/18315 [==============================] - 1s 42us/step - loss: 0.1853 - acc: 0.9125 - val_loss: 0.4848 - val_acc: 0.8348\n",
      "Epoch 25/300\n",
      "18315/18315 [==============================] - 1s 43us/step - loss: 0.1817 - acc: 0.9137 - val_loss: 0.5007 - val_acc: 0.8357\n",
      "Epoch 26/300\n",
      "18315/18315 [==============================] - 1s 43us/step - loss: 0.1788 - acc: 0.9170 - val_loss: 0.5134 - val_acc: 0.8324\n",
      "Epoch 27/300\n",
      "18315/18315 [==============================] - 1s 42us/step - loss: 0.1755 - acc: 0.9183 - val_loss: 0.5247 - val_acc: 0.8336\n",
      "Epoch 28/300\n",
      "18315/18315 [==============================] - 1s 42us/step - loss: 0.1779 - acc: 0.9160 - val_loss: 0.5250 - val_acc: 0.8369\n",
      "Epoch 29/300\n",
      "18315/18315 [==============================] - 1s 42us/step - loss: 0.1732 - acc: 0.9183 - val_loss: 0.5227 - val_acc: 0.8336\n",
      "Epoch 30/300\n",
      "18315/18315 [==============================] - 1s 42us/step - loss: 0.1717 - acc: 0.9207 - val_loss: 0.5439 - val_acc: 0.8350\n",
      "Epoch 31/300\n",
      "18315/18315 [==============================] - 1s 44us/step - loss: 0.1735 - acc: 0.9183 - val_loss: 0.5556 - val_acc: 0.8328\n",
      "Epoch 32/300\n",
      "18315/18315 [==============================] - 1s 43us/step - loss: 0.1708 - acc: 0.9188 - val_loss: 0.5565 - val_acc: 0.8354\n",
      "Epoch 33/300\n",
      "18315/18315 [==============================] - 1s 44us/step - loss: 0.1698 - acc: 0.9189 - val_loss: 0.5514 - val_acc: 0.8332\n",
      "Epoch 34/300\n",
      "18315/18315 [==============================] - 1s 42us/step - loss: 0.1686 - acc: 0.9229 - val_loss: 0.5610 - val_acc: 0.8341\n",
      "Epoch 35/300\n",
      "18315/18315 [==============================] - 1s 42us/step - loss: 0.1645 - acc: 0.9224 - val_loss: 0.5846 - val_acc: 0.8320\n",
      "Epoch 36/300\n",
      "18315/18315 [==============================] - 1s 44us/step - loss: 0.1657 - acc: 0.9222 - val_loss: 0.5862 - val_acc: 0.8341\n",
      "Epoch 37/300\n",
      "18315/18315 [==============================] - 1s 42us/step - loss: 0.1599 - acc: 0.9242 - val_loss: 0.5782 - val_acc: 0.8330\n",
      "Epoch 38/300\n",
      "18315/18315 [==============================] - 1s 42us/step - loss: 0.1574 - acc: 0.9256 - val_loss: 0.6021 - val_acc: 0.8336\n",
      "Epoch 39/300\n",
      "18315/18315 [==============================] - 1s 44us/step - loss: 0.1583 - acc: 0.9245 - val_loss: 0.6049 - val_acc: 0.8355\n",
      "Epoch 40/300\n",
      "18315/18315 [==============================] - 1s 43us/step - loss: 0.1560 - acc: 0.9249 - val_loss: 0.5945 - val_acc: 0.8337\n",
      "Epoch 41/300\n",
      "18315/18315 [==============================] - 1s 43us/step - loss: 0.1552 - acc: 0.9267 - val_loss: 0.6133 - val_acc: 0.8321\n",
      "Epoch 42/300\n",
      "18315/18315 [==============================] - 1s 42us/step - loss: 0.1568 - acc: 0.9260 - val_loss: 0.6243 - val_acc: 0.8331\n",
      "Epoch 43/300\n",
      "18315/18315 [==============================] - 1s 43us/step - loss: 0.1528 - acc: 0.9271 - val_loss: 0.6333 - val_acc: 0.8340\n",
      "Epoch 44/300\n",
      "18315/18315 [==============================] - 1s 44us/step - loss: 0.1533 - acc: 0.9268 - val_loss: 0.6076 - val_acc: 0.8297\n",
      "Epoch 45/300\n",
      "18315/18315 [==============================] - 1s 45us/step - loss: 0.1547 - acc: 0.9283 - val_loss: 0.6303 - val_acc: 0.8315\n",
      "Epoch 46/300\n",
      "18315/18315 [==============================] - 1s 42us/step - loss: 0.1531 - acc: 0.9281 - val_loss: 0.6231 - val_acc: 0.8333\n",
      "Epoch 47/300\n",
      "18315/18315 [==============================] - 1s 43us/step - loss: 0.1521 - acc: 0.9271 - val_loss: 0.6309 - val_acc: 0.8306\n",
      "Epoch 48/300\n",
      "18315/18315 [==============================] - 1s 43us/step - loss: 0.1506 - acc: 0.9267 - val_loss: 0.6261 - val_acc: 0.8314\n",
      "Epoch 49/300\n",
      "18315/18315 [==============================] - 1s 43us/step - loss: 0.1486 - acc: 0.9298 - val_loss: 0.6641 - val_acc: 0.8289\n",
      "Epoch 50/300\n",
      "18315/18315 [==============================] - 1s 43us/step - loss: 0.1495 - acc: 0.9292 - val_loss: 0.6579 - val_acc: 0.8309\n",
      "Epoch 51/300\n",
      "18315/18315 [==============================] - 1s 43us/step - loss: 0.1499 - acc: 0.9287 - val_loss: 0.6715 - val_acc: 0.8308\n",
      "Epoch 52/300\n",
      "18315/18315 [==============================] - 1s 42us/step - loss: 0.1450 - acc: 0.9307 - val_loss: 0.6670 - val_acc: 0.8317\n",
      "Epoch 53/300\n",
      "18315/18315 [==============================] - 1s 43us/step - loss: 0.1460 - acc: 0.9298 - val_loss: 0.6721 - val_acc: 0.8289\n",
      "Epoch 54/300\n",
      "18315/18315 [==============================] - 1s 44us/step - loss: 0.1443 - acc: 0.9288 - val_loss: 0.6755 - val_acc: 0.8338\n",
      "Epoch 55/300\n",
      "18315/18315 [==============================] - 1s 42us/step - loss: 0.1435 - acc: 0.9303 - val_loss: 0.6811 - val_acc: 0.8287\n",
      "Epoch 56/300\n",
      "18315/18315 [==============================] - 1s 42us/step - loss: 0.1534 - acc: 0.9292 - val_loss: 0.7029 - val_acc: 0.8300\n",
      "Epoch 57/300\n",
      "18315/18315 [==============================] - 1s 43us/step - loss: 0.1473 - acc: 0.9286 - val_loss: 0.6759 - val_acc: 0.8304\n",
      "Epoch 58/300\n",
      "18315/18315 [==============================] - 1s 43us/step - loss: 0.1443 - acc: 0.9291 - val_loss: 0.7068 - val_acc: 0.8322\n",
      "Epoch 59/300\n",
      "18315/18315 [==============================] - 1s 42us/step - loss: 0.1452 - acc: 0.9305 - val_loss: 0.6958 - val_acc: 0.8327\n",
      "Epoch 60/300\n",
      "18315/18315 [==============================] - 1s 43us/step - loss: 0.1413 - acc: 0.9317 - val_loss: 0.7192 - val_acc: 0.8318\n",
      "Epoch 61/300\n",
      "18315/18315 [==============================] - 1s 44us/step - loss: 0.1387 - acc: 0.9331 - val_loss: 0.7044 - val_acc: 0.8319\n",
      "Epoch 62/300\n",
      "18315/18315 [==============================] - 1s 43us/step - loss: 0.1386 - acc: 0.9294 - val_loss: 0.7283 - val_acc: 0.8308\n",
      "Epoch 63/300\n",
      "18315/18315 [==============================] - 1s 44us/step - loss: 0.1413 - acc: 0.9304 - val_loss: 0.7019 - val_acc: 0.8290\n",
      "Epoch 64/300\n",
      "18315/18315 [==============================] - 1s 43us/step - loss: 0.1453 - acc: 0.9313 - val_loss: 0.7291 - val_acc: 0.8276\n",
      "Epoch 65/300\n",
      "18315/18315 [==============================] - 1s 43us/step - loss: 0.1432 - acc: 0.9308 - val_loss: 0.7081 - val_acc: 0.8315\n",
      "Epoch 66/300\n",
      "18315/18315 [==============================] - 1s 42us/step - loss: 0.1391 - acc: 0.9321 - val_loss: 0.7230 - val_acc: 0.8297\n",
      "Epoch 67/300\n",
      "18315/18315 [==============================] - 1s 43us/step - loss: 0.1363 - acc: 0.9338 - val_loss: 0.7407 - val_acc: 0.8321\n",
      "Epoch 68/300\n",
      "18315/18315 [==============================] - 1s 43us/step - loss: 0.1383 - acc: 0.9321 - val_loss: 0.7280 - val_acc: 0.8298\n",
      "Epoch 69/300\n",
      "18315/18315 [==============================] - 1s 43us/step - loss: 0.1388 - acc: 0.9320 - val_loss: 0.7358 - val_acc: 0.8298\n",
      "Epoch 70/300\n",
      "18315/18315 [==============================] - 1s 44us/step - loss: 0.1370 - acc: 0.9335 - val_loss: 0.7450 - val_acc: 0.8310\n",
      "Epoch 71/300\n",
      "18315/18315 [==============================] - 1s 42us/step - loss: 0.1356 - acc: 0.9337 - val_loss: 0.7399 - val_acc: 0.8292\n",
      "Epoch 72/300\n",
      "18315/18315 [==============================] - 1s 43us/step - loss: 0.1360 - acc: 0.9330 - val_loss: 0.7418 - val_acc: 0.8320\n",
      "Epoch 73/300\n",
      "18315/18315 [==============================] - 1s 42us/step - loss: 0.1386 - acc: 0.9327 - val_loss: 0.7251 - val_acc: 0.8329\n",
      "Epoch 74/300\n",
      "18315/18315 [==============================] - 1s 43us/step - loss: 0.1340 - acc: 0.9339 - val_loss: 0.7353 - val_acc: 0.8299\n",
      "Epoch 75/300\n",
      "18315/18315 [==============================] - 1s 44us/step - loss: 0.1372 - acc: 0.9328 - val_loss: 0.7348 - val_acc: 0.8302\n",
      "Epoch 76/300\n",
      "18315/18315 [==============================] - 1s 43us/step - loss: 0.1335 - acc: 0.9350 - val_loss: 0.7574 - val_acc: 0.8294\n",
      "Epoch 77/300\n",
      "18315/18315 [==============================] - 1s 42us/step - loss: 0.1323 - acc: 0.9351 - val_loss: 0.7419 - val_acc: 0.8315\n",
      "Epoch 78/300\n",
      "18315/18315 [==============================] - 1s 42us/step - loss: 0.1353 - acc: 0.9351 - val_loss: 0.7658 - val_acc: 0.8320\n",
      "Epoch 79/300\n",
      "18315/18315 [==============================] - 1s 43us/step - loss: 0.1341 - acc: 0.9345 - val_loss: 0.7572 - val_acc: 0.8289\n",
      "Epoch 80/300\n",
      "18315/18315 [==============================] - 1s 43us/step - loss: 0.1363 - acc: 0.9330 - val_loss: 0.7520 - val_acc: 0.8313\n",
      "Epoch 81/300\n",
      "18315/18315 [==============================] - 1s 45us/step - loss: 0.1352 - acc: 0.9344 - val_loss: 0.7847 - val_acc: 0.8355\n",
      "Epoch 82/300\n",
      "18315/18315 [==============================] - 1s 48us/step - loss: 0.1330 - acc: 0.9333 - val_loss: 0.8063 - val_acc: 0.8284\n",
      "Epoch 83/300\n",
      "18315/18315 [==============================] - 1s 45us/step - loss: 0.1395 - acc: 0.9341 - val_loss: 0.7641 - val_acc: 0.8296\n",
      "Epoch 84/300\n",
      "18315/18315 [==============================] - 1s 48us/step - loss: 0.1314 - acc: 0.9349 - val_loss: 0.7914 - val_acc: 0.8352\n",
      "Epoch 85/300\n",
      "18315/18315 [==============================] - 1s 44us/step - loss: 0.1311 - acc: 0.9357 - val_loss: 0.7588 - val_acc: 0.8346\n",
      "Epoch 86/300\n",
      "18315/18315 [==============================] - 1s 44us/step - loss: 0.1318 - acc: 0.9352 - val_loss: 0.7977 - val_acc: 0.8312\n",
      "Epoch 87/300\n",
      "18315/18315 [==============================] - 1s 47us/step - loss: 0.1327 - acc: 0.9342 - val_loss: 0.7752 - val_acc: 0.8303\n",
      "Epoch 88/300\n",
      "18315/18315 [==============================] - 1s 44us/step - loss: 0.1303 - acc: 0.9360 - val_loss: 0.7845 - val_acc: 0.8329\n",
      "Epoch 89/300\n",
      "18315/18315 [==============================] - 1s 43us/step - loss: 0.1335 - acc: 0.9343 - val_loss: 0.7692 - val_acc: 0.8309\n",
      "Epoch 90/300\n",
      "18315/18315 [==============================] - 1s 43us/step - loss: 0.1277 - acc: 0.9367 - val_loss: 0.7912 - val_acc: 0.8320\n",
      "Epoch 91/300\n",
      "18315/18315 [==============================] - 1s 43us/step - loss: 0.1284 - acc: 0.9352 - val_loss: 0.7958 - val_acc: 0.8327\n",
      "Epoch 92/300\n",
      "18315/18315 [==============================] - 1s 43us/step - loss: 0.1266 - acc: 0.9360 - val_loss: 0.8133 - val_acc: 0.8310\n",
      "Epoch 93/300\n",
      "18315/18315 [==============================] - 1s 50us/step - loss: 0.1288 - acc: 0.9350 - val_loss: 0.8026 - val_acc: 0.8296\n",
      "Epoch 94/300\n",
      "18315/18315 [==============================] - 1s 46us/step - loss: 0.1308 - acc: 0.9338 - val_loss: 0.8261 - val_acc: 0.8320\n",
      "Epoch 95/300\n",
      "18315/18315 [==============================] - 1s 48us/step - loss: 0.1287 - acc: 0.9355 - val_loss: 0.8169 - val_acc: 0.8302\n",
      "Epoch 96/300\n",
      "18315/18315 [==============================] - 1s 44us/step - loss: 0.1288 - acc: 0.9357 - val_loss: 0.8057 - val_acc: 0.8309\n",
      "Epoch 97/300\n",
      "18315/18315 [==============================] - 1s 44us/step - loss: 0.1272 - acc: 0.9376 - val_loss: 0.8241 - val_acc: 0.8331\n",
      "Epoch 98/300\n",
      "18315/18315 [==============================] - 1s 49us/step - loss: 0.1284 - acc: 0.9370 - val_loss: 0.8302 - val_acc: 0.8335\n",
      "Epoch 99/300\n",
      "18315/18315 [==============================] - 1s 47us/step - loss: 0.1301 - acc: 0.9384 - val_loss: 0.8396 - val_acc: 0.8296\n",
      "Epoch 100/300\n",
      "18315/18315 [==============================] - 1s 45us/step - loss: 0.1344 - acc: 0.9356 - val_loss: 0.8496 - val_acc: 0.8301\n",
      "Epoch 101/300\n",
      "18315/18315 [==============================] - 1s 45us/step - loss: 0.1368 - acc: 0.9339 - val_loss: 0.8352 - val_acc: 0.8324\n",
      "Epoch 102/300\n",
      "18315/18315 [==============================] - 1s 45us/step - loss: 0.1338 - acc: 0.9356 - val_loss: 0.8233 - val_acc: 0.8297\n",
      "Epoch 103/300\n",
      "18315/18315 [==============================] - 1s 45us/step - loss: 0.1318 - acc: 0.9367 - val_loss: 0.8181 - val_acc: 0.8303\n",
      "Epoch 104/300\n",
      "18315/18315 [==============================] - 1s 44us/step - loss: 0.1262 - acc: 0.9376 - val_loss: 0.8341 - val_acc: 0.8317\n",
      "Epoch 105/300\n",
      "18315/18315 [==============================] - 1s 44us/step - loss: 0.1267 - acc: 0.9376 - val_loss: 0.8301 - val_acc: 0.8314\n",
      "Epoch 106/300\n",
      "18315/18315 [==============================] - 1s 47us/step - loss: 0.1352 - acc: 0.9350 - val_loss: 0.8345 - val_acc: 0.8298\n",
      "Epoch 107/300\n",
      "18315/18315 [==============================] - 1s 44us/step - loss: 0.1307 - acc: 0.9357 - val_loss: 0.8609 - val_acc: 0.8306\n",
      "Epoch 108/300\n",
      "18315/18315 [==============================] - 1s 45us/step - loss: 0.1297 - acc: 0.9363 - val_loss: 0.8479 - val_acc: 0.8313\n",
      "Epoch 109/300\n",
      "18315/18315 [==============================] - 1s 44us/step - loss: 0.1246 - acc: 0.9375 - val_loss: 0.8535 - val_acc: 0.8292\n",
      "Epoch 110/300\n",
      "18315/18315 [==============================] - 1s 44us/step - loss: 0.1242 - acc: 0.9373 - val_loss: 0.8607 - val_acc: 0.8303\n",
      "Epoch 111/300\n",
      "18315/18315 [==============================] - 1s 47us/step - loss: 0.1258 - acc: 0.9367 - val_loss: 0.8630 - val_acc: 0.8284\n",
      "Epoch 112/300\n",
      "18315/18315 [==============================] - 1s 53us/step - loss: 0.1243 - acc: 0.9374 - val_loss: 0.8636 - val_acc: 0.8262\n",
      "Epoch 113/300\n",
      "18315/18315 [==============================] - 1s 53us/step - loss: 0.1280 - acc: 0.9378 - val_loss: 0.8718 - val_acc: 0.8322\n",
      "Epoch 114/300\n",
      "18315/18315 [==============================] - 1s 51us/step - loss: 0.1280 - acc: 0.9372 - val_loss: 0.8682 - val_acc: 0.8281\n",
      "Epoch 115/300\n",
      "18315/18315 [==============================] - 1s 46us/step - loss: 0.1318 - acc: 0.9358 - val_loss: 0.8821 - val_acc: 0.8329\n",
      "Epoch 116/300\n",
      "18315/18315 [==============================] - 1s 44us/step - loss: 0.1331 - acc: 0.9363 - val_loss: 0.8694 - val_acc: 0.8278\n",
      "Epoch 117/300\n",
      "18315/18315 [==============================] - 1s 44us/step - loss: 0.1261 - acc: 0.9377 - val_loss: 0.8579 - val_acc: 0.8271\n",
      "Epoch 118/300\n",
      "18315/18315 [==============================] - 1s 44us/step - loss: 0.1244 - acc: 0.9394 - val_loss: 0.8875 - val_acc: 0.8282\n",
      "Epoch 119/300\n",
      "18315/18315 [==============================] - 1s 44us/step - loss: 0.1241 - acc: 0.9372 - val_loss: 0.8947 - val_acc: 0.8308\n",
      "Epoch 120/300\n",
      "18315/18315 [==============================] - 1s 46us/step - loss: 0.1268 - acc: 0.9384 - val_loss: 0.8815 - val_acc: 0.8291\n",
      "Epoch 121/300\n",
      "18315/18315 [==============================] - 1s 48us/step - loss: 0.1211 - acc: 0.9398 - val_loss: 0.8925 - val_acc: 0.8302\n",
      "Epoch 122/300\n",
      "18315/18315 [==============================] - 1s 44us/step - loss: 0.1217 - acc: 0.9390 - val_loss: 0.9014 - val_acc: 0.8298\n",
      "Epoch 123/300\n",
      "18315/18315 [==============================] - 1s 44us/step - loss: 0.1228 - acc: 0.9381 - val_loss: 0.8991 - val_acc: 0.8322\n",
      "Epoch 124/300\n",
      "18315/18315 [==============================] - 1s 50us/step - loss: 0.1217 - acc: 0.9387 - val_loss: 0.8842 - val_acc: 0.8308\n",
      "Epoch 125/300\n",
      "18315/18315 [==============================] - 1s 43us/step - loss: 0.1238 - acc: 0.9379 - val_loss: 0.9011 - val_acc: 0.8304\n",
      "Epoch 126/300\n",
      "18315/18315 [==============================] - 1s 45us/step - loss: 0.1213 - acc: 0.9380 - val_loss: 0.9196 - val_acc: 0.8327\n",
      "Epoch 127/300\n",
      "18315/18315 [==============================] - 1s 46us/step - loss: 0.1217 - acc: 0.9386 - val_loss: 0.8965 - val_acc: 0.8267\n",
      "Epoch 128/300\n",
      "18315/18315 [==============================] - 1s 44us/step - loss: 0.1237 - acc: 0.9367 - val_loss: 0.9007 - val_acc: 0.8290\n",
      "Epoch 129/300\n",
      "18315/18315 [==============================] - 1s 45us/step - loss: 0.1288 - acc: 0.9372 - val_loss: 0.8940 - val_acc: 0.8268\n",
      "Epoch 130/300\n",
      "18315/18315 [==============================] - 1s 43us/step - loss: 0.1251 - acc: 0.9394 - val_loss: 0.8934 - val_acc: 0.8331\n",
      "Epoch 131/300\n",
      "18315/18315 [==============================] - 1s 44us/step - loss: 0.1214 - acc: 0.9398 - val_loss: 0.8959 - val_acc: 0.8305\n",
      "Epoch 132/300\n",
      "18315/18315 [==============================] - 1s 43us/step - loss: 0.1217 - acc: 0.9382 - val_loss: 0.9059 - val_acc: 0.8310\n",
      "Epoch 133/300\n",
      "18315/18315 [==============================] - 1s 44us/step - loss: 0.1199 - acc: 0.9387 - val_loss: 0.9146 - val_acc: 0.8329\n",
      "Epoch 134/300\n",
      "18315/18315 [==============================] - 1s 43us/step - loss: 0.1199 - acc: 0.9397 - val_loss: 0.9073 - val_acc: 0.8304\n",
      "Epoch 135/300\n",
      "18315/18315 [==============================] - 1s 43us/step - loss: 0.1210 - acc: 0.9393 - val_loss: 0.9256 - val_acc: 0.8301\n",
      "Epoch 136/300\n",
      "18315/18315 [==============================] - 1s 44us/step - loss: 0.1266 - acc: 0.9375 - val_loss: 0.9047 - val_acc: 0.8305\n",
      "Epoch 137/300\n",
      "18315/18315 [==============================] - 1s 44us/step - loss: 0.1221 - acc: 0.9384 - val_loss: 0.9099 - val_acc: 0.8309\n",
      "Epoch 138/300\n",
      "18315/18315 [==============================] - 1s 44us/step - loss: 0.1192 - acc: 0.9393 - val_loss: 0.9150 - val_acc: 0.8296\n",
      "Epoch 139/300\n",
      "18315/18315 [==============================] - 1s 44us/step - loss: 0.1222 - acc: 0.9387 - val_loss: 0.9254 - val_acc: 0.8302\n",
      "Epoch 140/300\n",
      "18315/18315 [==============================] - 1s 49us/step - loss: 0.1251 - acc: 0.9379 - val_loss: 0.9254 - val_acc: 0.8282\n",
      "Epoch 141/300\n",
      "18315/18315 [==============================] - 1s 43us/step - loss: 0.1222 - acc: 0.9391 - val_loss: 0.9188 - val_acc: 0.8287\n",
      "Epoch 142/300\n",
      "18315/18315 [==============================] - 1s 43us/step - loss: 0.1240 - acc: 0.9384 - val_loss: 0.9175 - val_acc: 0.8299\n",
      "Epoch 143/300\n",
      "18315/18315 [==============================] - 1s 45us/step - loss: 0.1266 - acc: 0.9389 - val_loss: 0.9242 - val_acc: 0.8289\n",
      "Epoch 144/300\n",
      "18315/18315 [==============================] - 1s 44us/step - loss: 0.1250 - acc: 0.9404 - val_loss: 0.9019 - val_acc: 0.8321\n",
      "Epoch 145/300\n",
      "18315/18315 [==============================] - 1s 46us/step - loss: 0.1183 - acc: 0.9410 - val_loss: 0.9021 - val_acc: 0.8282\n",
      "Epoch 146/300\n",
      "18315/18315 [==============================] - 1s 44us/step - loss: 0.1207 - acc: 0.9388 - val_loss: 0.9034 - val_acc: 0.8280\n",
      "Epoch 147/300\n",
      "18315/18315 [==============================] - 1s 48us/step - loss: 0.1194 - acc: 0.9395 - val_loss: 0.9138 - val_acc: 0.8321\n",
      "Epoch 148/300\n",
      "18315/18315 [==============================] - 1s 44us/step - loss: 0.1223 - acc: 0.9388 - val_loss: 0.9256 - val_acc: 0.8313\n",
      "Epoch 149/300\n",
      "18315/18315 [==============================] - 1s 46us/step - loss: 0.1227 - acc: 0.9393 - val_loss: 0.9200 - val_acc: 0.8275\n",
      "Epoch 150/300\n",
      "18315/18315 [==============================] - 1s 43us/step - loss: 0.1195 - acc: 0.9399 - val_loss: 0.9355 - val_acc: 0.8329\n",
      "Epoch 151/300\n",
      "18315/18315 [==============================] - 1s 45us/step - loss: 0.1227 - acc: 0.9398 - val_loss: 0.9514 - val_acc: 0.8271\n",
      "Epoch 152/300\n",
      "18315/18315 [==============================] - 1s 44us/step - loss: 0.1274 - acc: 0.9385 - val_loss: 0.9234 - val_acc: 0.8300\n",
      "Epoch 153/300\n",
      "18315/18315 [==============================] - 1s 44us/step - loss: 0.1254 - acc: 0.9388 - val_loss: 0.9354 - val_acc: 0.8287\n",
      "Epoch 154/300\n",
      "18315/18315 [==============================] - 1s 44us/step - loss: 0.1296 - acc: 0.9393 - val_loss: 0.9367 - val_acc: 0.8291\n",
      "Epoch 155/300\n",
      "18315/18315 [==============================] - 1s 45us/step - loss: 0.1235 - acc: 0.9403 - val_loss: 0.9622 - val_acc: 0.8303\n",
      "Epoch 156/300\n",
      "18315/18315 [==============================] - 1s 43us/step - loss: 0.1234 - acc: 0.9399 - val_loss: 0.9481 - val_acc: 0.8338\n",
      "Epoch 157/300\n",
      "18315/18315 [==============================] - 1s 43us/step - loss: 0.1322 - acc: 0.9376 - val_loss: 0.9551 - val_acc: 0.8296\n",
      "Epoch 158/300\n",
      "18315/18315 [==============================] - 1s 44us/step - loss: 0.1225 - acc: 0.9397 - val_loss: 0.9698 - val_acc: 0.8286\n",
      "Epoch 159/300\n",
      "18315/18315 [==============================] - 1s 46us/step - loss: 0.1218 - acc: 0.9393 - val_loss: 0.9778 - val_acc: 0.8268\n",
      "Epoch 160/300\n",
      "18315/18315 [==============================] - 1s 43us/step - loss: 0.1183 - acc: 0.9406 - val_loss: 0.9627 - val_acc: 0.8312\n",
      "Epoch 161/300\n",
      "18315/18315 [==============================] - 1s 44us/step - loss: 0.1174 - acc: 0.9409 - val_loss: 0.9643 - val_acc: 0.8299\n",
      "Epoch 162/300\n",
      "18315/18315 [==============================] - 1s 45us/step - loss: 0.1179 - acc: 0.9403 - val_loss: 0.9652 - val_acc: 0.8277\n",
      "Epoch 163/300\n",
      "18315/18315 [==============================] - 1s 44us/step - loss: 0.1170 - acc: 0.9404 - val_loss: 0.9788 - val_acc: 0.8296\n",
      "Epoch 164/300\n",
      "18315/18315 [==============================] - 1s 44us/step - loss: 0.1194 - acc: 0.9399 - val_loss: 0.9708 - val_acc: 0.8270\n",
      "Epoch 165/300\n",
      "18315/18315 [==============================] - 1s 45us/step - loss: 0.1202 - acc: 0.9402 - val_loss: 1.0028 - val_acc: 0.8241\n",
      "Epoch 166/300\n",
      "18315/18315 [==============================] - 1s 45us/step - loss: 0.1258 - acc: 0.9388 - val_loss: 0.9689 - val_acc: 0.8294\n",
      "Epoch 167/300\n",
      "18315/18315 [==============================] - 1s 44us/step - loss: 0.1208 - acc: 0.9402 - val_loss: 0.9716 - val_acc: 0.8291\n",
      "Epoch 168/300\n",
      "18315/18315 [==============================] - 1s 44us/step - loss: 0.1195 - acc: 0.9418 - val_loss: 0.9833 - val_acc: 0.8296\n",
      "Epoch 169/300\n",
      "18315/18315 [==============================] - 1s 45us/step - loss: 0.1204 - acc: 0.9403 - val_loss: 0.9698 - val_acc: 0.8280\n",
      "Epoch 170/300\n",
      "18315/18315 [==============================] - 1s 45us/step - loss: 0.1221 - acc: 0.9398 - val_loss: 0.9709 - val_acc: 0.8242\n",
      "Epoch 171/300\n",
      "18315/18315 [==============================] - 1s 44us/step - loss: 0.1264 - acc: 0.9388 - val_loss: 0.9612 - val_acc: 0.8265\n",
      "Epoch 172/300\n",
      "18315/18315 [==============================] - 1s 47us/step - loss: 0.1198 - acc: 0.9399 - val_loss: 0.9515 - val_acc: 0.8265\n",
      "Epoch 173/300\n",
      "18315/18315 [==============================] - 1s 51us/step - loss: 0.1150 - acc: 0.9416 - val_loss: 0.9534 - val_acc: 0.8295\n",
      "Epoch 174/300\n",
      "18315/18315 [==============================] - 1s 44us/step - loss: 0.1149 - acc: 0.9413 - val_loss: 0.9691 - val_acc: 0.8288\n",
      "Epoch 175/300\n",
      "18315/18315 [==============================] - 1s 45us/step - loss: 0.1170 - acc: 0.9420 - val_loss: 0.9795 - val_acc: 0.8294\n",
      "Epoch 176/300\n",
      "18315/18315 [==============================] - 1s 47us/step - loss: 0.1163 - acc: 0.9419 - val_loss: 0.9945 - val_acc: 0.8273\n",
      "Epoch 177/300\n",
      "18315/18315 [==============================] - 1s 44us/step - loss: 0.1206 - acc: 0.9405 - val_loss: 1.0080 - val_acc: 0.8300\n",
      "Epoch 178/300\n",
      "18315/18315 [==============================] - 1s 52us/step - loss: 0.1280 - acc: 0.9386 - val_loss: 0.9847 - val_acc: 0.8275\n",
      "Epoch 179/300\n",
      "18315/18315 [==============================] - 1s 48us/step - loss: 0.1255 - acc: 0.9395 - val_loss: 0.9794 - val_acc: 0.8300\n",
      "Epoch 180/300\n",
      "18315/18315 [==============================] - 1s 52us/step - loss: 0.1205 - acc: 0.9406 - val_loss: 0.9818 - val_acc: 0.8269\n",
      "Epoch 181/300\n",
      "18315/18315 [==============================] - 1s 42us/step - loss: 0.1180 - acc: 0.9417 - val_loss: 0.9916 - val_acc: 0.8285\n",
      "Epoch 182/300\n",
      "18315/18315 [==============================] - 1s 45us/step - loss: 0.1159 - acc: 0.9417 - val_loss: 1.0025 - val_acc: 0.8295\n",
      "Epoch 183/300\n",
      "18315/18315 [==============================] - 1s 41us/step - loss: 0.1175 - acc: 0.9412 - val_loss: 1.0091 - val_acc: 0.8287\n",
      "Epoch 184/300\n",
      "18315/18315 [==============================] - 1s 44us/step - loss: 0.1281 - acc: 0.9388 - val_loss: 0.9847 - val_acc: 0.8287\n",
      "Epoch 185/300\n",
      "18315/18315 [==============================] - 1s 43us/step - loss: 0.1315 - acc: 0.9399 - val_loss: 0.9881 - val_acc: 0.8284\n",
      "Epoch 186/300\n",
      "18315/18315 [==============================] - 1s 45us/step - loss: 0.1285 - acc: 0.9406 - val_loss: 0.9866 - val_acc: 0.8286\n",
      "Epoch 187/300\n",
      "18315/18315 [==============================] - 1s 43us/step - loss: 0.1178 - acc: 0.9423 - val_loss: 0.9856 - val_acc: 0.8305\n",
      "Epoch 188/300\n",
      "18315/18315 [==============================] - 1s 45us/step - loss: 0.1162 - acc: 0.9422 - val_loss: 1.0004 - val_acc: 0.8290\n",
      "Epoch 189/300\n",
      "18315/18315 [==============================] - 1s 44us/step - loss: 0.1174 - acc: 0.9424 - val_loss: 1.0240 - val_acc: 0.8327\n",
      "Epoch 190/300\n",
      "18315/18315 [==============================] - 1s 43us/step - loss: 0.1187 - acc: 0.9420 - val_loss: 1.0205 - val_acc: 0.8275\n",
      "Epoch 191/300\n",
      "18315/18315 [==============================] - 1s 46us/step - loss: 0.1172 - acc: 0.9414 - val_loss: 1.0352 - val_acc: 0.8296\n",
      "Epoch 192/300\n",
      "18315/18315 [==============================] - 1s 47us/step - loss: 0.1231 - acc: 0.9400 - val_loss: 1.0153 - val_acc: 0.8254\n",
      "Epoch 193/300\n",
      "18315/18315 [==============================] - 1s 49us/step - loss: 0.1229 - acc: 0.9397 - val_loss: 1.0284 - val_acc: 0.8263\n",
      "Epoch 194/300\n",
      "18315/18315 [==============================] - 1s 46us/step - loss: 0.1230 - acc: 0.9396 - val_loss: 1.0304 - val_acc: 0.8284\n",
      "Epoch 195/300\n",
      "18315/18315 [==============================] - 1s 43us/step - loss: 0.1139 - acc: 0.9411 - val_loss: 1.0127 - val_acc: 0.8296\n",
      "Epoch 196/300\n",
      "18315/18315 [==============================] - 1s 45us/step - loss: 0.1107 - acc: 0.9432 - val_loss: 1.0267 - val_acc: 0.8287\n",
      "Epoch 197/300\n",
      "18315/18315 [==============================] - 1s 50us/step - loss: 0.1123 - acc: 0.9423 - val_loss: 1.0254 - val_acc: 0.8289\n",
      "Epoch 198/300\n",
      "18315/18315 [==============================] - 1s 54us/step - loss: 0.1144 - acc: 0.9421 - val_loss: 1.0274 - val_acc: 0.8300\n",
      "Epoch 199/300\n",
      "18315/18315 [==============================] - 1s 44us/step - loss: 0.1146 - acc: 0.9411 - val_loss: 1.0408 - val_acc: 0.8318\n",
      "Epoch 200/300\n",
      "18315/18315 [==============================] - 1s 43us/step - loss: 0.1142 - acc: 0.9414 - val_loss: 1.0233 - val_acc: 0.8308\n",
      "Epoch 201/300\n",
      "18315/18315 [==============================] - 1s 45us/step - loss: 0.1174 - acc: 0.9405 - val_loss: 1.0225 - val_acc: 0.8283\n",
      "Epoch 202/300\n",
      "18315/18315 [==============================] - 1s 51us/step - loss: 0.1180 - acc: 0.9403 - val_loss: 0.9907 - val_acc: 0.8294\n",
      "Epoch 203/300\n",
      "18315/18315 [==============================] - 1s 43us/step - loss: 0.1165 - acc: 0.9405 - val_loss: 1.0208 - val_acc: 0.8270\n",
      "Epoch 204/300\n",
      "18315/18315 [==============================] - 1s 45us/step - loss: 0.1257 - acc: 0.9393 - val_loss: 1.0166 - val_acc: 0.8320\n",
      "Epoch 205/300\n",
      "18315/18315 [==============================] - 1s 44us/step - loss: 0.1174 - acc: 0.9417 - val_loss: 1.0218 - val_acc: 0.8314\n",
      "Epoch 206/300\n",
      "18315/18315 [==============================] - 1s 45us/step - loss: 0.1132 - acc: 0.9420 - val_loss: 1.0215 - val_acc: 0.8292\n",
      "Epoch 207/300\n",
      "18315/18315 [==============================] - 1s 44us/step - loss: 0.1149 - acc: 0.9416 - val_loss: 1.0136 - val_acc: 0.8263\n",
      "Epoch 208/300\n",
      "18315/18315 [==============================] - 1s 48us/step - loss: 0.1154 - acc: 0.9417 - val_loss: 1.0303 - val_acc: 0.8323\n",
      "Epoch 209/300\n",
      "18315/18315 [==============================] - 1s 48us/step - loss: 0.1151 - acc: 0.9410 - val_loss: 1.0168 - val_acc: 0.8296\n",
      "Epoch 210/300\n",
      "18315/18315 [==============================] - 1s 49us/step - loss: 0.1140 - acc: 0.9421 - val_loss: 1.0349 - val_acc: 0.8281\n",
      "Epoch 211/300\n",
      "18315/18315 [==============================] - 1s 49us/step - loss: 0.1186 - acc: 0.9415 - val_loss: 1.0538 - val_acc: 0.8237\n",
      "Epoch 212/300\n",
      "18315/18315 [==============================] - 1s 49us/step - loss: 0.1221 - acc: 0.9405 - val_loss: 1.0057 - val_acc: 0.8289\n",
      "Epoch 213/300\n",
      "18315/18315 [==============================] - 1s 53us/step - loss: 0.1181 - acc: 0.9415 - val_loss: 1.0277 - val_acc: 0.8301\n",
      "Epoch 214/300\n",
      "18315/18315 [==============================] - 1s 49us/step - loss: 0.1133 - acc: 0.9421 - val_loss: 1.0181 - val_acc: 0.8294\n",
      "Epoch 215/300\n",
      "18315/18315 [==============================] - 1s 64us/step - loss: 0.1120 - acc: 0.9433 - val_loss: 1.0318 - val_acc: 0.8284\n",
      "Epoch 216/300\n",
      "18315/18315 [==============================] - 1s 48us/step - loss: 0.1139 - acc: 0.9419 - val_loss: 1.0375 - val_acc: 0.8303\n",
      "Epoch 217/300\n",
      "18315/18315 [==============================] - 1s 52us/step - loss: 0.1158 - acc: 0.9411 - val_loss: 1.0317 - val_acc: 0.8259\n",
      "Epoch 218/300\n",
      "18315/18315 [==============================] - 1s 56us/step - loss: 0.1177 - acc: 0.9417 - val_loss: 1.0543 - val_acc: 0.8263\n",
      "Epoch 219/300\n",
      "18315/18315 [==============================] - 1s 60us/step - loss: 0.1224 - acc: 0.9404 - val_loss: 1.0365 - val_acc: 0.8273\n",
      "Epoch 220/300\n",
      "18315/18315 [==============================] - 1s 62us/step - loss: 0.1194 - acc: 0.9413 - val_loss: 1.0433 - val_acc: 0.8294\n",
      "Epoch 221/300\n",
      "18315/18315 [==============================] - 1s 53us/step - loss: 0.1171 - acc: 0.9416 - val_loss: 1.0492 - val_acc: 0.8247\n",
      "Epoch 222/300\n",
      "18315/18315 [==============================] - 1s 51us/step - loss: 0.1135 - acc: 0.9437 - val_loss: 1.0553 - val_acc: 0.8257\n",
      "Epoch 223/300\n",
      "18315/18315 [==============================] - 1s 49us/step - loss: 0.1145 - acc: 0.9423 - val_loss: 1.0626 - val_acc: 0.8247\n",
      "Epoch 224/300\n",
      "18315/18315 [==============================] - 1s 48us/step - loss: 0.1140 - acc: 0.9425 - val_loss: 1.0625 - val_acc: 0.8290\n",
      "Epoch 225/300\n",
      "18315/18315 [==============================] - 1s 61us/step - loss: 0.1149 - acc: 0.9420 - val_loss: 1.0270 - val_acc: 0.8286\n",
      "Epoch 226/300\n",
      "18315/18315 [==============================] - 1s 63us/step - loss: 0.1213 - acc: 0.9408 - val_loss: 1.0323 - val_acc: 0.8265\n",
      "Epoch 227/300\n",
      "18315/18315 [==============================] - 1s 60us/step - loss: 0.1153 - acc: 0.9422 - val_loss: 1.0656 - val_acc: 0.8234\n",
      "Epoch 228/300\n",
      "18315/18315 [==============================] - 1s 58us/step - loss: 0.1118 - acc: 0.9426 - val_loss: 1.0612 - val_acc: 0.8298\n",
      "Epoch 229/300\n",
      "18315/18315 [==============================] - 1s 49us/step - loss: 0.1129 - acc: 0.9425 - val_loss: 1.0629 - val_acc: 0.8284\n",
      "Epoch 230/300\n",
      "18315/18315 [==============================] - 1s 46us/step - loss: 0.1127 - acc: 0.9426 - val_loss: 1.0701 - val_acc: 0.8271\n",
      "Epoch 231/300\n",
      "18315/18315 [==============================] - 1s 48us/step - loss: 0.1153 - acc: 0.9414 - val_loss: 1.0607 - val_acc: 0.8290\n",
      "Epoch 232/300\n",
      "18315/18315 [==============================] - 1s 51us/step - loss: 0.1143 - acc: 0.9420 - val_loss: 1.0467 - val_acc: 0.8289\n",
      "Epoch 233/300\n",
      "18315/18315 [==============================] - 1s 47us/step - loss: 0.1136 - acc: 0.9415 - val_loss: 1.0519 - val_acc: 0.8280\n",
      "Epoch 234/300\n",
      "18315/18315 [==============================] - 1s 58us/step - loss: 0.1138 - acc: 0.9423 - val_loss: 1.0519 - val_acc: 0.8283\n",
      "Epoch 235/300\n",
      "18315/18315 [==============================] - 1s 55us/step - loss: 0.1139 - acc: 0.9427 - val_loss: 1.0514 - val_acc: 0.8268\n",
      "Epoch 236/300\n",
      "18315/18315 [==============================] - 1s 63us/step - loss: 0.1136 - acc: 0.9417 - val_loss: 1.0420 - val_acc: 0.8292\n",
      "Epoch 237/300\n",
      "18315/18315 [==============================] - 1s 52us/step - loss: 0.1139 - acc: 0.9423 - val_loss: 1.0540 - val_acc: 0.8269\n",
      "Epoch 238/300\n",
      "18315/18315 [==============================] - 1s 51us/step - loss: 0.1141 - acc: 0.9420 - val_loss: 1.0576 - val_acc: 0.8271\n",
      "Epoch 239/300\n",
      "18315/18315 [==============================] - 1s 50us/step - loss: 0.1197 - acc: 0.9406 - val_loss: 1.0551 - val_acc: 0.8226\n",
      "Epoch 240/300\n",
      "18315/18315 [==============================] - 1s 53us/step - loss: 0.1136 - acc: 0.9427 - val_loss: 1.0212 - val_acc: 0.8281\n",
      "Epoch 241/300\n",
      "18315/18315 [==============================] - 1s 52us/step - loss: 0.1114 - acc: 0.9429 - val_loss: 1.0633 - val_acc: 0.8288\n",
      "Epoch 242/300\n",
      "18315/18315 [==============================] - 1s 49us/step - loss: 0.1106 - acc: 0.9433 - val_loss: 1.0599 - val_acc: 0.8297\n",
      "Epoch 243/300\n",
      "18315/18315 [==============================] - 1s 55us/step - loss: 0.1130 - acc: 0.9423 - val_loss: 1.0624 - val_acc: 0.8281\n",
      "Epoch 244/300\n",
      "18315/18315 [==============================] - 1s 50us/step - loss: 0.1116 - acc: 0.9436 - val_loss: 1.0650 - val_acc: 0.8284\n",
      "Epoch 245/300\n",
      "18315/18315 [==============================] - 1s 49us/step - loss: 0.1132 - acc: 0.9432 - val_loss: 1.0615 - val_acc: 0.8261\n",
      "Epoch 246/300\n",
      "18315/18315 [==============================] - 1s 53us/step - loss: 0.1144 - acc: 0.9419 - val_loss: 1.0587 - val_acc: 0.8287\n",
      "Epoch 247/300\n",
      "18315/18315 [==============================] - 1s 53us/step - loss: 0.1151 - acc: 0.9418 - val_loss: 1.0505 - val_acc: 0.8287\n",
      "Epoch 248/300\n",
      "18315/18315 [==============================] - 1s 52us/step - loss: 0.1303 - acc: 0.9409 - val_loss: 1.0595 - val_acc: 0.8245\n",
      "Epoch 249/300\n",
      "18315/18315 [==============================] - 1s 46us/step - loss: 0.1256 - acc: 0.9427 - val_loss: 1.0588 - val_acc: 0.8292\n",
      "Epoch 250/300\n",
      "18315/18315 [==============================] - 1s 53us/step - loss: 0.1136 - acc: 0.9439 - val_loss: 1.0620 - val_acc: 0.8267\n",
      "Epoch 251/300\n",
      "18315/18315 [==============================] - 1s 47us/step - loss: 0.1105 - acc: 0.9431 - val_loss: 1.0770 - val_acc: 0.8260\n",
      "Epoch 252/300\n",
      "18315/18315 [==============================] - 1s 50us/step - loss: 0.1167 - acc: 0.9424 - val_loss: 1.0780 - val_acc: 0.8305\n",
      "Epoch 253/300\n",
      "18315/18315 [==============================] - 1s 47us/step - loss: 0.1152 - acc: 0.9427 - val_loss: 1.0747 - val_acc: 0.8304\n",
      "Epoch 254/300\n",
      "18315/18315 [==============================] - 1s 47us/step - loss: 0.1146 - acc: 0.9427 - val_loss: 1.0895 - val_acc: 0.8290\n",
      "Epoch 255/300\n",
      "18315/18315 [==============================] - 1s 46us/step - loss: 0.1147 - acc: 0.9421 - val_loss: 1.0653 - val_acc: 0.8275\n",
      "Epoch 256/300\n",
      "18315/18315 [==============================] - 1s 46us/step - loss: 0.1148 - acc: 0.9434 - val_loss: 1.0714 - val_acc: 0.8274\n",
      "Epoch 257/300\n",
      "18315/18315 [==============================] - 1s 45us/step - loss: 0.1133 - acc: 0.9434 - val_loss: 1.0702 - val_acc: 0.8299\n",
      "Epoch 258/300\n",
      "18315/18315 [==============================] - 1s 47us/step - loss: 0.1096 - acc: 0.9438 - val_loss: 1.0567 - val_acc: 0.8296\n",
      "Epoch 259/300\n",
      "18315/18315 [==============================] - 1s 48us/step - loss: 0.1099 - acc: 0.9433 - val_loss: 1.0620 - val_acc: 0.8282\n",
      "Epoch 260/300\n",
      "18315/18315 [==============================] - 1s 50us/step - loss: 0.1105 - acc: 0.9432 - val_loss: 1.0875 - val_acc: 0.8278\n",
      "Epoch 261/300\n",
      "18315/18315 [==============================] - 1s 47us/step - loss: 0.1123 - acc: 0.9418 - val_loss: 1.0784 - val_acc: 0.8314\n",
      "Epoch 262/300\n",
      "18315/18315 [==============================] - 1s 46us/step - loss: 0.1119 - acc: 0.9433 - val_loss: 1.0704 - val_acc: 0.8296\n",
      "Epoch 263/300\n",
      "18315/18315 [==============================] - 1s 48us/step - loss: 0.1127 - acc: 0.9425 - val_loss: 1.0842 - val_acc: 0.8289\n",
      "Epoch 264/300\n",
      "18315/18315 [==============================] - 1s 44us/step - loss: 0.1168 - acc: 0.9414 - val_loss: 1.0493 - val_acc: 0.8284\n",
      "Epoch 265/300\n",
      "18315/18315 [==============================] - 1s 47us/step - loss: 0.1218 - acc: 0.9416 - val_loss: 1.0933 - val_acc: 0.8308\n",
      "Epoch 266/300\n",
      "18315/18315 [==============================] - 1s 47us/step - loss: 0.1206 - acc: 0.9423 - val_loss: 1.0701 - val_acc: 0.8277\n",
      "Epoch 267/300\n",
      "18315/18315 [==============================] - 1s 50us/step - loss: 0.1248 - acc: 0.9412 - val_loss: 1.0562 - val_acc: 0.8259\n",
      "Epoch 268/300\n",
      "18315/18315 [==============================] - 1s 48us/step - loss: 0.1157 - acc: 0.9431 - val_loss: 1.0820 - val_acc: 0.8295\n",
      "Epoch 269/300\n",
      "18315/18315 [==============================] - 1s 46us/step - loss: 0.1093 - acc: 0.9446 - val_loss: 1.0862 - val_acc: 0.8268\n",
      "Epoch 270/300\n",
      "18315/18315 [==============================] - 1s 47us/step - loss: 0.1094 - acc: 0.9442 - val_loss: 1.0962 - val_acc: 0.8284\n",
      "Epoch 271/300\n",
      "18315/18315 [==============================] - 1s 45us/step - loss: 0.1085 - acc: 0.9443 - val_loss: 1.0926 - val_acc: 0.8279\n",
      "Epoch 272/300\n",
      "18315/18315 [==============================] - 1s 43us/step - loss: 0.1095 - acc: 0.9429 - val_loss: 1.0839 - val_acc: 0.8270\n",
      "Epoch 273/300\n",
      "18315/18315 [==============================] - 1s 43us/step - loss: 0.1114 - acc: 0.9432 - val_loss: 1.0914 - val_acc: 0.8275\n",
      "Epoch 274/300\n",
      "18315/18315 [==============================] - 1s 46us/step - loss: 0.1108 - acc: 0.9433 - val_loss: 1.0997 - val_acc: 0.8261\n",
      "Epoch 275/300\n",
      "18315/18315 [==============================] - 1s 44us/step - loss: 0.1124 - acc: 0.9425 - val_loss: 1.1016 - val_acc: 0.8284\n",
      "Epoch 276/300\n",
      "18315/18315 [==============================] - 1s 49us/step - loss: 0.1120 - acc: 0.9418 - val_loss: 1.0790 - val_acc: 0.8282\n",
      "Epoch 277/300\n",
      "18315/18315 [==============================] - 1s 51us/step - loss: 0.1114 - acc: 0.9418 - val_loss: 1.0780 - val_acc: 0.8288\n",
      "Epoch 278/300\n",
      "18315/18315 [==============================] - 1s 51us/step - loss: 0.1140 - acc: 0.9434 - val_loss: 1.0782 - val_acc: 0.8272\n",
      "Epoch 279/300\n",
      "18315/18315 [==============================] - 1s 46us/step - loss: 0.1122 - acc: 0.9436 - val_loss: 1.0975 - val_acc: 0.8291\n",
      "Epoch 280/300\n",
      "18315/18315 [==============================] - 1s 49us/step - loss: 0.1198 - acc: 0.9406 - val_loss: 1.0931 - val_acc: 0.8278\n",
      "Epoch 281/300\n",
      "18315/18315 [==============================] - 1s 46us/step - loss: 0.1154 - acc: 0.9446 - val_loss: 1.1148 - val_acc: 0.8260\n",
      "Epoch 282/300\n",
      "18315/18315 [==============================] - 1s 47us/step - loss: 0.1238 - acc: 0.9406 - val_loss: 1.1211 - val_acc: 0.8258\n",
      "Epoch 283/300\n",
      "18315/18315 [==============================] - 1s 46us/step - loss: 0.1185 - acc: 0.9429 - val_loss: 1.0967 - val_acc: 0.8262\n",
      "Epoch 284/300\n",
      "18315/18315 [==============================] - 1s 44us/step - loss: 0.1108 - acc: 0.9440 - val_loss: 1.1013 - val_acc: 0.8263\n",
      "Epoch 285/300\n",
      "18315/18315 [==============================] - 1s 46us/step - loss: 0.1123 - acc: 0.9444 - val_loss: 1.1066 - val_acc: 0.8261\n",
      "Epoch 286/300\n",
      "18315/18315 [==============================] - 1s 45us/step - loss: 0.1107 - acc: 0.9435 - val_loss: 1.1137 - val_acc: 0.8266\n",
      "Epoch 287/300\n",
      "18315/18315 [==============================] - 1s 48us/step - loss: 0.1118 - acc: 0.9446 - val_loss: 1.1029 - val_acc: 0.8257\n",
      "Epoch 288/300\n",
      "18315/18315 [==============================] - 1s 47us/step - loss: 0.1114 - acc: 0.9440 - val_loss: 1.1301 - val_acc: 0.8270\n",
      "Epoch 289/300\n",
      "18315/18315 [==============================] - 1s 46us/step - loss: 0.1116 - acc: 0.9439 - val_loss: 1.1168 - val_acc: 0.8256\n",
      "Epoch 290/300\n",
      "18315/18315 [==============================] - 1s 46us/step - loss: 0.1113 - acc: 0.9436 - val_loss: 1.1242 - val_acc: 0.8260\n",
      "Epoch 291/300\n",
      "18315/18315 [==============================] - 1s 48us/step - loss: 0.1133 - acc: 0.9429 - val_loss: 1.1227 - val_acc: 0.8259\n",
      "Epoch 292/300\n",
      "18315/18315 [==============================] - 1s 47us/step - loss: 0.1261 - acc: 0.9414 - val_loss: 1.1343 - val_acc: 0.8281\n",
      "Epoch 293/300\n",
      "18315/18315 [==============================] - 1s 47us/step - loss: 0.1321 - acc: 0.9418 - val_loss: 1.1422 - val_acc: 0.8199\n",
      "Epoch 294/300\n",
      "18315/18315 [==============================] - 1s 46us/step - loss: 0.1223 - acc: 0.9433 - val_loss: 1.1065 - val_acc: 0.8261\n",
      "Epoch 295/300\n",
      "18315/18315 [==============================] - 1s 49us/step - loss: 0.1121 - acc: 0.9445 - val_loss: 1.1266 - val_acc: 0.8271\n",
      "Epoch 296/300\n",
      "18315/18315 [==============================] - 1s 47us/step - loss: 0.1119 - acc: 0.9434 - val_loss: 1.1423 - val_acc: 0.8251\n",
      "Epoch 297/300\n",
      "18315/18315 [==============================] - 1s 46us/step - loss: 0.1132 - acc: 0.9439 - val_loss: 1.1253 - val_acc: 0.8289\n",
      "Epoch 298/300\n",
      "18315/18315 [==============================] - 1s 47us/step - loss: 0.1084 - acc: 0.9461 - val_loss: 1.1281 - val_acc: 0.8287\n",
      "Epoch 299/300\n",
      "18315/18315 [==============================] - 1s 47us/step - loss: 0.1074 - acc: 0.9444 - val_loss: 1.1276 - val_acc: 0.8282\n",
      "Epoch 300/300\n",
      "18315/18315 [==============================] - 1s 45us/step - loss: 0.1076 - acc: 0.9443 - val_loss: 1.1255 - val_acc: 0.8277\n"
     ]
    }
   ],
   "source": [
    "model4 = build_model(normalized_X_train, Y_train, normalized_X_val, Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.8215097352669241\n",
      "delta DP 0.15690801375049557\n"
     ]
    }
   ],
   "source": [
    "score = evaluate_model(model4, normalized_X_test, Y_test)\n",
    "print('Test accuracy:', score)\n",
    "y_hat = predict(model4, normalized_X_test)\n",
    "print('delta DP', compute_delta_DP(y_hat, a_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### classifier h to predict A from this pre-processed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_normalize_without_male_female  = normalize_data(df_without_male_female, df_a)\n",
    "normalized_X_test_without_male_female = normalize_data(df_test_without_male_female, a_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "normalized_X_train_without_male_female = df_normalize_without_male_female  #contents only attributes in x\n",
    "A_train = df_a\n",
    "\n",
    "##loading test data\n",
    "#normalized_X_test_without_male_female = normalized_X_test_without_male_female  \n",
    "\n",
    "A_test =  pd.DataFrame(list(npz_test['a']))\n",
    "A_test.columns = ['sexe']\n",
    "\n",
    "\n",
    "normalized_X_train_without_male_female = np.array(normalized_X_train_without_male_female)\n",
    "A_train = np.array(A_train)\n",
    "A_train = A_train.flatten()\n",
    "\n",
    "normalized_X_test_without_male_female= np.array(normalized_X_test_without_male_female)\n",
    "A_test = np.array(A_test)\n",
    "# A_test = A_test.flatten()\n",
    "\n",
    "train_ind_a = np.random.choice(normalized_X_train_without_male_female.shape[0], 3*normalized_X_train_without_male_female.shape[0]//4, replace=False) ## choose indexes for train and validation set\n",
    "#train_ind\n",
    "\n",
    "#splitting the train data into train and val usin tain_ind_a\n",
    "normalized_X_train_without_male_female, A_train = normalized_X_train_without_male_female[train_ind_a], A_train[train_ind_a]\n",
    "X_val_normalized_a= df_without_male_female.drop(train_ind_a, axis=0)\n",
    "A_val = df_a.drop(train_ind_a)\n",
    "X_val_normalized_a = np.array(X_val_normalized_a)\n",
    "A_val = np.array(A_val)\n",
    "A_val = A_val.flatten()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24420 samples, validate on 8141 samples\n",
      "Epoch 1/300\n",
      "24420/24420 [==============================] - 2s 68us/step - loss: 0.1553 - acc: 0.9412 - val_loss: 0.0335 - val_acc: 0.9937\n",
      "Epoch 2/300\n",
      "24420/24420 [==============================] - 1s 51us/step - loss: 0.0134 - acc: 0.9970 - val_loss: 0.0174 - val_acc: 0.9957\n",
      "Epoch 3/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.0092 - acc: 0.9982 - val_loss: 0.0065 - val_acc: 0.9980\n",
      "Epoch 4/300\n",
      "24420/24420 [==============================] - 1s 37us/step - loss: 0.0039 - acc: 0.9992 - val_loss: 0.0113 - val_acc: 0.9975\n",
      "Epoch 5/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 0.0054 - acc: 0.9990 - val_loss: 0.0043 - val_acc: 0.9988\n",
      "Epoch 6/300\n",
      "24420/24420 [==============================] - 1s 39us/step - loss: 0.0046 - acc: 0.9992 - val_loss: 0.0050 - val_acc: 0.9983\n",
      "Epoch 7/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 0.0046 - acc: 0.9991 - val_loss: 0.0085 - val_acc: 0.9975\n",
      "Epoch 8/300\n",
      "24420/24420 [==============================] - 1s 39us/step - loss: 0.0042 - acc: 0.9991 - val_loss: 0.0124 - val_acc: 0.9984\n",
      "Epoch 9/300\n",
      "24420/24420 [==============================] - 1s 39us/step - loss: 0.0056 - acc: 0.9993 - val_loss: 0.0086 - val_acc: 0.9984\n",
      "Epoch 10/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 0.0050 - acc: 0.9996 - val_loss: 0.0072 - val_acc: 0.9991\n",
      "Epoch 11/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0073 - val_acc: 0.9993\n",
      "Epoch 12/300\n",
      "24420/24420 [==============================] - 1s 40us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0073 - val_acc: 0.9993\n",
      "Epoch 13/300\n",
      "24420/24420 [==============================] - 1s 41us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0074 - val_acc: 0.9993\n",
      "Epoch 14/300\n",
      "24420/24420 [==============================] - 1s 43us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0074 - val_acc: 0.9993\n",
      "Epoch 15/300\n",
      "24420/24420 [==============================] - 1s 39us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0075 - val_acc: 0.9993\n",
      "Epoch 16/300\n",
      "24420/24420 [==============================] - 1s 39us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0075 - val_acc: 0.9991\n",
      "Epoch 17/300\n",
      "24420/24420 [==============================] - 1s 40us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0076 - val_acc: 0.9991\n",
      "Epoch 18/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0076 - val_acc: 0.9991\n",
      "Epoch 19/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0077 - val_acc: 0.9991\n",
      "Epoch 20/300\n",
      "24420/24420 [==============================] - 1s 48us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0077 - val_acc: 0.9993\n",
      "Epoch 21/300\n",
      "24420/24420 [==============================] - 1s 51us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0078 - val_acc: 0.9991\n",
      "Epoch 22/300\n",
      "24420/24420 [==============================] - 1s 43us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0079 - val_acc: 0.9993\n",
      "Epoch 23/300\n",
      "24420/24420 [==============================] - 1s 41us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0079 - val_acc: 0.9993\n",
      "Epoch 24/300\n",
      "24420/24420 [==============================] - 1s 55us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0079 - val_acc: 0.9995\n",
      "Epoch 25/300\n",
      "24420/24420 [==============================] - 1s 53us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0080 - val_acc: 0.9994\n",
      "Epoch 26/300\n",
      "24420/24420 [==============================] - 1s 52us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0081 - val_acc: 0.9994\n",
      "Epoch 27/300\n",
      "24420/24420 [==============================] - 1s 61us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0081 - val_acc: 0.9994\n",
      "Epoch 28/300\n",
      "24420/24420 [==============================] - 1s 57us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0081 - val_acc: 0.9994\n",
      "Epoch 29/300\n",
      "24420/24420 [==============================] - 1s 61us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 30/300\n",
      "24420/24420 [==============================] - 1s 54us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0083 - val_acc: 0.9994\n",
      "Epoch 31/300\n",
      "24420/24420 [==============================] - 1s 60us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0083 - val_acc: 0.9994\n",
      "Epoch 32/300\n",
      "24420/24420 [==============================] - 1s 61us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 33/300\n",
      "24420/24420 [==============================] - 1s 52us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0083 - val_acc: 0.9994\n",
      "Epoch 34/300\n",
      "24420/24420 [==============================] - 1s 48us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0083 - val_acc: 0.9994\n",
      "Epoch 35/300\n",
      "24420/24420 [==============================] - 2s 65us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0083 - val_acc: 0.9994\n",
      "Epoch 36/300\n",
      "24420/24420 [==============================] - 2s 67us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0083 - val_acc: 0.9994\n",
      "Epoch 37/300\n",
      "24420/24420 [==============================] - 2s 70us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 38/300\n",
      "24420/24420 [==============================] - 2s 68us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 39/300\n",
      "24420/24420 [==============================] - 2s 70us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0083 - val_acc: 0.9994\n",
      "Epoch 40/300\n",
      "24420/24420 [==============================] - 1s 59us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 41/300\n",
      "24420/24420 [==============================] - 2s 63us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0083 - val_acc: 0.9994\n",
      "Epoch 42/300\n",
      "24420/24420 [==============================] - 1s 43us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0083 - val_acc: 0.9994\n",
      "Epoch 43/300\n",
      "24420/24420 [==============================] - 1s 55us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0083 - val_acc: 0.9994\n",
      "Epoch 44/300\n",
      "24420/24420 [==============================] - 1s 56us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0081 - val_acc: 0.9995\n",
      "Epoch 45/300\n",
      "24420/24420 [==============================] - 1s 57us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 46/300\n",
      "24420/24420 [==============================] - 1s 49us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 47/300\n",
      "24420/24420 [==============================] - 1s 45us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 48/300\n",
      "24420/24420 [==============================] - 1s 41us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0083 - val_acc: 0.9994\n",
      "Epoch 49/300\n",
      "24420/24420 [==============================] - 1s 41us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0081 - val_acc: 0.9994\n",
      "Epoch 50/300\n",
      "24420/24420 [==============================] - 1s 41us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0081 - val_acc: 0.9994\n",
      "Epoch 51/300\n",
      "24420/24420 [==============================] - 1s 45us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0081 - val_acc: 0.9994\n",
      "Epoch 52/300\n",
      "24420/24420 [==============================] - 1s 40us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0081 - val_acc: 0.9994\n",
      "Epoch 53/300\n",
      "24420/24420 [==============================] - 1s 48us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 54/300\n",
      "24420/24420 [==============================] - 1s 58us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 55/300\n",
      "24420/24420 [==============================] - 1s 51us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0081 - val_acc: 0.9994\n",
      "Epoch 56/300\n",
      "24420/24420 [==============================] - 1s 52us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0081 - val_acc: 0.9994\n",
      "Epoch 57/300\n",
      "24420/24420 [==============================] - 1s 57us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 58/300\n",
      "24420/24420 [==============================] - 1s 55us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 59/300\n",
      "24420/24420 [==============================] - 1s 40us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 60/300\n",
      "24420/24420 [==============================] - 1s 48us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 61/300\n",
      "24420/24420 [==============================] - 1s 39us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 62/300\n",
      "24420/24420 [==============================] - 1s 45us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 63/300\n",
      "24420/24420 [==============================] - 1s 45us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 64/300\n",
      "24420/24420 [==============================] - 1s 46us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 65/300\n",
      "24420/24420 [==============================] - 1s 39us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 66/300\n",
      "24420/24420 [==============================] - 1s 39us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 67/300\n",
      "24420/24420 [==============================] - 1s 39us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 68/300\n",
      "24420/24420 [==============================] - 1s 45us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 69/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 70/300\n",
      "24420/24420 [==============================] - 1s 41us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 71/300\n",
      "24420/24420 [==============================] - 1s 41us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 72/300\n",
      "24420/24420 [==============================] - 1s 41us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 73/300\n",
      "24420/24420 [==============================] - 1s 41us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 74/300\n",
      "24420/24420 [==============================] - 1s 45us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 75/300\n",
      "24420/24420 [==============================] - 1s 40us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 76/300\n",
      "24420/24420 [==============================] - 1s 45us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 77/300\n",
      "24420/24420 [==============================] - 1s 41us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 78/300\n",
      "24420/24420 [==============================] - 1s 48us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 79/300\n",
      "24420/24420 [==============================] - 1s 45us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 80/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 81/300\n",
      "24420/24420 [==============================] - 1s 49us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 82/300\n",
      "24420/24420 [==============================] - 1s 53us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 83/300\n",
      "24420/24420 [==============================] - 1s 54us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 84/300\n",
      "24420/24420 [==============================] - 1s 50us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 85/300\n",
      "24420/24420 [==============================] - 1s 40us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 86/300\n",
      "24420/24420 [==============================] - 1s 40us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 87/300\n",
      "24420/24420 [==============================] - 1s 40us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 88/300\n",
      "24420/24420 [==============================] - 1s 40us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 89/300\n",
      "24420/24420 [==============================] - 1s 42us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 90/300\n",
      "24420/24420 [==============================] - 1s 41us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 91/300\n",
      "24420/24420 [==============================] - 1s 42us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 92/300\n",
      "24420/24420 [==============================] - 1s 40us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 93/300\n",
      "24420/24420 [==============================] - 1s 40us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 94/300\n",
      "24420/24420 [==============================] - 1s 41us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 95/300\n",
      "24420/24420 [==============================] - 1s 40us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 96/300\n",
      "24420/24420 [==============================] - 1s 40us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 97/300\n",
      "24420/24420 [==============================] - 1s 39us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 98/300\n",
      "24420/24420 [==============================] - 1s 40us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 99/300\n",
      "24420/24420 [==============================] - 1s 41us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 100/300\n",
      "24420/24420 [==============================] - 1s 40us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 101/300\n",
      "24420/24420 [==============================] - 1s 41us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 102/300\n",
      "24420/24420 [==============================] - 1s 40us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 103/300\n",
      "24420/24420 [==============================] - 1s 40us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 104/300\n",
      "24420/24420 [==============================] - 1s 41us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 105/300\n",
      "24420/24420 [==============================] - 1s 40us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 106/300\n",
      "24420/24420 [==============================] - 1s 40us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 107/300\n",
      "24420/24420 [==============================] - 1s 40us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 108/300\n",
      "24420/24420 [==============================] - 1s 41us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 109/300\n",
      "24420/24420 [==============================] - 1s 40us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 110/300\n",
      "24420/24420 [==============================] - 1s 40us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 111/300\n",
      "24420/24420 [==============================] - 1s 41us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 112/300\n",
      "24420/24420 [==============================] - 1s 41us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 113/300\n",
      "24420/24420 [==============================] - 1s 41us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 114/300\n",
      "24420/24420 [==============================] - 1s 40us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 115/300\n",
      "24420/24420 [==============================] - 1s 40us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 116/300\n",
      "24420/24420 [==============================] - 1s 41us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 117/300\n",
      "24420/24420 [==============================] - 1s 41us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 118/300\n",
      "24420/24420 [==============================] - 1s 40us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 119/300\n",
      "24420/24420 [==============================] - 1s 40us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 120/300\n",
      "24420/24420 [==============================] - 1s 41us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 121/300\n",
      "24420/24420 [==============================] - 1s 40us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 122/300\n",
      "24420/24420 [==============================] - 1s 41us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 123/300\n",
      "24420/24420 [==============================] - 1s 41us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 124/300\n",
      "24420/24420 [==============================] - 1s 40us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 125/300\n",
      "24420/24420 [==============================] - 1s 40us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 126/300\n",
      "24420/24420 [==============================] - 1s 41us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 127/300\n",
      "24420/24420 [==============================] - 1s 40us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 128/300\n",
      "24420/24420 [==============================] - 1s 41us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 129/300\n",
      "24420/24420 [==============================] - 1s 41us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 130/300\n",
      "24420/24420 [==============================] - 1s 40us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 131/300\n",
      "24420/24420 [==============================] - 1s 40us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 132/300\n",
      "24420/24420 [==============================] - 1s 40us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 133/300\n",
      "24420/24420 [==============================] - 1s 41us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 134/300\n",
      "24420/24420 [==============================] - 1s 40us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 135/300\n",
      "24420/24420 [==============================] - 1s 42us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 136/300\n",
      "24420/24420 [==============================] - 1s 41us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 137/300\n",
      "24420/24420 [==============================] - 1s 40us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 138/300\n",
      "24420/24420 [==============================] - 1s 41us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 139/300\n",
      "24420/24420 [==============================] - 1s 41us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 140/300\n",
      "24420/24420 [==============================] - 1s 40us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 141/300\n",
      "24420/24420 [==============================] - 1s 40us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 142/300\n",
      "24420/24420 [==============================] - 1s 40us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 143/300\n",
      "24420/24420 [==============================] - 1s 40us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 144/300\n",
      "24420/24420 [==============================] - 1s 40us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 145/300\n",
      "24420/24420 [==============================] - 1s 40us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 146/300\n",
      "24420/24420 [==============================] - 1s 41us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 147/300\n",
      "24420/24420 [==============================] - 1s 40us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 148/300\n",
      "24420/24420 [==============================] - 1s 41us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 149/300\n",
      "24420/24420 [==============================] - 1s 41us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 150/300\n",
      "24420/24420 [==============================] - 1s 49us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 151/300\n",
      "24420/24420 [==============================] - 1s 48us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 152/300\n",
      "24420/24420 [==============================] - 1s 46us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 153/300\n",
      "24420/24420 [==============================] - 1s 47us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 154/300\n",
      "24420/24420 [==============================] - 1s 44us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 155/300\n",
      "24420/24420 [==============================] - 1s 40us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 156/300\n",
      "24420/24420 [==============================] - 1s 40us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 157/300\n",
      "24420/24420 [==============================] - 1s 40us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 158/300\n",
      "24420/24420 [==============================] - 1s 40us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 159/300\n",
      "24420/24420 [==============================] - 1s 40us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 160/300\n",
      "24420/24420 [==============================] - 1s 41us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 161/300\n",
      "24420/24420 [==============================] - 1s 40us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 162/300\n",
      "24420/24420 [==============================] - 1s 41us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 163/300\n",
      "24420/24420 [==============================] - 1s 41us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 164/300\n",
      "24420/24420 [==============================] - 1s 40us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 165/300\n",
      "24420/24420 [==============================] - 1s 41us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 166/300\n",
      "24420/24420 [==============================] - 1s 40us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 167/300\n",
      "24420/24420 [==============================] - 1s 42us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 168/300\n",
      "24420/24420 [==============================] - 1s 41us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 169/300\n",
      "24420/24420 [==============================] - 1s 40us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 170/300\n",
      "24420/24420 [==============================] - 1s 41us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 171/300\n",
      "24420/24420 [==============================] - 1s 41us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 172/300\n",
      "24420/24420 [==============================] - 1s 40us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 173/300\n",
      "24420/24420 [==============================] - 1s 41us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 174/300\n",
      "24420/24420 [==============================] - 1s 41us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 175/300\n",
      "24420/24420 [==============================] - 1s 41us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 176/300\n",
      "24420/24420 [==============================] - 1s 40us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 177/300\n",
      "24420/24420 [==============================] - 1s 41us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 178/300\n",
      "24420/24420 [==============================] - 1s 41us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 179/300\n",
      "24420/24420 [==============================] - 1s 41us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 180/300\n",
      "24420/24420 [==============================] - 1s 41us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 181/300\n",
      "24420/24420 [==============================] - 1s 41us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 182/300\n",
      "24420/24420 [==============================] - 1s 41us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 183/300\n",
      "24420/24420 [==============================] - 1s 40us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 184/300\n",
      "24420/24420 [==============================] - 1s 40us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 185/300\n",
      "24420/24420 [==============================] - 1s 41us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 186/300\n",
      "24420/24420 [==============================] - 1s 40us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 187/300\n",
      "24420/24420 [==============================] - 1s 40us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 188/300\n",
      "24420/24420 [==============================] - 1s 41us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 189/300\n",
      "24420/24420 [==============================] - 1s 41us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 190/300\n",
      "24420/24420 [==============================] - 1s 41us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 191/300\n",
      "24420/24420 [==============================] - 1s 42us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 192/300\n",
      "24420/24420 [==============================] - 1s 41us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 193/300\n",
      "24420/24420 [==============================] - 1s 41us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 194/300\n",
      "24420/24420 [==============================] - 1s 40us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 195/300\n",
      "24420/24420 [==============================] - 1s 40us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 196/300\n",
      "24420/24420 [==============================] - 1s 41us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 197/300\n",
      "24420/24420 [==============================] - 1s 41us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 198/300\n",
      "24420/24420 [==============================] - 1s 40us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 199/300\n",
      "24420/24420 [==============================] - 1s 43us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 200/300\n",
      "24420/24420 [==============================] - 1s 46us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 201/300\n",
      "24420/24420 [==============================] - 1s 48us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 202/300\n",
      "24420/24420 [==============================] - 1s 48us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 203/300\n",
      "24420/24420 [==============================] - 1s 42us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 204/300\n",
      "24420/24420 [==============================] - 1s 43us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 205/300\n",
      "24420/24420 [==============================] - 1s 40us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 206/300\n",
      "24420/24420 [==============================] - 1s 46us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 207/300\n",
      "24420/24420 [==============================] - 1s 44us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 208/300\n",
      "24420/24420 [==============================] - 1s 44us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 209/300\n",
      "24420/24420 [==============================] - 1s 43us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 210/300\n",
      "24420/24420 [==============================] - 1s 42us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 211/300\n",
      "24420/24420 [==============================] - 1s 43us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 212/300\n",
      "24420/24420 [==============================] - 1s 44us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 213/300\n",
      "24420/24420 [==============================] - 1s 43us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 214/300\n",
      "24420/24420 [==============================] - 1s 41us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 215/300\n",
      "24420/24420 [==============================] - 1s 43us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 216/300\n",
      "24420/24420 [==============================] - 1s 48us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 217/300\n",
      "24420/24420 [==============================] - 1s 49us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 218/300\n",
      "24420/24420 [==============================] - 1s 48us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 219/300\n",
      "24420/24420 [==============================] - 1s 44us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 220/300\n",
      "24420/24420 [==============================] - 1s 42us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 221/300\n",
      "24420/24420 [==============================] - 1s 40us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 222/300\n",
      "24420/24420 [==============================] - 1s 40us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 223/300\n",
      "24420/24420 [==============================] - 1s 39us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 224/300\n",
      "24420/24420 [==============================] - 1s 50us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 225/300\n",
      "24420/24420 [==============================] - 1s 52us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 226/300\n",
      "24420/24420 [==============================] - 1s 55us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 227/300\n",
      "24420/24420 [==============================] - 1s 54us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 228/300\n",
      "24420/24420 [==============================] - 1s 43us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 229/300\n",
      "24420/24420 [==============================] - 1s 39us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 230/300\n",
      "24420/24420 [==============================] - 1s 40us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 231/300\n",
      "24420/24420 [==============================] - 1s 39us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 232/300\n",
      "24420/24420 [==============================] - 1s 39us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 233/300\n",
      "24420/24420 [==============================] - 1s 41us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 234/300\n",
      "24420/24420 [==============================] - 1s 40us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 235/300\n",
      "24420/24420 [==============================] - 1s 42us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 236/300\n",
      "24420/24420 [==============================] - 1s 46us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 237/300\n",
      "24420/24420 [==============================] - 1s 41us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 238/300\n",
      "24420/24420 [==============================] - 1s 40us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 239/300\n",
      "24420/24420 [==============================] - 1s 41us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 240/300\n",
      "24420/24420 [==============================] - 1s 42us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 241/300\n",
      "24420/24420 [==============================] - 1s 40us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 242/300\n",
      "24420/24420 [==============================] - 1s 42us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 243/300\n",
      "24420/24420 [==============================] - 1s 51us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 244/300\n",
      "24420/24420 [==============================] - 1s 46us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 245/300\n",
      "24420/24420 [==============================] - 1s 40us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 246/300\n",
      "24420/24420 [==============================] - 1s 39us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 247/300\n",
      "24420/24420 [==============================] - 1s 39us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 248/300\n",
      "24420/24420 [==============================] - 1s 42us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 249/300\n",
      "24420/24420 [==============================] - 1s 50us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 250/300\n",
      "24420/24420 [==============================] - 1s 45us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 251/300\n",
      "24420/24420 [==============================] - 1s 40us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 252/300\n",
      "24420/24420 [==============================] - 1s 56us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 253/300\n",
      "24420/24420 [==============================] - 1s 57us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 254/300\n",
      "24420/24420 [==============================] - 1s 45us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 255/300\n",
      "24420/24420 [==============================] - 1s 44us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 256/300\n",
      "24420/24420 [==============================] - 1s 45us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 257/300\n",
      "24420/24420 [==============================] - 1s 46us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 258/300\n",
      "24420/24420 [==============================] - 1s 45us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 259/300\n",
      "24420/24420 [==============================] - 1s 40us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 260/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 261/300\n",
      "24420/24420 [==============================] - 1s 38us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 262/300\n",
      "24420/24420 [==============================] - 1s 48us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 263/300\n",
      "24420/24420 [==============================] - 1s 51us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 264/300\n",
      "24420/24420 [==============================] - 1s 53us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 265/300\n",
      "24420/24420 [==============================] - 1s 58us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 266/300\n",
      "24420/24420 [==============================] - 1s 54us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 267/300\n",
      "24420/24420 [==============================] - 1s 50us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 268/300\n",
      "24420/24420 [==============================] - 1s 53us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 269/300\n",
      "24420/24420 [==============================] - 1s 40us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 270/300\n",
      "24420/24420 [==============================] - 1s 44us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 271/300\n",
      "24420/24420 [==============================] - 1s 43us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 272/300\n",
      "24420/24420 [==============================] - 1s 39us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 273/300\n",
      "24420/24420 [==============================] - 1s 49us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 274/300\n",
      "24420/24420 [==============================] - 1s 52us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 275/300\n",
      "24420/24420 [==============================] - 1s 47us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 276/300\n",
      "24420/24420 [==============================] - 1s 50us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 277/300\n",
      "24420/24420 [==============================] - 1s 45us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 278/300\n",
      "24420/24420 [==============================] - 1s 42us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 279/300\n",
      "24420/24420 [==============================] - 1s 44us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 280/300\n",
      "24420/24420 [==============================] - 1s 42us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 281/300\n",
      "24420/24420 [==============================] - 1s 41us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 282/300\n",
      "24420/24420 [==============================] - 1s 41us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 283/300\n",
      "24420/24420 [==============================] - 1s 41us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 284/300\n",
      "24420/24420 [==============================] - 1s 43us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 285/300\n",
      "24420/24420 [==============================] - 1s 43us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 286/300\n",
      "24420/24420 [==============================] - 1s 41us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 287/300\n",
      "24420/24420 [==============================] - 1s 43us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 288/300\n",
      "24420/24420 [==============================] - 1s 42us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 289/300\n",
      "24420/24420 [==============================] - 1s 42us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 290/300\n",
      "24420/24420 [==============================] - 1s 41us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 291/300\n",
      "24420/24420 [==============================] - 1s 42us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 292/300\n",
      "24420/24420 [==============================] - 1s 42us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 293/300\n",
      "24420/24420 [==============================] - 1s 42us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 294/300\n",
      "24420/24420 [==============================] - 1s 41us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 295/300\n",
      "24420/24420 [==============================] - 1s 42us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 296/300\n",
      "24420/24420 [==============================] - 1s 41us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 297/300\n",
      "24420/24420 [==============================] - 1s 42us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 298/300\n",
      "24420/24420 [==============================] - 1s 41us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 299/300\n",
      "24420/24420 [==============================] - 1s 42us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 300/300\n",
      "24420/24420 [==============================] - 1s 41us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9994\n"
     ]
    }
   ],
   "source": [
    "model5 = build_model(normalized_X_train_without_male_female, A_train, X_val_normalized_a, A_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.999324365825195\n"
     ]
    }
   ],
   "source": [
    "score = evaluate_model(model5, normalized_X_test_without_male_female, A_test)\n",
    "print('Test accuracy:', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9994473609382787"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_hat_normalised = predict(model5, normalized_X_test_without_male_female)\n",
    "reweighted_accuracy(A_hat_normalised, A_test, A_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, let’s try a neural network solution. Train a neural network with at least one hidden layer as your binary classifier. Use a cross-entropy loss, and include an MMD regularizer on the final hidden layer of the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mmd import MMD_torch\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_model_with_regularizer(train_data, train_target, val_data, val_target,regularizer, batch_size=32, epochs=20, verbose=1):\n",
    "    # Build neural network\n",
    "    model1 = Sequential()\n",
    "    model1.add(Dense(256, activation='relu', input_dim=train_data.shape[1]))\n",
    "    #model.add(Dropout(0.1))\n",
    "    model1.add(Dense(128, activation='relu', kernel_regularizer=regularizer))\n",
    "    #model.add(Dropout(0.1))\n",
    "    model1.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Compile model\n",
    "    model1.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam', \n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # Train model\n",
    "    model1.fit(train_data, train_target,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              verbose=verbose,\n",
    "              validation_data=(val_data, val_target))\n",
    "    return model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A = df_a\n",
    "A = np.array(A)[:5000]\n",
    "A = torch.tensor(A)\n",
    "\n",
    "Z = df\n",
    "Z = np.array(Z)\n",
    "\n",
    "\n",
    "\n",
    "Z = torch.tensor(Z)[:5000]\n",
    "#from keras import backend as K\n",
    "a = MMD_torch(Z, A).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model for alpha ==  1\n",
      "===================================classifier g=================================================\n",
      "Test accuracy for Y: 0.8345310484870236\n",
      "deltaDP for Y 0.4780466538323777\n",
      "====================================================================================================\n",
      "===================================classifier h=================================================\n",
      "Test accuracy for A: 0.999324365825195\n",
      "reweighted accuracy for A 0.9992625873801596\n",
      "====================================================================================================\n",
      "model for alpha ==  0.1\n",
      "===================================classifier g=================================================\n",
      "Test accuracy for Y: 0.8267919661210756\n",
      "deltaDP for Y 0.5228691849724653\n",
      "====================================================================================================\n",
      "===================================classifier h=================================================\n",
      "Test accuracy for A: 0.9992629445365764\n",
      "reweighted accuracy for A 0.9993089336435654\n",
      "====================================================================================================\n",
      "model for alpha ==  0.01\n",
      "===================================classifier g=================================================\n",
      "Test accuracy for Y: 0.8300472943592874\n",
      "deltaDP for Y 0.493727194202364\n",
      "====================================================================================================\n",
      "===================================classifier h=================================================\n",
      "Test accuracy for A: 0.9990172593821018\n",
      "reweighted accuracy for A 0.9990323848018907\n",
      "====================================================================================================\n",
      "model for alpha ==  0.001\n",
      "===================================classifier g=================================================\n",
      "Test accuracy for Y: 0.8324427246410412\n",
      "deltaDP for Y 0.5088961821440288\n",
      "====================================================================================================\n",
      "===================================classifier h=================================================\n",
      "Test accuracy for A: 0.9990786806707205\n",
      "reweighted accuracy for A 0.9987550715908362\n",
      "====================================================================================================\n",
      "model for alpha ==  0.0001\n",
      "===================================classifier g=================================================\n",
      "Test accuracy for Y: 0.8261777532348893\n",
      "deltaDP for Y 0.477346538976155\n",
      "====================================================================================================\n",
      "===================================classifier h=================================================\n",
      "Test accuracy for A: 0.9992629445365764\n",
      "reweighted accuracy for A 0.9993089336435654\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "#redefine the keras l1 regularizer\n",
    "\n",
    "alphas = [1, 0.1, 0.01, 0.001, 0.0001]\n",
    "accuracies = []\n",
    "delta_DPs = []\n",
    "accuracies_A = []\n",
    "reweighted_acc = []\n",
    "for alpha in alphas:\n",
    "    print('model for alpha == ', alpha)\n",
    "    def l1_reg(alpha):\n",
    "        return alpha*a\n",
    "    print('===================================classifier g=================================================')\n",
    "    # Build neural network\n",
    "    model6 = build_model_with_regularizer(normalized_X_train, Y_train, normalized_X_val, Y_val, l1_reg, batch_size=16, epochs= 20, verbose=0,)\n",
    "    score = evaluate_model(model6, normalized_X_test, Y_test)\n",
    "    accuracies.append(score)\n",
    "    print('Test accuracy for Y:', score)\n",
    "    y_hat_after_mmd = predict(model6, normalized_X_test)\n",
    "    delta_DPs.append(compute_delta_DP(y_hat_after_mmd.flatten(), Y_test))\n",
    "    print('deltaDP for Y', compute_delta_DP(y_hat_after_mmd.flatten(), Y_test))\n",
    "    print('=='*50)\n",
    "    \n",
    "    print('===================================classifier h=================================================')\n",
    "    model7 = build_model_with_regularizer(normalized_X_train_without_male_female, A_train, X_val_normalized_a, A_val, l1_reg, batch_size=16, epochs= 20, verbose=0)\n",
    "    score = evaluate_model(model7, normalized_X_test_without_male_female, A_test)\n",
    "    accuracies_A.append(score)\n",
    "    print('Test accuracy for A:', score)\n",
    "    A_hat_mmd = predict(model7, normalized_X_test_without_male_female)\n",
    "    reweighted_acc.append(reweighted_accuracy(A_hat_mmd, A_test, A_test))\n",
    "    print('reweighted accuracy for A', reweighted_accuracy(A_hat_mmd, A_test, A_test))\n",
    "    print('=='*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlEAAAHSCAYAAADMsJ41AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWUb+YwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe094cbd8d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(alphas,accuracies, label='accuracy for Y')\n",
    "plt.plot(alphas,delta_DPs, label='delta_DP')\n",
    "plt.plot(alphas,accuracies_A, label='accuracy for A')\n",
    "plt.plot(alphas,reweighted_acc, label='reweighted accuracy')\n",
    "plt.legend()\n",
    "plt.savefig('mmd.png', dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
